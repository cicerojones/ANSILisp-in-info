This is long-ANSI-sample.info, produced by makeinfo version 4.8 from
/Users/a/Documents/lisp-in-info/long-samp.texi.

   This is a short manual.

   This is the next paragraph


File: long-ANSI-sample.info,  Node: Example-- Macro Utilities,  Next: On Lisp,  Prev: Generalized Reference,  Up: Macros

10.7 Example- Macro Utilities
=============================

Section 6.4 introduced the concept of a utility, a general-purpose
operator like those that make up Lisp itself. We can use macros to
define utilities that could not be written as functions. We've seen
several examples already: NIL ! , ntimes, and while all have to be
written as macros, because all have to control the way in which their
arguments are evaluated. This section gives some more examples of the
kinds of utilities you can write with macros. Figure 10.2 contains a
selection that have proven their worth in practice. The first, for,
is similar in design to while (page 164). It is for loops whose
bodies are evaluated with a new variable bound to a range of values:
> (for x 1 8 (princ x)) 12345678 NIL

   170

   MACROS

   (defmacro for (var start stop ftbody body) (let ((gstop (gensym)))
'(do ((,var ,start (1+ ,var)) (,gstop ,stop)) ((> ,var ,gstop))
,<3body)))

   (defmacro in (obj ferest choices) (let ((insym (gensym))) '(let
((,insym ,obj)) (or ,\Comma-at(mapcar #'(lambda (c) '(eql ,insym ,c))
choices)))))

   (defmacro random-choice (ferest exprs) '(case (random ,(length
exprs)) ,\Comma-at(let ((key -1)) (mapcar #>(lambda (expr) '(,(incf
key) ,expr)) exprs))))

   (defmacro avg (&rest args) '(/ (+ ,<3args) ,(length args)))

   (defmacro with-gensyms (syms febody body) '(let ,(mapcar #'(lambda
(s) '(,s (gensym))) syms) ,©body))

   (defmacro aif (test then ^optional else) '(let ((it ,test)) (if it
,then ,else)))

   Figure 10.2: Macro utilities.

   This is less work to write than the equivalent do, (do ((x 1 (1+ x
))) ((> x 8)) ( princx)) which is very close to the actual expansion:

   10.7 (do ((x 1 (1+ x)) ( # : g l 8)) ((> x # : g l )) (princ x))

   EXAMPLE: MACRO UTILITIES

   171

   The macro has to introduce an additional variable to hold the
value that marks the end of the range. The 8 in the example above
might have been a call, and we would not want to evaluate it multiple
times. The additional variable has to be a gensym, in order to avoid
inadvertent variable capture. The second macro in Figure 10.2, in,
returns true if its first argument is eql to any of the other
arguments. The expression that we can write as (in (car expr) '+ ' -
'*) we would otherwise have to write as (let ((op (car (or (eql op
(eql op (eql op expr))) '+) '-) '*)))

   Indeed, the first expression expands into one like the second,
except that the variable op is replaced by a gensym. The next
example, random-choice, randomly chooses an argument to evaluate. We
had to choose randomly between two alternatives on page 74. The
random-choice macro implements the general solution. A call like
(random-choice (turn-left) (turn-right)) gets expanded into: (case
(random 2) (0 ( t u r n - l e f t )) (1 ( t u r n - r i g h t ))) The
next macro, with-gensyms is intended to be used mainly within macro
bodies. It's not unusual, especially in macros for specific
applications, to have to gensym several variables. With this macro,
instead of (let ((x (gensym)) (y (gensym)) (z (gensym))) ...) we can
write (with-gensyms (x y z) ...)

   172

   MACROS

   So far, none of the macros defined in Figure 10.2 could have been
defined as functions. As a rule, the only reason to write something
as a macro is because you can't write it as a function. But there are
a few exceptions to this rule. Sometimes you may want to define an
operator as a macro in order to make it do some of its work at
compile-time. The macro avg, which returns the average of its
arguments, > (avg 2 4 8) 14/3 is an example of such a macro. We could
write avg as a function,

   (defun avg (ferest args) (/ (apply #'+ args) (length a r g s )))

   but then it would have to find the number of arguments at
run-time. As long as we are willing to forgo applying avg, why not
make this call to length at compile-time? The last macro in Figure
10.2 is aif, which is included as an example of intentional variable
capture. It allows us to use the variable i t to refer to the value
returned by the test argument in a conditional. That is, instead of
(let ((val (calculate-something))) (if val (1+ v a l ) 0)) we can
write (aif (calculate-something) (1+ it) 0) Used judiciously,
intentional variable capture can be a valuable technique. Common Lisp
itself uses it in several places: both next-method-p and c a l l - n
e x t - m e t hod rely on variable capture, for example. Macros like
these show clearly what it means to write programs that write your
programs for you. Once you have defined for, you don't have to write
out the whole do expression. Is it worth writing a macro just to save
typing? Very much so. Saving typing is what programming languages are
all about; the purpose of a compiler is to save you from typing your
program in machine language. And macros allow you to bring to your
specific applications the same kinds of advantages that high-level
languages bring to programming in general. By the careful use of
macros, you may be able to make your programs

   ON LISP

   173

   significantly shorter than they would be otherwise, and
proportionately easier to read, write, and maintain. If you doubt
this, consider what your programs would look like if you didn't use
any of the built-in macros. All the expansions those macros generate,
you would have to generate by hand. You can use this question in the
other direction as well. As you're writing a program, ask yourself,
am I writing macroexpansions? If so, the macros that generate those
expansions are the ones you need to write.


File: long-ANSI-sample.info,  Node: On Lisp,  Prev: Example-- Macro Utilities,  Up: Macros

10.8 On Lisp
============

Now that macros have been introduced, we see that even more of Lisp
is written in Lisp than we might have expected. Most of the Common
Lisp operators that aren't functions are macros, and they are all
written in Lisp. Only 25 of Common Lisp's built-in operators are
special operators. John Foderaro has called Lisp "a programmable
programming language."0 By writing your own functions and macros, you
can turn Lisp into just about any language you want. (We'll see a
graphic demonstration of this possibility in Chapter 17.) Whatever
turns out to be the right form for your program, you can be assured
that you will be able to shape Lisp to suit it. Macros are one of the
key ingredients in this flexibility. They allow you to transform Lisp
almost beyond recognition, and yet to do so in a principled,
efficient way. Within the Lisp community, macros are a topic of
increasing interest. It's clear already that one can do amazing
things with them, but more certainly remain to be discovered. By you,
if you want. Lisp has always put its evolution in the hands of the
programmer. That's why it survives.

   Summary 1. Calling eval is one way to make Lisp treat lists as
code, but it's inefficient and unnecessary.  2. You define a macro by
saying what a call should expand into. Underneath, macros are just
functions that return expressions.  3. A macro body defined with
backquote resembles the expansion it will produce.  4. The macro
designer must be aware of variable capture and multiple evaluation.
Macros can be tested by pretty-printing their expansions.  5.
Multiple evaluation is a problem for most macros that expand into
setfs.

    174

   MACROS

   6. Macros are more flexible than functions, and can be used to
define a broader range of utilities. You can even use variable
capture to advantage.  7. Lisp has survived because it puts its
evolution in the hands of the programmer. Macros are part of what
makes this possible.

   Exercises

   1. If x is a, y is b, and z is ( c d), write backquoted
expressions containing only variables that yield each of the
following: (a) ((CD) A Z) (b) (X B C D) (c) ((C D A) Z) 2. Define if
in terms of cond. 3. Define a macro that takes a number n followed by
one or more expressions, and returns the value of the nth expression:
> (let ((n 2)) (nth-expr n (/ 1 0) ( + 1 2 ) 3

   (/ 1 0 )))

   4. Define ntimes (page 167) to expand into a (local) recursive
function instead of ado. 5. Define a macro n-of that takes a number n
and an expression, and returns a list of n successive values returned
by the expression: > (let ( ( i 0) (n 4)) (n-of n (incf i ))) ( 1 2 3
4) 6. Define a macro that takes a list of variables and a body of
code, and ensures that the variables revert to their original values
after the body of code is evaluated.

   10.8

   EXERCISES

   175

   7. What's wrong with the following definition of push?

   (defmacro push (obj lst) ( (setf ,lst (cons ,obj ,lst)))

   Give an example of a call where it would not do the same thing as
the real push. 8. Define a macro that doubles its argument: > (let
((x 1)) (double x) x) 2


File: long-ANSI-sample.info,  Node: CLOS,  Next: Structure,  Prev: Macros,  Up: Top

11 CLOS
*******

The Common Lisp Object System, or CLOS, is a set of operators for
doing object-oriented programming. Because of their common history it
is conventional to treat these operators as a group.0 Technically,
they are in no way distinguished from the rest of Common Lisp: def
method is just as much (and just as little) an integral part of the
language as defun.

* Menu:

* Object-Oriented Programming::
* Classes and Instances::
* Slot Properties::
* Superclasses::
* Precedence::
* Generic Functions::
* Auxiliary Methods::
* Method Combination::
* Encapsulation::
* Two Models::


File: long-ANSI-sample.info,  Node: Object-Oriented Programming,  Next: Classes and Instances,  Up: CLOS

11.1 Object-Oriented Programming
================================

Object-oriented programming means a change in the way programs are
organized. This change is analogous to the one that has taken place
in the distribution of processor power. In 1970, a multi-user
computer system meant one or two big mainframes connected to a large
number of dumb terminals. Now it is more likely to mean a large
number of workstations connected to one another by a network. The
processing power of the system is now distributed among individual
users instead of centralized in one big computer. Object-oriented
programming breaks up traditional programs in much the same way.
Instead of having a single program that operates on an inert mass of
data, the data itself is told how to behave, and the program is
implicit in the interactions of these new data "objects." For
example, suppose we want to write a program to find the areas of
two-dimensional shapes. One way to do this would be to write a single
function that looked at the type of its argument and behaved
accordingly, as in Figure 11.1.

   176

   11.1

   OBJECT-ORIENTED PROGRAMMING

   177

   (defstruct rectangle height width) (defstruct circle radius)

   (defun area (x) (cond ((rectangle-p x) ( * (rectangle-height x)
(rectangle-width x))) ((circle-p x) ( * pi (expt (circle-radius x)
2)))))

   > (let ((r (make-rectangle))) (setf (rectangle-height r) 2
(rectangle-width r) 3) (area r)) 6

   Figure 11.1: Area with structures and a function.

   Using CLOS we might write an equivalent program as in Figure 11.2.
In the object-oriented model, our program gets broken up into several
distinct methods, each one intended for certain kinds of arguments.
The two methods in Figure 11.2 implicitly define an a r e a function
that works just like the one in Figure 11.1. When we call area, Lisp
looks at the type of the argument and invokes the corresponding
method. Together with this way of breaking up functions into distinct
methods, object-oriented programming implies inheritance-both of
slots and methods. The empty list given as the second argument in the
two def classes in Figure 11.2 is a list of superclasses. Suppose we
define a new class of colored objects, and then a class of colored
circles that has both colored and c i r c l e as superclasses: ( d e
f c l a s s colored () (color)) (defclass c o l o r e d - c i r c l e
( c i r c l e colored) 0) When we make instances of c o l o r e d - c
i r c l e , we will see two kinds of inheritance:

   178

   CLOS

   (defclass rectangle 0 (height width)) ( d e f c l a s s c i r c l
e () (radius)) (defmethod a r e a ((x r e c t a n g l e )) (* ( s l o
t - v a l u e x J h e i g h t ) ( s l o t - v a l u e x ' w i d t h
))) (defmethod area ((x c i r c l e )) (* p i (expt ( s l o t -value
x ' r a d i u s ) 2 ))) > (let ( ( r (make-instance ' r e c t a n g l
e ))) (setf (slot-value r 'height) 2 ( s l o t - v a l u e r 'width)
3) (area r )) 6 Figure 11.2 : Area with classes and methods.

   1. Instances of c o l o r e d - c i r c l e will have two slots: r
a d i u s , which is inherited from the c i r c l e class, and color,
which is inherited from the colored class. 2. Because there is no a r
e a method defined explicitly for instances of c o l o r e d - c i r
c l e , if we call a r e a on an instance of c o l o r e d - c i r c
l e , we will get the method defined for the c i r c l e class. In
practical terms, object-oriented programming means organizing a
program in terms of methods, classes, instances, and inheritance. Why
would you want to organize programs this way? One of the claims of
the objectoriented approach is that it makes programs easier to
change. If we want to change the way objects of class ob are
displayed, we just change the d i s p l a y method of the ob class.
If we want to make a new class of objects like obs but different in a
few respects, we can create a subclass of ob; in the subclass, we
change the properties we want, and all the rest will be inherited by
default from the ob class. And if we just want to make a single ob
that behaves differently from the rest, we can create a new child of
ob and modify the child's properties directly. If the program was
written carefully to begin with, we can make all these types of
modifications without even looking at the rest of the code.0

   11.3

   CLASSES AND INSTANCES

   179


File: long-ANSI-sample.info,  Node: Classes and Instances,  Next: Slot Properties,  Prev: Object-Oriented Programming,  Up: CLOS

11.2 Classes and Instances
==========================

In Section 4.6 we went through two steps to create structures: we
called def s t r u c t to lay out the form of a structure, and a
specific function like make-point to make them. Creating instances
requires two analogous steps. First we define a class, using def c l
a s s : (defclass circle () (radius center))

   This definition says that instances of the c i r c l e class will
have two slots (like fields in a structure), named r a d i u s and c
e n t e r respectively. To make instances of this class, instead of
calling a specific function, we call the general make-instance with
the class name as the first argument: > (setf c (make-instance
#<Circle #XC27496> 'circle))

   To set the slots in this instance, we can use s e t f with s l o t
- v a l u e : > (setf ( s l o t - v a l u e c ' r a d i u s ) 1) 1
Like structure fields, the values of uninitialized slots are
undefined.


File: long-ANSI-sample.info,  Node: Slot Properties,  Next: Superclasses,  Prev: Classes and Instances,  Up: CLOS

11.3 Slot Properties
====================

The third argument to d e f c l a s s must be a list of slot
definitions. The simplest slot definition, as in the example above,
is a symbol representing its name. In the general case, a slot
definition can be a list of a name followed by one or more
properties. Properties are specified like keyword arguments, By
defining an : accessor for a slot, we implicitly define a function
that refers to the slot, making it unnecessary to call s l o t - v a
l u e . If we update our definition of the c i r c l e class as
follows, (defclass c i r c l e () ( ( r a d i u s :accessor c i r c l
e - r a d i u s ) (center :accessor c i r c l e - c e n t e r )))
then we will be able to refer to the slots as c i r c l e - r a d i u
s and c i r c l e center respectively: > (setf c (make-instance ' c i
r c l e )) #<Circle #XC5C726>

   180

   CLOS

   > (setf (circle-radius c) 1) 1 > (circle-radius c) 1 By specifying
a : w r i t e r or a : r e a d e r instead of an : accessor, we could
get just the first half of this behavior, or just the second. To
specify a default value for a slot, we have to give an : i n i t f
orm argument. If we want to be able to initialize the slot in the
call to make-instance, we define a parameter name as an : i n i t a r
g . 1 With both added, our class definition might become: ( d e f c l
a s s c i r c l e () ( ( r a d i u s :accessor :initarg :initform ( c
e n t e r :accessor :initarg :initform circle-radius :radius 1)
circle-center :center (cons 0 0 ))))

   Now when we make an instance of a c i r c l e we can either pass a
value for a slot using the keyword parameter defined as the slot's :
i n i t a r g , or let the value default to that of the slot's : i n
i t f orm. > ( s e t f c (make-instance ' c i r c l e .-radius 3))
#<Circle #XC2DE0E>

   > (circle-radius c) 3

   > ( c i r c l e - c e n t e r c) (0 . 0) Note that : i n i t a r g
s take precedence over : i n i t f orms. We can specify that some
slots are to be shared-that is, their value is the same for every
instance. We do this by declaring the slot to have ·.allocation : c
l a s s . (The alternative is for a slot to have -.allocation : i n s
t a n c e , but since this is the default there is no need to say so
explicitly.) When we change the value of such a slot in one instance,
that slot will get the same value in every other instance. So we
would want to use shared slots to contain properties that all the
instances would have in common. For example, suppose we wanted to
simulate the behavior of a flock of tabloids. In our simulation we
want to be able to represent the fact that when one tabloid takes up
a subject, they all do. We can do this by making all the instances
share a slot. If the t a b l o i d class is defined as follows,
Initarg names are usually keywords, but they don't have to be.

   11.4

   SUPERCLASSES

   181

   (defclass t a b l o i d () ( ( t o p - s t o r y .-accessor t a b
l o i d - s t o r y :allocation :class))) then if we make two
instances of tabloids, whatever becomes front-page news to one
instantly becomes front-page news to the other: > (setf daily-blab
(make-instance 'tabloid) unsolicited-mail (make-instance 'tabloid))
#<Tabloid #XC2AB16> > (setf (tabloid-story daily-blab)
'adultery-of-senator) ADULTERY-OF-SENATOR > (tabloid-story
unsolicited-mail) ADULTERY-OF-SENATOR

   The : documentation property, if given, should be a string to
serve as the slot's documentation. By specifying a : type, you are
promising that the slot will only contain elements of that type. Type
declarations are explained in Section 13.3.


File: long-ANSI-sample.info,  Node: Superclasses,  Next: Precedence,  Prev: Slot Properties,  Up: CLOS

11.4 Superclasses
=================

The second argument to def c l a s s is a list of superclasses. A
class inherits the union of the slots of its superclasses. So if we
define the class s c r e e n - c i r c l e to be a subclass of both c
i r c l e and graphic, (defclass graphic () ((color :accessor g r a p
h i c - c o l o r :initarg ( v i s i b l e :accessor g r a p h i c -
v i s i b l e : i n i t a r g :initform t ))) (defclass s c r e e n -
c i r c l e ( c i r c l e graphic) :color) :visible

   0)

   then instances of s c r e e n - c i r c l e will have four slots,
two inherited from each superclass. A class does not have to create
any new slots of its own; s c r e e n - c i r c l e exists just to
provide something instantiable that inherits from both c i r c l e
and graphic. The accessors and initargs work for instances of s c r e
e n - c i r c l e just as they would for instances of c i r c l e or
graphic: > ( g r a p h i c - c o l o r (make-instance RED
'screen-circle :color ' r e d : r a d i u s 3))

   182

   CLOS

   We can cause every s c r e e n - c i r c l e to have some default
initial color by specifying an initform for this slot in the def c l
a s s : ( d e f c l a s s s c r e e n - c i r c l e ( c i r c l e
graphic) ((color :initform 'purple))) Now instances of s c r e e n -
c i r c l e will be purple by default: > ( g r a p h i c - c o l o r
(make-instance PURPLE 'screen-circle))


File: long-ANSI-sample.info,  Node: Precedence,  Next: Generic Functions,  Prev: Superclasses,  Up: CLOS

11.5 Precedence
===============

We've seen how classes can have multiple superclasses. When there are
methods defined for several of the classes to which an instance
belongs, Lisp needs some way to decide which one to use. The point of
precedence is to ensure that this happens in an intuitive way. For
every class there is a precedence list: an ordering of itself and its
superclasses from most specific to least specific. In the examples so
far, precedence has not been an issue, but it can become one in
bigger programs. Here's a more complex class hierarchy: ( d e f c l a
s s s c u l p t u r e () (height width depth)) (defclass statue
(sculpture) ( d e f c l a s s metalwork () (subject))

   (metal-type))

   ( d e f c l a s s c a s t i n g (metalwork) ( )) (defclass
cast-statue (statue casting) ())

   Figure 11.3 contains a network representing c a s t - s t a t u e
and its superclasses. To build such a network for a class, start at
the bottom with a node representing that class. Draw links upward to
nodes representing each of its immediate superclasses, laid out from
left to right as they appeared in the calls to d e f c l a s s .
Repeat the process for each of those nodes, and so on, until you
reach classes whose only immediate superclass is standard-object-that
is, classes for which the second argument to d e f c l a s s was ( )
. Create links from those classes up to a node representing s t a n d
a r d - o b j e c t , and one from that node up to another node
representing the class t . The result will be a network that comes to
a point at both top and bottom, as in Figure 11.3.

   11.6

   PRECEDENCE

   183

   ^standard-objt

   JL icT^ \V (jnetalworkj)

   0

   i

   ^sculpture

   y

   C

   ^jUT statue

   J)

   Q

   jn" casting

   ^

   /if

   > (^cast-statue Figure 11.3: Class hierarchy.

   The precedence list for a class can be computed by traversing the
corresponding network as follows: 1. Start at the bottom of the
network. 2. Walk upward, always taking the leftmost unexplored
branch. 3. If you are about to enter a node and you notice another
path entering the same node from the right, then instead of entering
the node, retrace your steps until you get to a node with an
unexplored path leading upward. Go back to step 2. 4. When you get to
the node representing t, you're done. The order in which you first
entered each node determines its place in the precedence list. One of
the consequences of this definition (in fact, of rule 3) is that no
class appears in the precedence list before one of its subclasses.
The arrows in Figure 11.3 show how it would be traversed. The
precedence list determined by this graph is: c a s t - s t a t u e ,
s t a t u e , s c u l p t u r e , c a s t i n g , metalwork, s t a n
d a r d - o b j e c t , t . Sometimes the word specific is used as
shorthand to refer to the position of a class in a given precedence
list. The preceding list runs from most specific to least specific.
The main point of precedence is to decide what method gets used when
a generic function is invoked. This process is described in the next
section. The other time precedence matters is when a slot with a
given name is inherited from several superclasses. The note on page
408 explains the rules that apply when this happens.0

   184

   CLOS


File: long-ANSI-sample.info,  Node: Generic Functions,  Next: Auxiliary Methods,  Prev: Precedence,  Up: CLOS

11.6 Generic Functions
======================

A generic function is a function made up of one or more methods.
Methods are defined with def method, which is similar in form to def
un: (defmethod combine (x y) ( LIST x y)) Now combine has one method.
If we call combine at this point, we will get the two arguments in a
list: > (combine ' a 'b) (A B) So far we haven't done anything we
could not have done with a normal function. The unusual thing about a
generic function is that we can continue to add new methods for it.
First, we define some classes for the new methods to refer to: ( d e
f c l a s s s t u f f () ((name :accessor name : i n i t a r g
:name))) ( d e f c l a s s ice-cream ( s t u f f ) ( )) ( d e f c l a
s s topping ( s t u f f ) ( )) This defines three classes: stuff,
which is just something with a name, and ice-cream and topping, which
are subclasses of stuff. Now here is a second method for combine:
(defmethod combine ( ( i c ice-cream) (top topping)) (format NIL ""A
ice-cream with ~A t o p p i n g . " (name i c ) (name t o p ))) In
this call to defmethod the parameters are specialized: each one
appears in a list with the name of a class. The specializations of a
method indicate the kinds of arguments to which it applies. The
method we just defined will only be used if the arguments to combine
are instances of ice-cream and topping respectively. How does Lisp
decide which method to use when a generic function is called? It will
use the most specific method for which the classes of the arguments
match the specializations of the parameters. Which means that if we
call combine with an instance of ice-cream and an instance of
topping, we'll get the method we just defined: > (combine
(make-instance ' i c e - c r e a m :name ' f i g ) (make-instance ' t
o p p i n g :name ' t r e a c l e )) "FIG ice-cream with TREACLE t o
p p i n g . "

   11.6

   GENERIC FUNCTIONS

   185

   But with any other arguments, we'll get the first method we
defined: > (combine 23 'skiddoo) (23 SKIDDOO) Because neither of the
parameters of the first method is specialized, it will always get
last priority, yet will always get called if no other method does. An
unspecialized method acts as a safety net, like an otherwise clause
in a case expression. Any combination of the parameters in a method
can be specialized. In this method only the first argument is:
(defmethod combine ((ic ice-cream) x) (format nil "~A ice-cream with
A." (name ic) x))

   If we call combine with an instance of ice-cream and an instance
of topping, we'll still get the method that's looking for both,
because it's more specific: > (combine (make-instance ' i c e - c r e
a m :name 'grape) (make-instance ' t o p p i n g :name 'marshmallow))
"GRAPE ice-cream with M A R S H M A L L O W topping." However, if the
first argument is ice-cream and the second argument is anything but
topping, we'll get the method we just defined above: > (combine
(make-instance ' i c e - c r e a m :name 'clam) 'reluctance) "CLAM
ice-cream with RELUCTANCE." When a generic function is called, the
arguments determine a set of one or more applicable methods. A method
is applicable if the arguments in the call come within the
specializations of all its parameters. If there are no applicable
methods we get an error. If there is just one, it is called. If there
is more than one, the most specific gets called. The most specific
applicable method is determined based on the class precedence for the
arguments in the call. The arguments are examined left to right. If
the first parameter of one of the applicable methods is specialized
on a more specific class than thefirstparameters of the other
methods, then it is the most specific method. Ties are broken by
looking at the second argument, and so on.2 2 We can't go through all
the arguments and still have a tie, because then we would have two
methods with exactly the same specializations. That's impossible
because the definition of the second would overwrite the first.

   186

   CLOS

   In the preceding examples, it is easy to see what the most
specific applicable method would be, because all the objects have a
single line of descent. An instance of ice-cream is, in order,
itself, ice-cream, stuff, a standard-ob j ect, and a member of the
class t. Methods don't have to be specialized on classes defined by
def c l a s s . They can also be specialized on types (or more
precisely, the classes that mirror types). Here is a method for
combine that's specialized on numbers: (defmethod combine ((x number)
(y number)) (+ x y))

   Methods can even be specialized on individual objects, as
determined by eql: (defmethod combine ((x (eql 'powder)) (y (eql ' s
p a r k ))) 'boom) Specializations on individual objects take
precedence over class specializations. Methods can have parameter
lists as complex as ordinary Common Lisp functions, but the parameter
lists of all the methods that compose a generic function must be
congruent. They must have the same number of required parameters, the
same number of optional parameters (if any), and must either all use
ferest or &key, or all not use them. The following pairs of parameter
lists are all congruent, (x) (x feoptional y) (x y ferest z) (x y
&key z) (a) (afeoptionalb) (a b &key c) (a b &key c d)

   and the following pairs are not: (x) (a b) (x &optional y) (a
&optional b c) (x feoptional y) (a forest b) (x &key x y) (a) Only
required parameters can be specialized. Thus each method is uniquely
identified by its name and the specializations of its required
parameters. If we define another method with the same qualifiers and
specializations, it overwrites the original one. So by saying
(defmethod combine ((x (eql 'powder)) (y (eql 'spark))) 'kaboom)

   we redefine what combine does when its arguments are powder and
spark.

   11.7

   AUXILIARY METHODS

   187


File: long-ANSI-sample.info,  Node: Auxiliary Methods,  Next: Method Combination,  Prev: Generic Functions,  Up: CLOS

11.7 Auxiliary Methods
======================

Methods can be augmented by auxiliary methods, including before-,
after-, and around-methods. Before-methods allow us to say, "But
first, do this." They are called, most specific first, as a prelude
to the rest of the method call. After-methods allow us to say, "P.S.
Do this too." They are called, most specific last, as an epilogue to
the method call. Between them, we run what has till now been
considered just the method, but is more precisely known as the
primary method. The value of this call is the one returned, even if
after-methods are called later. Before- and after-methods allow us to
wrap new behavior around the call to the primary method.
Around-methods provide a more drastic way of doing the same thing. If
an around-method exists, it will be called instead of the primary
method. Then, at its own discretion, the around-method may itself
invoke the primary method (via the function call-next-method, which
is provided just for this purpose). This is called standard method
combination. In standard method combination, calling a generic
function invokes 1. The most specific around-method, if there is one.
2. Otherwise, in order, (a) All before-methods, from most specific to
least specific. (b) The most specific primary method. (c) All
after-methods, from least specific to most specific. The value
returned is the value of the around-method (in case 1) or the value
of the most specific primary method (in case 2). Auxiliary methods
are defined by putting a qualifying keyword after the method name in
the call to def method. If we define a primary speak method for the
speaker class as (def c l a s s speaker 0 0)

   (defmethod speak ( ( s speaker) s t r i n g ) (format t "~A" s t r
i n g )) then calling speak with an instance of speaker just prints
the second argument: > (speak (make-instance 'speaker) "I'm hungry")
I'm hungry NIL

   188

   CLOS

   By defining a subclass i n t e l l e c t u a l , which wraps
before- and aftermethods around the primary speak method, ( d e f c l
a s s i n t e l l e c t u a l (speaker) ()) string)

   (defmethod speak :before ( ( i i n t e l l e c t u a l ) (
princ"Perhaps ")) (defmethod speak : a f t e r ( ( i i n t e l l e c
t u a l ) ( princ" i n some s e n s e " ))

   string)

   we can create a subclass of speakers that always have the last
(and the first) word: > (speak (make-instance 'intellectual) "I'm
hungry") Perhaps I'm hungry in some sense NIL

   As the preceding outline of standard method combination noted, all
before- and after-methods get called. So if we define before- or
after-methods for the speaker superclass, (defmethod speak .-before (
( s speaker) s t r i n g ) ( princ"I t h i n k ")) they will get
called in the middle of the sandwich: > (speak (make-instance
'intellectual) "I'm hungry") Perhaps I think I'm hungry in some sense
NIL

   Regardless of what before- or after-methods get called, the value
returned by the generic function is the value of the most specific
primary method-in this case, the NIL returned by format. This changes
if there are around-methods. If there is an around-method specialized
for the arguments passed to the generic function, the aroundmethod
will get called first, and the rest of the methods will only run if
the around-method decides to let them. An around- or primary method
can invoke the next method by calling call-next-method. Before doing
so, it can use next-method-p to test whether there is a next method
to call. With around-methods we can define another, more cautious,
subclass of speaker:

   11.8

   METHOD COMBINATION

   189

   (defclass courtier (speaker) ()) (defmethod speak :around ((c
courtier) string) (format t "Does the King believe that ~A? " string)
(if (eql (read) 'yes) (if (next-method-p) (call-next-method)) (format
t "Indeed, it is a preposterous idea.~°/,")) 'bow)

   When the first argument to speak is an instance of the c o u r t i
e r class, the courtier's tongue is now guarded by the around-method:
> (speak (make-instance ' c o u r t i e r ) "kings will l a s t " )
Does the King believe that kings will l a s t ? yes I think kings
will l a s t BOW

   > (speak (make-instance ' c o u r t i e r ) "the world i s round")
Does the King believe that the world i s round? no Indeed, i t is a
preposterous idea. B O W Note that, unlike before- and after-methods,
the value returned by the aroundmethod is returned as the value of
the generic function.


File: long-ANSI-sample.info,  Node: Method Combination,  Next: Encapsulation,  Prev: Auxiliary Methods,  Up: CLOS

11.8 Method Combination
=======================

In standard method combination the only primary method that gets
called is the most specific (though it can call others via
call-next-method). Instead we might like to be able to combine the
results of all applicable primary methods. It's possible to define
methods that are combined in other ways-for example, for a generic
function to return the sum of all the applicable primary methods.
Operator method combination can be understood as if it resulted in
the evaluation of a Lisp expression whose first element was some
operator, and whose arguments were calls to the applicable primary
methods, in order of specificity. If we defined the p r i c e generic
function to combine values with +, and there were no applicable
around-methods, it would behave as though it were defined:

   (defun p r i c e (&rest args) (+ (apply (most specific primary
method) args) (apply (least specific primary method) a r g s )))

   190

   CLOS

   If there are applicable around-methods, they take precedence, just
as in standard method combination. Under operator method combination,
an aroundmethod can still call the next method via call-next-method.
However, primary methods can no longer use call-next-method. We can
specify the type of method combination to be used by a generic
function with a :method-combinat ion clause in a call to def generic:
(defgeneric p r i c e (x) (:method-combination +)) Now the p r i c e
method will use + method combination; any def met hods for p r i c e
must have + as the second argument. If we define some classes with
prices, ( d e f c l a s s j a c k e t () ( )) ( d e f c l a s s t r o
u s e r s () ()) ( d e f c l a s s s u i t (jacket t r o u s e r s )

   ())

   (defmethod p r i c e + ( ( j k j a c k e t )) 350) (defmethod p r
i c e + ( ( t r t r o u s e r s )) 200) then when we ask for the
price of an instance of s u i t , we get the sum of the applicable p
r i c e methods: > ( p r i c e (make-instance 550 'suit))

   The following symbols can be used as the second argument to def
method or in the : met hod-combination option to defgeneric: + and
append list max min nconc or progn

   You can also use standard, which yields standard method
combination. Once you specify the method combination a generic
function should use, all methods for that function must use the same
kind. Now it would cause an error if we tried to use another operator
(or -.before or : a f t e r ) as the second argument in a def method
for pr i ce. If we want to change the method combination of p r i c e
, we must remove the whole generic function by calling fmakunbound.


File: long-ANSI-sample.info,  Node: Encapsulation,  Next: Two Models,  Prev: Method Combination,  Up: CLOS

11.9 Encapsulation
==================

Object-oriented languages often provide some way of distinguishing
between the actual representation of objects and the interface they
present to the world. Hiding implementation details brings two
advantages: you can change the

   11.10

   ENCAPSULATION

   191

   implementation without affecting the object's outward appearance,
and you prevent objects from being modified in potentially dangerous
ways. Hidden details are sometimes said to be encapsulated. Although
encapsulation is often associated with object-oriented programming,
the two ideas are really separate. You can have either one without
the other. We saw an example of encapsulation on a small scale on
page 108. The functions stamp and r e s e t work by sharing a
counter, but calling code does not need to know about this counter,
nor can it modify it directly. In Common Lisp, packages are the
standard way to distinguish between public and private information.
To restrict access to something, we put it in a separate package, and
only export the names that are part of the external interface. We can
encapsulate a slot by exporting the names of the methods that can
modify it, but not the name of the slot itself. For example, we could
define a counter class and associated increment and c l e a r methods
as follows: (defpackage "CTR" (:use "COMMON-LISP") (:export "COUNTER"
"INCREMENT" "CLEAR")) (in-package ctr) (defclass counter () ((state
:initform 0))) (defmethod increment ((c counter)) (incf (slot-value c
'state))) (defmethod clear ((c counter)) (setf (slot-value c 'state)
0))

   Under this definition, code outside the package would be able to
make instances of counter and call increment and c l e a r , but
would not have legitimate access to the name s t a t e . If you want
to do more than just distinguish between the internal and external
interface to a class, and actually make it impossible to reach the
value stored in a slot, you can do that too. Simply unintern its name
after you've defined the code that needs to refer to it: (unintern ;

   state)

   Then there is no way, legitimate or otherwise, to refer to the
slot from any package.0

   192

   CLOS


File: long-ANSI-sample.info,  Node: Two Models,  Prev: Encapsulation,  Up: CLOS

11.10 Two Models
================

Object-oriented programming is a confusing topic partly because there
are two models of how to do it: the message-passing model and the
generic function model. The message-passing model came first. Generic
functions are a generalization of message-passing. In the
message-passing model, methods belong to objects, and are inherited
in the same sense that slots are. To find the area of an object, we
send it an a r e a message, t e l l obj a r e a and this invokes
whatever a r e a method obj has or inherits. Sometimes we have to
pass additional arguments. For example, a move method might take an
argument specifying how far to move. If we wanted to tell obj to move
10, we might send it the following message: tell obj move 10

   If we put this another way, (move obj 10) the limitation of the
message-passing model becomes clearer. In messagepassing, we only
specialize the first parameter. There is no provision for methods
involving multiple objects-indeed, the model of objects responding to
messages makes this hard even to conceive of. In the message-passing
model, methods are of objects, while in the generic function model,
they are specialized/or objects. If we only specialize the first
parameter, they amount to exactly the same thing. But in the generic
function model, we can go further and specialize as many parameters
as we need to. This means that, functionally, the message-passing
model is a subset of the generic function model. If you have generic
functions, you can simulate message-passing by only specializing the
first parameter.

   Summary 1. In object-oriented programming, the function/is defined
implicitly via the/methods of the objects that have them. Objects
inherit methods from their parents.

   2. Defining a class is like defining a structure, but more
verbose. A shared slot belongs to a whole class.

   3. A class inherits the slots of its superclasses.

   EXERCISES

   193

   4. The ancestors of a class are ordered into a precedence list.
The precedence algorithm is best understood visually.

   5. A generic function consists of all the methods with a given
name. A method is identified by its name and the specializations of
its parameters. Argument precedence determines the method used when a
generic function is called.

   6. Methods can be augmented by auxiliary methods. Standard method
combination means calling the around-method, if there is one;
otherwise the before-, most specific primary, and after-methods.

   7. In operator method combination, all the primary methods are
treated as arguments to some operator.

   8. Encapsulation can be done via packages.  9. There are two
models of object-oriented programming. The generic function model is
a generalization of the message-passing model.

   Exercises 1. Define accessors, initforms, and initargs for the
classes defined in Figure 11.2. Rewrite the associated code so that
it no longer calls slot-value. 2. Rewrite the code in Figure 9.5 so
that spheres and points are classes, and i n t e r s e c t and normal
are generic functions. 3. Suppose that a number of classes are
defined as follows: (defclass (defclass (defclass (defclass a b c d
(c (d () (e d) ...) c) ...) ..) f g) ...) (defclass (defclass
(defclass (defclass e f g h () . ..) (h) ...) (h) ...) () , .0

   (a) Draw the network representing the ancestors of a, and list the
classes an instance of a belongs to, from most to least specific. (b)
Do the same for b. 4. Suppose that you already have the following
functions; precedence: takes an object and returns its precedence
list, a list of classes ordered from most specific to least specific.

   194

   CLOS

   methods: takes a generic function and returns a list of all its
methods. s p e c i a l i z a t i o n s : takes a method and returns a
list of the specializations of the parameters. Each element of the
returned list will be either a class, or a list of the form (eql x),
or t (indicating that the parameter is unspecialized). Using these
functions (and not compute-applicable-methods or find-method), define
a function most-spec-app-meth that takes a generic function and a
list of the arguments with which it has been called, and returns the
most specific applicable method, if any. 5. Without changing the
behavior of the generic function area (Figure 11.2) in any other
respect, arrange it so that a global counter gets incremented each
time a r e a is called. 6. Give an example of a problem that would be
difficult to solve if only the first argument to a generic function
could be specialized.


File: long-ANSI-sample.info,  Node: Structure,  Next: Speed,  Prev: CLOS,  Up: Top

12 Structure
************

Section 3.3 explained how Lisp's use of pointers allows us to put any
value anywhere. This statement is full of possibilities, not all of
them good. For example, an object can be an element of itself. Whether
this is good or bad depends on whether it's done on purpose or by
accident.

* Menu:

* Shared Structure::
* SI::
* Modification::
* Example-- Queues::
* Destructive Functions::
* Example-- Binary Search Trees II::
* Example-- Doubly-Linked Lists::
* Circular Structure::
* Constant Structure::


File: long-ANSI-sample.info,  Node: Shared Structure,  Next: SI,  Up: Structure

12.1 Shared Structure
=====================

Lists can share conses in common. In the simplest case, one list
might be part of another. After > (setf p a r t ( LIST 'b ' c )) (B
C) > (setf whole (cons ' a p a r t )) (A B C) the first cons is part
of (in fact, is the cdr of) the second. In situations like this, we
say that the two lists share structure. The underlying structure of
the two lists is represented in Figure 12.1. The predicate t a i l p
detects this situation. It takes two lists and returns true if the
first would be encountered on traversing the second: > ( t a i l p p
a r t whole) T We could imagine it written as:

   195

   196

   STRUCTURE

   parts: wholel = nil whole2 =

   Figure 12.2: A shared tail.

   (defun our-tailp (x y) (or (eql x y) (and (consp y) (our-tailp x
(cdr y))))) As the definition suggests, every list is a tail of
itself, and NIL is a tail of every proper list. In the more complex
case, two lists can share structure without either one being a tail
of the other. This happens when they share a tail in common, as in
Figure 12.2. We can create this situation as follows: (setf part (
LIST ' b 'c) wholel (cons 1 p a r t ) whole2 (cons 2 p a r t )) Now
wholel and whole2 share structure without either list being part of
the other. When we have nested lists, it's important to distinguish
between the lists sharing structure, and their elements sharing
structure. Top-level list structure

   12.1

   SHARED STRUCTURE

   197

   holds 1 =

   · i

   nil f i

   \f nil

   f d.

   \ i

   r

   holds2 =

   ·

   1 Fig ure 3 iare d su btre B.

   I!

   nil


File: long-ANSI-sample.info,  Node: SI,  Next: Modification,  Prev: Shared Structure,  Up: Structure

12.2 SI
=======

refers to the conses that make up a list, not including any conses
that make up its elements. Figure 12.3 shows the top-level list
structure of a nested list. Whether two conses share structure
depends on whether we are considering them as lists or as trees. Two
nested lists may share structure as trees, without sharing structure
as lists. The following code creates the situation shown in Figure
12.4, in which two lists contain the same list as an element: (setf
element (list 'a Jb) holdsl (list 1 element 2) holds2 (list element
3))

   Although the second element of h o l d s l shares structure with
(in fact, is identical to) the first element of holds2, h o l d s l
and holds2 do not share structure as lists. Two lists only share
structure as lists if they share top-level list structure, which h o
l d s l and holds2 do not.

   198

   STRUCTURE

   X

   (copy-list)<) nil

   (copy-tree x)

   1 ^>* ;

   nil

   f

   1 a ~+

   1

   nil

   1

   1

   nil

   nil

   Figure 12.5: 1Pwo kinds o f copying.

   If we want to avoid sharing structure, we can do it by copying.
The function c o p y - LIST , which could be defined as

   (defun our-copy-list (lst) (if (null lst) nil (cons (car lst)
(our-copy-list (cdr lst)))))

   will return a list that doesn't share top-level list structure
with the original list. The function copy-tree, which might be
defined as

   (defun our-copy-tree (tr) (if (atom tr) tr (cons (our-copy-tree
(car tr)) (our-copy-tree (cdr tr)))))

   will return a list that doesn't even share tree structure with the
original list. Figure 12.5 shows the difference between calling c o p
y - LIST and copy-tree on a nested list.


File: long-ANSI-sample.info,  Node: Modification,  Next: Example-- Queues,  Prev: SI,  Up: Structure

12.3 Modification
=================

Why would we want to avoid sharing structure? Up to this point, the
issue of shared structure has been just an intellectual exercise. It
would not have made any difference to any program we've written so
far. It is when we modify objects that shared structure becomes an
issue. If two lists share structure, and we modify one, then we may
inadvertently be modifying the other. In the previous section, we saw
how to make one list a tail of another: (setf whole (list 'a ;b c)
tail (cdr whole))

   12.3

   MODIFICATION

   199

   Since this will make t a i l identical with the cdr of whole, if
we modify either t a i l or the cdr of whole, we are modifying the
same cons:

   > (setf (second t a i l ) ' e) E > tail (B E) > whole (A B E) The
same thing can also happen, of course, if two lists share the same
tail. It's not always an error to modify two things at once.
Sometimes it might be what you want. But when it happens
inadvertently, modifying shared structure can cause some very subtle
bugs. Lisp programmers learn to be aware of shared structure, and to
suspect it immediately in certain kinds of errors. When a list
mysteriously changes for no apparent reason, it is probably because
you changed something else that shared structure with it. It is not
the shared structure that's dangerous, but the changing. To be on the
safe side, simply avoid using s e t f (or related operators like pop,
rplaca, etc.) on list structure, and you won't run into any problems.
If some application absolutely requires you to modify list structure,
find out where the lists come from to make sure that they don't share
structure with anything that shouldn't be changed. If they do, or if
you can't predict where the lists will come from, make the changes to
a copy. You have to be doubly careful when you are calling a function
written by someone else. Until you know otherwise, consider the
possibility that anything you pass to the function 1. could have
destructive operations done to it, and/or 2. could be saved
somewhere, so that if you later modified the object, you would also
be modifying part of something that the other code was maintaining
for its own use.1 In both cases, the solution is to pass a copy. In
Common Lisp, a function called in the course of traversing list
structure (e.g. an argument to mapcar or remove-if) is not allowed to
modify the structure being traversed. The consequences of evaluating
such code are undefined.  For example, in Common Lisp it's an error
to modify a string being used as a symbol name, and since the
definition of i n t e r n doesn't say that it copies its argument, we
must assume that it's an error to modify any string that has been
passed to i n t e r n to create a new symbol.  1

   200

   STRUCTURE


File: long-ANSI-sample.info,  Node: Example-- Queues,  Next: Destructive Functions,  Prev: Modification,  Up: Structure

12.4 Example- Queues
====================

Shared structure is not just something to worry about. It's also
something you can put to use. This section shows how to use shared
structure to represent queues. A queue is a repository from which
objects can be retrieved, one at a time, in the order in which they
were inserted. This principle is known as FTFO, from "first in, first
out." It's easy to represent stacks using lists, because in a stack
you insert and retrieve from the same end. Representing queues is
more difficult, because insertion and retrieval happen at different
ends. To implement queues efficiently, we need somehow to get hold of
both ends of a list. Figure 12.6 suggests a strategy we could use. It
shows how we might represent a queue of a, b, and c. A queue is a
pair of a list, and the last cons in that same list. Call these front
and back. To retrieve an element from the queue we just pop front. To
add an element, we create a new cons, make it the cdr of back, and
then set back to it. The code in Figure 12.7 implements this
strategy. It's used as below: > (setf ql (make-queue)) (NIL) > (progn
(enqueue 'a ql) (enqueue ; b ql) (enqueue 'c ql)) (A B C)

   At this point, ql is the structure shown in Figure 12.6: > qi ((A
B C) C) Now we can try dequeueing some elements:

   12.4

   DESTRUCTIVE FUNCTIONS

   201

   (defun make-queue () (cons nil nil))

   (defun enqueue (obj q) (if (null (car q)) (setf (cdr q) (setf (car
q) (list obj))) (setf (cdr (cdr q)) (list obj) (cdr q) (cdr (cdr
q)))) (car q))

   (defun dequeue (q) (pop (car q))) Figure 12.7: Implementing queues.

   > (dequeue ql) A > (dequeue ql) B > (enqueue 'd ql) (C D)


File: long-ANSI-sample.info,  Node: Destructive Functions,  Next: Example-- Binary Search Trees II,  Prev: Example-- Queues,  Up: Structure

12.5 Destructive Functions
==========================

Common Lisp includes several functions that are allowed to modify
list structure. These functions are destructive for reasons of
efficiency. Though they may recycle conses passed to them as
arguments, they are not meant to be called for their side-effects.
For example, d e l e t e is a destructive version of remove. While it
is allowed to trash the list passed to it as an argument, it doesn't
promise to do anything. This is what happens in most implementations:
> ( s e t f lst >(a r a b i a )) (ARABIA) > (delete 'a lst) (R B I) >
lst (A R B I) As with remove, if you want side-effects, you should
use s e t f with the return value: (setf lst (delete 'a lst))

   202

   STRUCTURE

   As an example of how destructive functions recycle the lists
passed to them, consider nconc, the destructive version of append. 2
This twoargument version shows clearly how two existing lists are
sewn together:

   (defun nconc2 (x y) (if (consp x) (progn (setf (cdr (last x)) y)
x) y» We go to the last cons cell in the first list, and set its cdr
to point to the second list. A proper multi-argument nconc could be
defined as in Appendix B. The function mapcan is like mapcar, but
splices together the values returned by the function (which must be
lists) using nconc: > (mapcan #;list '(a b c) '(1 2 3 4)) (A 1 B 2 C
3) This function might be defined as follows: (defun our-mapcan (fn
ferest l s t s ) (apply #'nconc (apply #'inapcar fn l s t s ))) Use
mapcan with caution, because it is destructive. It splices together
the returned lists with nconc, so they had better not be needed
elsewhere. This kind of function is particularly useful in problems
that can be understood as collecting all the nodes at one level of
some tree. For example, if c h i l d r e n returns a list of
someone's children, then we could define a function to return a list
of someone's grandchildren as follows: (defun grandchildren (x)
(mapcan #'(lambda (c) (copy-list (children c))) (children x))) This
function calls c o p y - LIST on the assumption that c h i l d r e n
returns a list that's stored somewhere, instead of making a fresh
one. A nondestructive variant of mapcan might be defined: (defun
mappend (fn &rest l s t s ) (apply #'append (apply #'mapcar fn l s t
s ))) 2 The n originally stood for "non-consing." Several destructive
functions have names beginning with n.

   12.5

   EXAMPLE: BINARY SEARCH TREES

   203

   (defun bst-insert! (obj bst <) (if (null bst) (make-node :elt obj)
(progn (bsti obj bst <) bst))) (defun bsti (obj bst <) (let ((elt
(node-elt bst))) (if (eql obj elt) bst (if (funcall < obj elt) (let
((1 (node-1 bst))) (if 1 (bsti obj 1 <) (setf (node-1 bst) (make-node
:elt obj)))) (let ((r (node-r bst))) (if r (bsti obj r <) (setf
(node-r bst) (make-node :elt obj))))))))

   Figure 12.8: Binary search trees: Destructive insertion.

   If we used mappend, we could leave out the c o p y - LIST in the
definition of grandchildren: (defun grandchildren (x) (mappend
#'children (children x)))


File: long-ANSI-sample.info,  Node: Example-- Binary Search Trees II,  Next: Example-- Doubly-Linked Lists,  Prev: Destructive Functions,  Up: Structure

12.6 Example- Binary Search Trees II
====================================

In some situations it's more natural to use destructive operations
than nondestructive ones. Section 4.7 showed how to maintain a sorted
collection of objects in a binary search tree, or BST. The functions
given in Section 4.7 were all nondestructive, but in the situations
where we would actually use BSTS, this is a needless precaution. This
section shows how to define destructive insertion and deletion
functions that are more likely to be useful in practice. Figure 12.8
shows how to define a destructive version of b s t - i n s e r t
(page 72). It takes the same arguments and has the same return value.
The only difference is that it may modify the BST given as the second
argument.

   204

   STRUCTURE

   As Section 2.12 warned, being destructive doesn't mean that a
function is meant to be called for side-effects. And indeed, if you
want to build a BST using b s t - i n s e r t ! , you have to call it
the same way you would call the original b s t - i n s e r t : >
(setf *bst* nil) NIL > (dolist (x ' ( 7 2 9 8 4 1 5 12)) (setf *bst*
(bst-insert! x *bst* #'<))) NIL You could define an analogue of push
for BSTs, but the techniques for doing so are beyond the scope of
this book. (For the curious, this macro is defined on page 409.°)
Figure 12.9 contains a destructive b s t - d e l e t e , which is to
bst-remove (page 74) as d e l e t e is to remove. And like d e l e t
e , it's not meant to be called for side-effects. You should call b s
t - d e l e t e as you would call bst-remove: > ( s e t f *bst* ( b s
t - d e l e t e 2 *bst* # ' < )) #<7> > ( b s t - f i n d 2 *bst*
#'<) NIL


File: long-ANSI-sample.info,  Node: Example-- Doubly-Linked Lists,  Next: Circular Structure,  Prev: Example-- Binary Search Trees II,  Up: Structure

12.7 Example- Doubly-Linked Lists
=================================

Ordinary Lisp lists are singly linked lists, meaning that the
pointers go in one direction: you can get to the next element, but
not the preceding one. In a doubly linked list, the pointers go in
both directions, so you can go backward as well as forward. This
section shows how to create and manipulate doubly linked lists.
Figure 12.10 shows how to implement doubly linked lists using
structures. Considered as a structure, a cons has two fields: the
car, which points to the data, and the cdr, which points to the next
element. To represent an element in a doubly linked list we will need
a third field, to point to the preceding element. The def s t r u c t
in Figure 12.10 defines a three-part object called a d l (for "doubly
linked") that we will use to build doubly linked lists. The d a t a
field of a d l corresponds to the car of a cons, and the r e s t
field to the cdr. The prev field will be like a cdr that goes in the
other direction. (Figure 12.11 shows a doubly linked list of three
elements.) The empty doubly linked list will be NIL , just like the
empty list. By this call to def s t r u c t we define functions
corresponding to car, cdr and consp for doubly linked lists: d l - d
a t a , d l - n e x t , and d l - p . The print-

   12.6

   EXAMPLE: DOUBLY-LINKED LISTS

   205

   (defun bst-delete (obj bst <) (if bst (bstd obj bst nil nil <))
bst) (defun bstd (obj bst prev dir <) (let ((elt (node-elt bst))) (if
(eql elt obj) (let ((rest (percolate! bst))) (case dir ( : 1 (setf
(node-1 prev) rest)) ( : r (setf (node-r prev) rest)))) (if (funcall
< obj elt) (if (node-1 bst) (bstd obj (node-1 bst) bst :1 <)) (if
(node-r bst) (bstd obj (node-r bst) bst :r <)))))) (defun percolate!
(bst) (cond ((null (node-1 bst)) (if (null (node-r bst)) nil (rperc!
bst))) ((null (node-r bst)) (lperc! bst)) (t (if (zerop (random 2))
(lperc! bst) (rperc! bst))))) (defun lperc! (bst) (setf (node-elt
bst) (node-elt (node-1 bst))) (percolate! (node-1 bst))) (defun
rperc! (bst) (setf (node-elt bst) (node-elt (node-r bst)))
(percolate! (node-r bst))) Figure 12.9: Binary search trees:
Destructive deletion.

   function for dls calls d l - > LIST , which returns an ordinary
list containing the elements of a dl. The function d l - i n s e r t
is like cons for doubly linked lists. At least, it's like cons in
that it is the basic constructor function. It's unlike cons

   206

   STRUCTURE

   (defstruct (dl (:print-function print-dl)) prev data next) (defun
print-dl (dl stream depth) (declare (ignore depth)) (format stream
"#<DL ~A>" (dl->list dl))) (defun dl->list (lst) (if (dl-p lst) (cons
(dl-data lst) (dl->list (dl-next lst))) lst)) (defun dl-insert (x
lst) (let ((elt (make-dl :data x :next lst))) (when (dl-p lst) (if
(dl-prev lst) (setf (dl-next (dl-prev lst)) elt (dl-prev elt)
(dl-prev lst))) (setf (dl-prev lst) elt)) elt)) (defun dl-list
(forest args) (reduce #'dl-insert args :from-end t :initial-value
nil)) (defun dl-remove (lst) (if (dl-prev lst) (setf (dl-next
(dl-prev lst)) (dl-next lst))) (if (dl-next lst) (setf (dl-prev
(dl-next lst)) (dl-prev lst))) (dl-next lst))

   Figure 12.10: Building doubly linked lists.

   in that it actually modifies the doubly linked list passed to it
as the second argument. In this situation it is the most natural
thing to do. You don't have to do anything to the rest of an ordinary
list to cons something onto it, but if you want to put something on
the front of a doubly linked list, you have to make the prev field of
the rest of the list point back to the new element. To put it another
way, several normal lists can share the same tail. But in doubly
linked lists the tails have to point back at the structure that
precedes

   72.7

   EXAMPLE: DOUBLY-LINKED LISTS

   207

   nil

   nil

   f

   a

   t

   b

   *

   c

   Figure 12.11: A doubly linked list.

   them, so no two doubly linked lists can have the same tail. If d l
- i n s e r t weren't destructive, it would always have to copy its
second argument. Another interesting difference between singly and
doubly linked lists is how you hold them. You hold a singly linked
list by the front; when you set a variable to a list, it has a
pointer to the first cons. But since a doubly linked list is
connected in both directions, you can hold it at any point. So d l -
i n s e r t is also unlike cons in that it can put a new element
anywhere in a doubly linked list, not just on the front. The function
d l - LIST is the d l analogue of LIST . You give it any number of
arguments and it returns a d l containing them: > ( d l - LIST ' a '
b >c) #<DL (A B C)> It uses reduce, which, with :from-end true and an
: i n i t i a l - v a l u e of NIL , makes the preceding call
equivalent to ( d l - i n s e r t 'a ( d l - i n s e r t 'b ( d l - i
n s e r t ' c NIL ))) If you replaced # ' d l - i n s e r t in the
definition of d l - LIST with # ' cons, it would behave like LIST .
Here is the new code in use: > (setf d l ( d l - LIST ' a >b)) #<DL
(A B)> > (setf dl (dl-insert >c dl)) #<DL (C A B)> > (dl-insert 'r
(dl-next dl)) #<DL (R A B)> > dl #<DL (C R A B)> Finally, dl-remove
is for removing an element from a doubly linked list. Like d l - i n
s e r t , it makes sense for it to be destructive.

   208

   STRUCTURE

   J a Figure 12.12: Circular lists.


File: long-ANSI-sample.info,  Node: Circular Structure,  Next: Constant Structure,  Prev: Example-- Doubly-Linked Lists,  Up: Structure

12.8 Circular Structure
=======================

By modifying list structure it's possible to create circular lists.
There are two kinds of circular lists. The more useful kind are those
whose top-level list structure is a loop. Such lists are called
cdr-circular because the loop passes through the cdr part of a cons.
To make a cdr-circular list with one element, you set the cdr of a
list to be the list itself: > (setf x (list 'a)) (A) > (progn (setf
(cdr x) x) nil) NIL At this point x is a circular list, with the
structure shown in Figure 12.12. If Lisp tried to print the list we
just created, it would usually display (a a a a a, ad infinitum. But
if we set the global * p r i n t - c i r c l e * to t, objects will
be displayed in a way that can represent circular structure:

   > (setf *print-circle* t ) T > x #1=(A . #1#) If you need to, you
can use the #n= and #n# read-macros to represent shared structure
yourself. Cdr-circular lists could be useful-to represent buffers or
pools, for example. The following function would take any
non-cdr-circular, nonempty list and convert it into a cdr-circular
list with the same elements: (defun circular (lst) (setf (cdr (last
lst)) lst))

   12.7

   CIRCULAR STRUCTURE

   209

   The other kind of circular lists are car-circular lists. A
car-circular list is a tree that has itself as a subtree. They are so
called because the loop passes through the car of some cons. Here we
create a car-circular list whose second element is itself: > (let ((y
( LIST >a ))) (setf (car y) y) y) #i=(#i#) Figure 12.12 shows the
resulting structure. Though car-circular, this list is a proper list.
Cdr-circular lists are never proper lists, but car-circular lists can
be, unless they are disqualified for some other reason. A list could
be both car- and cdr-circular. The car and the cdr of this cons will
be the cons itself: > (let ( ( c (cons 1 1 ))) (setf (car c) c (cdr
c) c) c) #1=(#1# . #1#) It's hard to imagine what the use of such an
object would be. Indeed, the main reason to know about circular lists
may be to avoid creating them by accident, because most functions
that traverse list structure will go into an infinite loop if they
are given a list that's circular in the dimension they traverse.
Circular structure can be an issue for other kinds of objects besides
lists. For example, an array can contain itself as an element:

   > (setf *print-array* t ) T

   > (let ( ( a (make-array 1 ))) (setf (aref a 0) a) a) #1=#(#1#)
Indeed, just about anything that can have elements can have itself as
an element. It's quite common to have circularities involving
structures created by def s t r u c t . For example, a structure c
representing an element in a tree might have a parent field that
contained another structure/? whose c h i l d field in turn contained
c:

   210

   STRUCTURE

   > (progn ( d e f s t r u c t e l t (parent NIL ) ( c h i l d NIL
)) (let ( ( c (make-elt)) (p ( m a k e - e l t ))) ( s e t f (elt - p
a r e n t c) p (elt - c h i l d p) c) c)) #1=#S(ELT PARENT #S(ELT
PARENT NIL CHILD #1#) CHILD NIL) In the p r i n t - f u n c t i o n
of such a structure, you would either want to bind · p r i n t - c i
r c l e * to t , or avoid printing the values of the fields through
which cycles might pass.


File: long-ANSI-sample.info,  Node: Constant Structure,  Prev: Circular Structure,  Up: Structure

12.9 Constant Structure
=======================

Because constants are effectively part of the code in which they
occur, it is also important not to modify them, or you may
inadvertently create selfrewriting programs. A quoted list is a
constant, so you should be careful not to modify any cons that was
ever part of a quoted list in the text of a program. For example, if
we use the following predicate to test whether something is an
arithmetic operator, (defun arith-op (x) (member x '(+ - * /))) then
its return value, if true, will incorporate at least part of a quoted
list. If we modify the return value, > (nconc ( a r i t h - o p '*) '
( a s i t were)) (* / AS IT WERE) then we could be modifying the list
within a r i t h - o p , and thereby changing what the function does:
> (arith-op 'as) (AS IT WERE) It is not necessarily an error to write
a function that returns constant structure. But when you are
considering whether it's safe to perform destructive operations on
something, you must certainly take this into account. There are
several ways to write a r i t h - o p so that it doesn't return part
of a quoted list. In the general case, you can ensure safety by
replacing any quoted list with a call to LIST , which returns a new
list each time:

   SUMMARY

   211

   (defun arith-op (x) (member x (list ;+ '-

   '* V)))

   In this case, calling LIST is an inefficient solution. You would
be better off using find instead of member: (defnn arith-op (x) (find
x >(+ - * /))) The problem described in this section is most likely
to happen with lists, but it could happen with complex objects of any
type: arrays, strings, structures, instances, and so on. You
shouldn't modify anything that occurs literally in the text of a
program. Even if you want to write self-modifying programs, modifying
constants is not the way to do it. The compiler can wire constants
into the code, and destructive operators can modify their arguments,
but neither is guaranteed. The way to write self-modifying programs,
if that's what you want, is to use closures (Section 6.5).

   Summary 1. Two lists can share a tail. Lists can share structure
as trees without sharing top-level list structure. Shared structure
can be avoided by copying. 2. Shared structure can usually be
ignored, but it must be considered if you are going to modify lists.
Modifying one list can modify other lists that share structure with
it. 3. Queues can be represented as conses in which the car points to
the first cons in a list and the cdr to the last. 4. For reasons of
efficiency, destructive functions are allowed to modify their
arguments. 5. In some applications, destructive implementations are
the most natural. 6. Lists can be car- or cdr-circular. Lisp can
represent circular and shared structure. 7. Constants occurring in
the text of a program should not be modified.

   212

   STRUCTURE

   Exercises 1. Draw three different trees that would print as ((A)
(A) (A)). Write an expression that generates each. 2. Assuming
make-queue, enqueue, and dequeue are defined as in Figure 12.7, draw
the queue in box-notation after each step: > (setf q (make-queue))
(NIL) > (enqueue ' a q) (A) > (enqueue ' b q) (A B) > (dequeue q) A

   3. Define a function copy-queue that returns a copy of a queue. 4.
Define a function that takes an object and a queue, and puts the
object on the front of the queue. 5. Define a function that takes an
object and a queue, and (destructively) moves the first (eql)
instance of the object to the front of the queue. 6. Define a
function that takes an object and a possibly cdr-circular list, and
returns true if the object is a member of the list. 7. Define a
function that returns true when its argument is a cdr-circular list.
8. Define a function that returns true when its argument is a
car-circular list.


File: long-ANSI-sample.info,  Node: Speed,  Next: Advanced Topics,  Prev: Structure,  Up: Top

13 Speed
********

Lisp is really two languages: a language for writing fast programs and
a language for writing programs fast. In the early stages of a program
you can trade speed for convenience. Then once the structure of your
program begins to crystallize, you can refine critical portions to
make them faster.

   It's difficult to give general advice about optimization, because
of the variation between Common Lisp implementations. A change that
made your program faster in one implementation might make it slower in
another. This is something that comes with the territory. The more
powerful the language, the further you are from the machine, and the
further you are from the machine, the greater the chance that
different implementations will take different paths toward it. So
while there are some techniques that are almost certain to make your
programs faster, the aim of this chapter will be to suggest rather
than to prescribe.

* Menu:

* The Bottleneck Rule::
* Compilation II::
* Type Declarations::
* Garbage Avoidance::
* Example-- Pools::
* Fast Operators::
* Two-Phase Development::


File: long-ANSI-sample.info,  Node: The Bottleneck Rule,  Next: Compilation II,  Up: Speed

13.1 The Bottleneck Rule
========================

Three points can be made about optimization, regardless of the
implementation: it should be focused on bottlenecks, it should not
begin too early, and it should begin with algorithms. Probably the
most important thing to understand about optimization is that
programs tend to have a few bottlenecks that account for a great part
of the execution time. According to Knuth, "most of the running time
in non-iobound programs is concentrated in about 3% of the source
text."0 Optimizing these parts of the program will make it run
noticeably faster; optimizing the rest of the program will be a waste
of time in comparison. 213

   214

   SPEED

   So the crucial first step in optimizing any program is to find the
bottlenecks. Many Lisp implementations come with profilers that can
watch a program as it's running and report the amount of time spent
in each part. A profiler is a valuable tool-perhaps even a
necessity-in producing the most efficient code. If your Lisp
implementation provides one, use it to guide optimization. If not,
you are reduced to guessing where the bottlenecks are, and you might
be surprised how often such guesses turn out to be wrong. A corollary
of the bottleneck rule is that one should not put too much effort
into optimization early in a program's life. Knuth puts the point
even more strongly: "Premature optimization is the root of all evil
(or at least most of it) in programming."0 It's hard to see where the
real bottlenecks will be when you've just started writing a program,
so there's more chance you'll be wasting your time. Optimizations
also tend to make a program harder to change, so trying to write a
program and optimize it at the same time can be like trying to paint
a picture with paint that dries too fast. You end up with better
programs if each task can be emphasized at the appropriate time. One
of the benefits of Lisp is that it lets you work at a range of
different speeds: you can write slow code fast or fast code slow. In
the early stages of a program you tend to work in the former mode,
then as optimization takes precedence you switch into the latter. As
the bottleneck rule suggests, this is a more effective use of your
time. In a very low-level language, like assembler, you are
essentially optimizing every line of the program. Most of this effort
is wasted, because the bottlenecks only make up a small part of it. A
more abstract language allows you to spend a greater proportion of
your time on the bottlenecks, and so get most of the gains with a
fraction of the effort. When you do turn to optimization, begin at
the top. That is, make sure that you're using the most efficient
algorithm before you resort to low-level coding tricks. The potential
gains are greater-perhaps great enough that you won't have to resort
to coding tricks after all. This rule has to be balanced against the
preceding one, though. Sometimes decisions about algorithms have to
be made early.


File: long-ANSI-sample.info,  Node: Compilation II,  Next: Type Declarations,  Prev: The Bottleneck Rule,  Up: Speed

13.2 Compilation II
===================

Five parameters control the way your code is compiled: speed refers
to the speed of the code produced by the compiler; compilation-speed
refers to the speed at which your program will be compiled; s a f e t
y refers to the amount of error-checking done in the object code;
space refers to the size and memory needs of the object code; and
debug refers to the amount of information retained for debugging.

   13.2

   COMPILATION

   215

   INTERACTIVE VS. INTERPRETED

   Lisp is an interactive language, but a language does not have to
be interpreted to be interactive. Early Lisp implementations were
implemented by interpreters, and the idea arose that Lisp's unique
qualities depended on its being interpreted. This idea is mistaken:
Common Lisp is the same language compiled as it is interpreted. At
least two Common Lisp implementations do not even include
interpreters. In these implementations, expressions typed into the
toplevel are compiled before being evaluated. So it is not merely
old-fashioned to call the toplevel the "interpreter," it can be an
error of fact.

   The compilation parameters are not real variables. They are
assigned weights from 0 (unimportant) to 3 (most important) in
declarations. If a major bottleneck occurred in the inner loop of
some function, we might add a declaration like the following: (defun
b o t t l e n e c k ( . . . ) (do ( . . . ) (...) (do ( . . . ) (...)
( d e c l a r e (optimize (speed 3) ( s a f e t y 0 ))) ...)))
Generally you would not want to add such declarations until the code
was finished and tested. To ask globally for the fastest possible
code, regardless of the consequences, you could say: (declaim
(optimize (speed 3) (compilation-speed 0) ( s a f e t y 0) (debug 0
))) This would be a drastic step, and probably not even necessary,
given the bottleneck rule.1 One particularly important kind of
optimization done by Lisp compilers is the optimization of tail
calls. Giving speed the maximum weight will ensure tail call
optimization by any compiler capable of it.  'Older implementations
may not provide declaim; instead use proclaim and quote the argument.

   216

   SPEED

   A call is a tail call if nothing remains to be done after it
returns. The following function returns the length of a list: (defun
length/r (lst) (if (null lst) 0 (1+ (length/r (cdr lst)))))

   The recursive call is not a tail call, because after it returns,
its value has to be passed to 1+. However, this version is
tail-recursive, (defun length/tr (lst) (labels ((len (lst ace) (if
(null lst) ace (len (cdr lst) (1+ ace))))) (len lst 0)))

   or more precisely, the local function l e n is, because nothing
more has to happen after the recursive call returns. Instead of
building its return value on the way back up the recursion, like l e
n g t h / r , it accumulates the return value on the way down. Hence
the additional parameter ace, which can simply be returned at the end
of the last recursive call. A good compiler can compile a tail call
into a goto, and so can compile a tail-recursive function into a
loop.0 In typical machine language code, when control arrives for the
first time at the segment of instructions representing len, there is
information on the stack saying what to do upon returning. Because
nothing remains to be done after the recursive call, this information
remains valid for the second invocation as well: what we are supposed
to do on returning from the second invocation is simply to return
from the first invocation. So after setting the parameters to their
new values, we can just jump back to the beginning of the function
and act as if this were the second invocation. There is no need to do
a real function call. Another way to have the abstraction of function
calls without the cost is to have functions compiled inline. This is
valuable mainly for small functions, where the machinery of calling
the function could entail more work than the function itself
performs. For example, the following function tells whether something
is a list of a single element: (declaim (inline single?)) (defun
single? (lst) (and (consp lst) (null (cdr lst))))

   13.3

   TYPE DECLARATIONS

   217

   Because this function is globally declared inline, a reference to
s i n g l e ? within a compiled function should no longer require a
real function call.2 If we define a function that calls it, (defun
foo (x) (single? (bar x)))

   then when foo is compiled, the code for s i n g l e ? should be
compiled right into it, just as if we had written (defun foo (x) (let
( ( lst (bar x ))) (and (consp lst ) ( n u l l (cdr lst ))))) in the
first place. There are two limitations on inline compilation.
Recursive functions can't be inlined. And if an inlined function is
redefined, we have to recompile any function that calls it, or the
calling function will still reflect the old definition. In some
earlier dialects of Lisp, one used macros (Section 10.2) to avoid
function calls. In Common Lisp this is no longer supposed to be
necessary. Different Lisp compilers do varying amounts of
optimization. If you want to see the code your compiler produces for
a function, try calling disassemble. This function takes a function
or function name and displays its compiled form. Even if what you see
is completely incomprehensible, you can still use disassemble to
determine whether declarations are being used: compile two version of
the function, one with the declaration and one without, and see if
the code displayed by disassemble differs between the two. You can
use a similar technique to see if functions are being compiled
inline. In either case, be sure to set the compilation parameters
beforehand to get the fastest code.0


File: long-ANSI-sample.info,  Node: Type Declarations,  Next: Garbage Avoidance,  Prev: Compilation II,  Up: Speed

13.3 Type Declarations
======================

If you're learning Lisp as a second language, you may have been
puzzled by the omission up to this point of something that's de
rigueur in most other languages: type declarations. In most
languages, you have to declare the type of each variable, and the
variable can only hold values of that type. Such a language is said
to be strongly typed. As well as being a lot of work for the
programmer, this approach imposes restrictions on what you can do. In
such a language it's hard to write functions that work for different
kinds of arguments, or to have 2 For inline declarations to have an
effect, you may also have to set the compilation parameters to get
fast code.

   218

   SPEED

   data structures that contain different kinds of elements.0 The
advantage of this approach is that whenever the compiler sees an
addition, for example, it knows beforehand what kind of addition is
involved. If both arguments are integers, it can hard-wire an integer
addition in the object code. As Section 2.15 mentioned, Common Lisp
uses a more flexible approach called manifest typing.3 Values have
types, not variables. Variables can hold objects of any type. If we
left it at that, we would have to pay for this flexibility in speed.
Because it can take several different types of numbers, + would have
to look at the types of each of its arguments, and decide what kind
of addition to do at run-time. If we just want an integer addition
after all, this is an inefficient way to get it. So Common Lisp's
approach is: tell me as much as you know. If we know ahead of time
that both of the arguments in some addition will be fixnums, then we
can declare them to be such, and the compiler will hard-wire an
integer addition just as in C. So the difference between the two
approaches to typing need not entail any difference in speed. It's
just that the first approach makes type declarations mandatory, and
the second doesn't. In Common Lisp, type declarations are completely
optional. They may make a program faster, but (unless incorrect) they
will not change its behavior. Global declarations are made with
declaim, which should be followed by one or more declaration forms. A
type declaration is a list containing the symbol type, followed by a
type name and the names of one or more variables. So to declare the
type of a global variable, one could say: (declaim (type fixnum
*count*)) In ANSI Common Lisp you can omit the type and say simply:
(declaim (fixnum *count*)) Local declarations are made with d e c l a
r e , which takes the same arguments as declaim. Declarations can
begin any body of code where variables have just been created: in
defun, lambda, l e t , do, and so on. To declare a function's
parameters to be fixnums, for example, we would say: (defun poly (a b
x) (declare (fixnum a b x)) (+ ( * a (expt x 2)) ( * b x))) 3 There
are two ways to describe Lisp's approach to typing: by where the type
information is kept, and by when it is used. Manifest typing means
that the type information is attached to the data objects, and
run-time typing means that type information is used at run-time. In
practice they mean the same thing.

   13.3

   TYPE DECLARATIONS

   219

   A variable name in a type declaration refers to the variable with
that name in the context where the declaration occurs-to the variable
whose value would be altered if it were instead an assignment. You
can also declare that the value of an expression will be of a certain
type, by using the. If we know beforehand that a, b, and x will not
only be fixnums, but that they will be small enough fixnums that all
the intermediate results will be fixnums, we can say: (defun poly (a
b x) (declare (fixnum a b x)) (the fixnum (+ (the fixnum ( * a (the
fixnum (expt x 2)))) (the fixnum ( * b x))))) Looks a bit awkward,
doesn't it? Fortunately, there are two reasons that you rarely have
to clutter up your numeric code with thes in this way. One is that
it's easy to use macros to insert such declarations for you.° The
other is that some implementations use special tricks to make fixnum
arithmetic fast without declarations. There are a great many types in
Common Lisp-a potentially unlimited number, considering that you can
define new types yourself. However, declarations only matter for a
few. When does it pay to make type declarations? There are two
general rules: 1. It pays to declare the types of arguments to
functions that work for arguments of several different types (but not
all types). If you knew that the arguments in a call to + would
always be fixnums, or that the first argument in a call to aref would
always be a particular kind of array, it could pay to make a type
declaration. 2. It is usually only worthwhile to make declarations
for types near the bottom of the type hierarchy: declaring something
to be of type f ixnum or simple-array might be useful, but declaring
something to be of type i n t e g e r or sequence probably would not.
Type declarations are particularly important for the contents of
complex objects, including arrays, structures, and instances. Such
declarations can improve efficiency in two ways: as well as allowing
the compiler to determine the types of arguments to functions, they
make it possible to represent these objects more efficiently in
memory. If nothing is known about the type of elements an array will
contain, it has to be represented in memory as a block of pointers.
But if it is known that the array will only contain, say,
double-floats, then the array can be represented as a block of actual
double-floats. This way the array will take less space, because we no
longer need a pointer to point to each of the double-floats, and

   220

   SPEED

   -CH

   1

   \

   N

   N

   N 2.345d0 3.456d0 2.345d0 3.456d0 1.234d0

   ' -c::r i 1.234d0

   Figure 13.1: Effect of specifying element type.

   access will be faster, because we don't have to follow pointers to
read and write elements. You can specify the kind of values that an
array will contain by giving the : element-type argument to
make-array. Such an an array is called a specialized array. Figure
13.1 shows what would happen, in most implementations, as a result of
evaluating the following code: ( s e t f x (vector 1.234d0 2.345d0
3.456d0) y (make-array 3 :element-type ' d o u b l e - f l o a t )
(aref y 0) 1.234d0 (aref y 1) 2.345d0 (aref y 2) 3.456d0) Each
rectangle in Figure 13.1 represents a word of memory. The two arrays
each consist of a header of unspecified length, followed by some
representation of the three elements. In x, each element is
represented by a pointer. All three pointers happen to point to
double-floats at the moment, but we could store objects of any type
in this vector. In y, each element is an actual double-float. This is
faster and takes less space, but it means that the vector can only
hold double-floats. Note that we use aref to refer to the elements of
y. A specialized vector is no longer a simple vector, so we can no
longer use svref to refer to its elements. As well as specifying the
element type of an array when you create it, you should declare the
dimensions and element type of an array in code that uses it. A full
vector declaration would look like: (declare (type (vector fixnum 20)
v)) This declares v to be a vector of length 20, specialized for
fixnums.

   133

   TYPE DECLARATIONS

   221

   (setf a (make-array '(1000 1000) :element-type ' s i n g l e - f l
o a t : i n i t i a l - e l e m e n t l.OsO)) (defun sum-elts (a) ( d
e c l a r e (type ( s i m p l e - a r r a y s i n g l e - f l o a t
a)) (let ((sum 0.0s0)) (declare (type s i n g l e - f l o a t sum))
(dotimes (r 1000) (dotimes (c 1000) (incf sum (aref a r c )))) sum))
Figure 13.2: Summing an array.

   (1000 1000))

   The most general form of array declaration consists of the array
type followed by the element type and a list of dimensions: (declare
(type (simple-array fixnum (4 4)) ar))

   This declares that a r will be a 4 x 4 simple array specialized
for fixnums. Figure 13.2 shows how to create a lOOOx 1000 array of
single-floats, and how to write a function to sum the elements of
such an array. Arrays are stored in row-major order and should be
traversed that way when possible. We will use t ime to compare the
performance of sum-elt s with and without declarations. The t ime
macro displays some (implementation-dependent) measure of how long it
takes to evaluate an expression. It's only meaningful to time
compiled functions. In one implementation, if we compile sum-elts
with the compilation parameters set to get the fastest code, it
returns in less than half a second: > (time (sum-elts a )) User Run
Time = 0 . 4 3 seconds 1000000.0

   If we take the type declarations out of sum-elts and recompile it,
the same computation takes more than five seconds: > (time (sum-elts
a)) User Run Time = 5 . 1 7 seconds 1000000.0

   222

   SPEED

   The importance of type declarations, especially for arrays and
numbers, cannot be overemphasized. Here, two lines of code make
sum-elts twelve times faster.


File: long-ANSI-sample.info,  Node: Garbage Avoidance,  Next: Example-- Pools,  Prev: Type Declarations,  Up: Speed

13.4 Garbage Avoidance
======================

As Lisp allows you to delay thinking about the types of variables, it
also allows you to delay thinking about memory allocation. In the
early stages of a program it frees your imagination not to have to
think about (or deal with bugs involving) memory allocation. As a
program matures, it can rely less on dynamic allocation and so become
faster. However, consing less does not always make a program faster.
In Lisp implementations with bad garbage collectors, programs that
cons a lot tend to run slowly. Until recently, most Lisp
implementations have had bad garbage collectors, and so it has become
a tradition that efficient programs should cons as little as
possible. Recent developments have turned this conventional wisdom on
its head. Some implementations now have such sophisticated garbage
collectors that it is faster to cons up new objects and throw them
away than it is to recycle them. This section introduces some ways to
make programs cons less. Whether consing less will make your programs
run faster depends on the implementation. Again, the best advice is
to try it and see. There are a lot of things you can do to reduce
consing. Some of them won't affect the shape of your program at all.
For example, one of the easiest steps you can take is to use
destructive functions. The following table lists some commonly used
functions and their destructive counterparts.

   [ SAFE append reverse remove remove-if remove-duplicates subst
subst-if union intersection set-difference DESTRUCTIVE nconc nreverse
delete delete-if delete-duplicates nsubst nsubst-if nunion
nintersection nset-difference .

   When you know it's safe to modify a list, you can use d e l e t e
instead of remove, n r e v e r s e instead of r e v e r s e , and so
on. If you want to eliminate consing entirely, you don't have to give
up the possibility of creating things on the fly. What you have to
avoid is allocating

   13.4

   GARBAGE AVOIDANCE

   223

   space for them on the fly, and reclaiming it by garbage
collection. The general solution is to allocate blocks of memory
beforehand, and explicitly recycle used blocks yourself. Beforehand
could mean at compile-time, or in some initialization routine. When
speed begins to matter depends on the application. For example, when
circumstances allow us to impose a limit on the size of a stack, we
could have the stack grow and shrink along a pre-allocated vector,
instead of building it out of conses. Common Lisp has built-in
support for using vectors as stacks. If we give the optional f i l l
- p o i n t e r argument to make-array, we will get a vector that
seems to be expandable. The first argument to make-array specifies
the amount of storage to be allocated for the vector, but the f i l l
- p o i n t e r , when given, specifies the initial effective length:
> (setf *print-array* t) T > (setf vec (make-array 10 -.fill-pointer
2 :initial-element nil)) #(NIL NIL)

   The vector we just made will seem to sequence functions as if it
had only two elements, > (length vec) 2 but it will be able to grow
until it has up to ten. Because vec has a fill pointer, we can use
the functions vector-push and vector-pop to push and pop elements as
if it were a list: > (vector-push 'a vec) 2 > vec #(NIL NIL A) >
(vector-pop vec) A > vec #(NIL NIL)

   When we called vector-push, it incremented the fill pointer and
returned its old value. As long as the fill pointer is less than the
initial argument to make-array, we can push new elements onto the
vector; when it runs out of space, vector-push will return NIL . We
could push up to eight more elements onto vec at this point.

   224

   SPEED

   (defconstant d i e t (make-array 25000 : f i l l - p o i n t e r
0)) (defun read-words (from) ( s e t f ( f i l l - p o i n t e r d i
e t ) 0) ( w i t h - o p e n - f i l e ( i n from : d i r e c t i o n
:input) (do ((w ( r e a d - l i n e i n NIL :eof) (read-line in NIL
:eof))) ( ( e q l w :eof)) (vector-push w d i e t )))) (defun xform
(fn seq) (map-into seq fn seq)) (defun write-words (to) ( w i t h - o
p e n - f i l e (out t o

   : d i r e c t i o n :output : i f - e x i s t s .·supersede)

   (map NIL #'(lambda (x) ( f r e s h - l i n e out) (princ x out))
(xform U n r e v e r s e ( s o r t (xform U n r e v e r s e d i e t )
#'string<))))) Figure 3.3: Generating a rhyming dictionary.

   One disadvantage of vectors with fill pointers is that they are no
longer simple vectors. We have to use aref instead of svref to refer
to elements. This, cost has to be balanced against the potential
gains. In applications that involve very long sequences, you may want
to use map-into instead of map. Instead of a sequence type, map-into
takes as its first argument an actual sequence to hold the result.
This sequence can be one of those from which the arguments to the
function are taken. So, for example, if you want to increment each
element of a vector v, you might write: ( s e t f v (map-into v #'1+
v)) Figure 13.3 shows an example of an application that uses a large
vector: a program to generate a simple rhyming dictionary (or more
precisely, a dictionary of sight rhymes). The function read-words
reads words from a file containing one per line,0 and the function
write-words prints them out in reverse alphabetical order. That is,
the output might begin with a amoeba alba samba marimba...

   13.4 and end with

   GARBAGE AVOIDANCE

   225

   ...megahertz gigahertz jazz buzz fuzz

   By taking advantage of fill-pointers and map- into* we can write
this program in a way that's both simple and efficient. In numeric
applications, be careful of bignums. Bignum arithmetic conses, as
well as being inherently slower. But even if your program must return
bignums in the end, you may be able to make it more efficient by
arranging that intermediate results are usually fixnums. Another way
to avoid garbage collection is to encourage the compiler to allocate
objects on the stack instead of the heap. When you know that you will
only need something temporarily, you may be able to avoid allocating
space for it on the heap by declaring it to have dynamic extent. By
giving a dynamic extent declaration for a variable, you're saying
that the variable's value need not last any longer than the variable
does. When could the value last longer than the variable? Here's an
example: (defun o u r - r e v e r s e ( lst ) (let ((rev NIL )) ( d o
LIST (x lst ) (push x r e v )) rev)) In o u r - r e v e r s e , the
list passed as an argument will be accumulated in reverse order in
rev. When the function returns, the variable rev will go away.
However, the list that is its value will persist: it is sent back to
the calling function, where who knows what fate awaits it. In
contrast, consider the following implementation of adj oin: (defun
our-adjoin (obj lst &rest args) (if (apply t'member obj lst args) lst
(cons obj lst ))) In this case, we can see from the definition of the
function that the list in args is going nowhere. It need not last
longer than the variable itself. This is the kind of situation where
it would make sense to make a dynamic extent declaration. If we add
such a declaration, (defun our-adjoin (obj lst ferest args) (declare
(dynamic-extent args)) (if (apply #'member obj lst args) lst (cons
obj lst)))

   226

   SPEED

   (defparameter *harbor* nil) (defstruct ship name flag tons) (defun
enter (n f d) (push (make-ship :name n :flag f :tons d) *harbor*))
(defun find-ship (n) (find n *harbor* :key #'ship-name)) (defun leave
(n) (setf *harbor* (delete (find-ship n) *harbor*))) Figure 13.4:
Harbor.

   then the compiler is free (but not required) to allocate space for
args on the stack, where it will be automatically discarded on return
from our-adjoin.


File: long-ANSI-sample.info,  Node: Example-- Pools,  Next: Fast Operators,  Prev: Garbage Avoidance,  Up: Speed

13.5 Example- Pools
===================

In applications that involve data structures, you can avoid dynamic
allocation by pre-allocating a certain number of them in a pool. When
you need a structure, you get one from the pool, and when you're
finished with one, you send it back to the pool.0 To illustrate the
use of pools, we'll write a quick prototype of a program to keep
track of the ships in a harbor, and then rewrite it to use a pool.
Figure 13.4 contains the first version. The global *harbor* will be a
list of ships, each represented by a ship structure. The function e n
t e r is called when a ship enters the harbor; f i n d - s h i p
finds a ship with a given name (if there is one); and leave is called
when a ship leaves the harbor. This would be a perfectly good way to
write the initial version of a program, but it will generate a lot of
garbage. As this program runs it will cons in two ways: new
structures will have to be allocated as ships enter the harbor, and
new conses will have to be made as *harbor* grows. We can eliminate
both sources of consing by allocating the space at compile-time.
Figure 13.5 contains a second version of the program that shouldn't
cons at all.

   13.6

   EXAMPLE: POOLS

   227

   (defconstant pool (make-array 1000 :f ill-pointer t)) (dotimes (i
1000) (setf (aref pool i) (make-ship))) (defconstant harbor
(make-hash-table :size 1100 :test # ; eq)) (defun enter (n f d) (let
((s (if (plusp (length pool)) (vector-pop pool) (make-ship)))) (setf
(ship-name s) n (ship-flag s) f (ship-tons s) d (gethash n harbor)
s))) (defun find-ship (n) (gethash n harbor)) (defun leave (n) (let
((s (gethash n harbor))) (remhash n harbor) (vector-push s pool)))
Figure 13.5: Harbor, version 2.

   Strictly speaking, the new version does cons, just not at
run-time. In the second version, harbor is a hash table instead of a
list, so all the space for it will be allocated at compile-time. A
thousand ship structures will also be created at compile-time, and
stored in the vector pool. (If the : f i l l - p o i n t e r argument
is t, the fill pointer points to the end of the vector.) Now when e n
t e r needs a new structure, it gets one from the pool instead of
calling make-ship. And when leave removes a ship from harbor, instead
of being thrown away, it is sent back to the pool. What we're doing
by using pools is taking over the job of memory management. Whether
this actually makes our program run faster depends on how our Lisp
implementation manages memory. Generally speaking, it pays to use
pools only in implementations with primitive garbage collectors, or
in real-time applications where the unpredictability of GC would be a
problem.

   228

   SPEED


File: long-ANSI-sample.info,  Node: Fast Operators,  Next: Two-Phase Development,  Prev: Example-- Pools,  Up: Speed

13.6 Fast Operators
===================

The beginning of this chapter described Lisp as two different
languages. In one sense this is literally true. If you look closely
at the design of Common Lisp, you can see that some features are
intended mainly for speed, and others mainly for convenience. For
example, there are three functions you could use to retrieve the
element at a given position in a vector: e l t , aref, and svref.
Such variety exists to allow you to squeeze as much performance out
of a program as possible. So if you can use svref, do. Conversely, a
part of a program where speed is important probably should not be
calling e l t , which works for both arrays and lists. Instead of
calling e l t on a list, you can call nth, which is specifically for
lists. Yet there is only a single function, length, for finding the
length of any sequence. Why doesn't Common Lisp provide a separate
version for lists? Because if your program is finding the lengths of
lists, it's already lost, as far as speed is concerned. In this case,
as in many others, the design of the language suggests what is fast
and what isn't. Another pair of similar functions are eql and eq. The
former is the default predicate for testing identity, but the latter
is faster if you know that the arguments won't be characters or
numbers. Two objects are eq when they have the same location in
memory. Numbers and characters may not be associated with any
particular memory location, so eq does not apply to them (though in
most implementations it does work for fixnums). For arguments of any
other kind, eq will return the same value as eql. It's always fastest
to compare objects using eq, because all Lisp has to do is compare
the pointers to them. So eq hash tables (as in Figure 13.5) should
offer the fastest access. In an eq hash table, gethash can just hash
on pointers, without even looking at what they point to. Access is
not the only thing to consider, however; eq and e q l hash tables
incur extra costs under copying garbage collection algorithms because
they have to be rehashed after a GC. If this becomes a problem, the
best solution may be to use an eql hash table with fixnums as keys.
Calling reduce can be a more efficient alternative to apply when the
function in question has a rest parameter. For example, instead of
something like (apply #'+ ' ( 1 2 3)) it can be more efficient to
say: (reduce #'+ ' (1 2 3)) Not only does it help to call the right
functions, it helps to call them the right way. Rest, optional, and
keyword parameters are expensive. With

   13.7

   TWO-PHASE DEVELOPMENT

   229

   ordinary parameters, the arguments in a function call are simply
left by the caller where the callee knows to look for them. But other
kinds of parameters involve processing at run-time. Keyword
parameters are the worst. For builtin functions, good compilers take
special measures to compile calls with keyword arguments into fast
code. But in your own functions it is just as well to avoid using
them in speed-critical parts of a program. It is also wise not to
push large numbers of arguments into rest parameters, if this can be
avoided. Individual compilers sometimes perform their own particular
optimizations. For example, some compilers can optimize case
statements where the keys are integers in a narrow range. Check your
user's manual for hints about such implementation-specific
optimizations.


File: long-ANSI-sample.info,  Node: Two-Phase Development,  Prev: Fast Operators,  Up: Speed

13.7 Two-Phase Development
==========================

In applications where speed is paramount, you may want to rewrite
part of a Lisp program in a lower-level language like C or assembler.
You can use this technique with programs written in any
language-critical parts of C programs are often rewritten in
assembler-but the more abstract the language, the greater the
benefits of developing programs in two phases. Common Lisp does not
prescribe a way of integrating code written in other languages. This
is left up to the implementation, but almost all implementations
provide some way to do it. It may seem wasteful to write a program in
one language and then to rewrite part of it in another. In fact,
experience has shown this to be a good way to develop software. It
can be easier to aim for functionality first, and then for speed,
than to try to achieve both at the same time. If programming were an
entirely mechanical process-a matter of simply translating
specifications into code-it would be reasonable to do everything in a
single step. But programming is never like that. No matter how
precise the specifications, programming always involves a certain
amount of exploration-usually a lot more than anyone had anticipated.
It might seem that if the specifications were good, programming would
simply be a matter of translating them into code. This is a
widespread misconception. Programming necessarily involves
exploration, because specifications are necessarily vague. If they
weren't vague, they wouldn't be specifications. In other fields, it
may be desirable for specifications to be as precise as possible. If
you're asking for a piece of metal to be cut to a certain shape, it's
probably best to say exactly what you want. But this rule does not
extend to software, because programs and specifications are made out
of the same thing: text. You can't write specifications that say
exactly what you want. If the specifications were that precise, then
they would be the program.0

   230

   SPEED

   In applications that involve a substantial amount of exploration
(and again, more do than anyone admits), it can pay to separate
implementation into two phases. And the medium you use in the first
phase need not be the final one. For example, the standard way to
make bronze sculptures is to begin with clay. You build a sculpture
out of clay first, and then use that to make a mold in which the
bronze sculpture is cast.0 No clay remains in the final sculpture,
but you can see its effect in the shape of the bronze. Imagine how
much more difficult it would be to produce the same thing starting
with a lump of bronze and a chisel. For the same reasons, it can be
better to write a program in Lisp, and then rewrite it in C, than to
try to write it in C from the start.

   Summary 1. Optimization should not begin too early, should be
focused on bottlenecks, and should begin with algorithms.  2. Five
parameters control compilation. They can be set with local or global
declarations.  3. A good compiler can optimize tail calls, turning a
tail-recursive function into a loop. Inline compilation is another
way to avoid function calls.  4. Type declarations are not necessary,
but they can make a program more efficient. Type declarations are
especially important in numeric code, and code that deals with arrays.
5. Consing less can make a program faster, especially in
implementations with primitive garbage collectors. Solutions include
using destructive functions, pre-allocating blocks of space, and
stack allocation.  6. In some situations, it might pay to draw
objects from a pre-allocated pool.  7. Some parts of Common Lisp are
designed for speed and others for flexibility.  8. Programming
necessarily involves exploration. Exploration and optimization should
be separated-sometimes even to the extent of using different
languages for each.

   Exercises 1. Test whether your compiler observes inline
declarations.

   13.7

   EXERCISES

   231

   2. Rewrite the following function to be tail-recursive. How much
faster is it when compiled? (defun foo (x) (if (zerop x) 0 (+ 1 (foo
(1- x))))) Note: you will have to add another parameter. 3. Add
declarations to the following programs. How much faster can you make
them? (a) The date arithmetic code in Section 5.7. (b) The ray-tracer
in Section 9.8. 4. Rewrite the breadth-first search code in Section
3.15 so that it conses as little as possible. 5. Modify the binary
search tree code in Section 4.7 to use pools.


File: long-ANSI-sample.info,  Node: Advanced Topics,  Next: Example-- Inference,  Prev: Speed,  Up: Top

14 Advanced Topics
******************

This chapter is optional. It describes a selection of the more
esoteric features of Common Lisp. Common Lisp is like an iceberg: a
great part of its functionality is invisible to most users, who never
need it. You may never need to define packages or read-macros of your
own, but when you do, it is helpful to have examples to work from.

* Menu:

* Type Specifiers::
* Binary Streams::
* Read-Macros::
* Packages::
* The Loop Facility::
* Conditions::


File: long-ANSI-sample.info,  Node: Type Specifiers,  Next: Binary Streams,  Up: Advanced Topics

14.1 Type Specifiers
====================

lypes are not objects in Common Lisp. There is no object that
corresponds to the type i n t e g e r , for example. What we get from
a function like type-of, and give as an argument to a function like
typep, is not a type, but a type specifier. A type specifier is the
name of a type. The simplest type specifiers are symbols like i n t e
g e r . These form a hierarchy in Common Lisp. At the top of the
hierarchy is the type t-all objects are of type t . The hierarchy is
not a tree. There are two paths from NIL to the top, for example: one
through atom, and the other through LIST and sequence. A type is
really just a set of objects. Which means that there are as many
types as there are sets of objects: an infinite number. We can denote
some of these sets with atomic type specifiers: i n t e g e r denotes
the set of all the integers. But we can also construct compound type
specifiers that refer to any set of objects. For example, if a and b
are two type specifiers, then (or a b) denotes the union of the type
denoted by a and that denoted by b. That is, an object is of type (or
a b) if it is of type a or type b. 232

   14.1

   TYPE SPECIFIERS

   233

   If c i r c u l a r ? were a function that returned true of
cdr-circular lists, then to denote the set of proper sequences you
could use:1 (or vector (and list (not (satisfies circular?))))

   Some of the atomic type specifiers can also appear in compound
type specifiers. To denote the set of integers between 1 and 100
inclusive, we would use: ( i n t e g e r 1 100) Such a type specifier
is said to denote a.finitetype. In a compound type-specifier, you can
leave some information unspecified by using * in place of an
argument. So (simple-array fixnum (* *)) describes the set of
two-dimensional simple arrays specialized for fixnums, and
(simple-array fixnum *) describes the set (a supertype of the first)
of simple arrays specialized for fixnums. Trailing asterisks can be
dropped, so in the latter case we could have said: (simple-array
fixnum) If no arguments are given to a compound type-specifier, you
can use an atom. So simple-array describes the set of all simple
arrays. If there is some compound type specifier that you'd like to
use repeatedly, you can define an abbreviation for it with def type.
This macro is just like def macro, but expands into a type specifier
instead of an expression. By saying (deftype proseq () '(or vector
(and list (not (satisfies circular?)))))

   we define proseq as a new atomic type specifier: > (typep #(1 2)
'proseq) T If you define a type-specifier to take arguments, the
arguments are treated as forms (that is, not evaluated), just as with
def macro. So 1 Though the standard does not seem to mention this,
you can assume that the type-specifiers and and or only consider as
many of their arguments as they need to, like the and and or macros.

   234

   ADVANCED TOPICS

   (deftype multiple-of (n) '(and integer (satisfies (lambda (x)
(zerop (mod x ,n)))))) defines ( m u l t i p l e - o f n) as a
specifier for all multiples of n: > (typep 12 ' ( m u l t i p l e - o
f 4)) T Type specifiers are interpreted, and therefore slow, so you
would generally be better off defining a function to make this kind
of test.


File: long-ANSI-sample.info,  Node: Binary Streams,  Next: Read-Macros,  Prev: Type Specifiers,  Up: Advanced Topics

14.2 Binary Streams
===================

Chapter 7 mentioned that there were binary streams as well as
character streams. A binary stream is a source and/or destination not
of characters but of integers. You create a binary stream by
specifying a subtype of integer-most often unsigned-byte-as the :
element-type when you open the stream. There are only two functions
for I/O on binary streams, read-byte and w r i t e - b y t e . So
here is how you might define a function to copy a file: (defun c o p
y - f i l e (from t o ) ( w i t h - o p e n - f i l e ( i n from : d
i r e c t i o n :input :element-type 'unsigned-byte) ( w i t h - o p
e n - f i l e (out t o : d i r e c t i o n :output :element-type
'unsigned-byte) (do ( ( i ( r e a d - b y t e in NIL -1) (read-byte
in NIL -1))) ((minusp i )) ( d e c l a r e (fixnum i )) (write-byte i
out))))) By specifying just unsigned-byte as the : element-type, you
let the operating system choose the length of a byte. If you
specifically wanted to read or write 7-bit integers, for example, you
would use (unsigned-byte 7) as the : element-type instead.

   14.3

   READ-MACROS

   235


File: long-ANSI-sample.info,  Node: Read-Macros,  Next: Packages,  Prev: Binary Streams,  Up: Advanced Topics

14.3 Read-Macros
================

Section 7.5 introduced the concept of a macro character, a character
that has a special meaning to read. Each such character has a
function associated with it that tells read what to do when the
character is encountered. You can change the function associated with
an existing macro character, or define new read-macros of your own.
The function s e t - m a c r o - c h a r a c t e r provides one way
to define readmacros. It takes a character and a function, and
thereafter when read encounters the character, it returns the result
of calling the function. One of the oldest read-macros in Lisp is ',
the quote. We could define it as: (set-macro-character #V #'(lambda
(stream char) ( LIST (quote quote) (read stream t NIL t )))) When
read encounters an instance of * in a normal context, it will return
the result of calling this function on the current stream and
character. (The function ignores this second parameter, which will
always be the quote character.) So when read sees ' a, it will return
(quote a ) . Now we see the point of the last argument to read. It
says whether the call to read occurs within a call to read. The
arguments to read will be the same in nearly all read-macros: the
stream; the second argument, t , which says that read should signal
an error if the next thing it sees is the end-of-file; the third
argument, which says what to return instead of generating an error is
therefore irrelevant; and the fourth argument, t, which says that the
call to read is a recursive one. You can (with
make-dispatch-macro-character) define your own dispatching macro
characters, but since # is already defined as one, you may as well
use it. Six combinations beginning with # are explicitly reserved for
your use: #!, #?, # [ , # ] , #"", and #. You can define new
dispatching macro character combinations by calling s e t - d i s p a
t c h - m a c r o - c h a r a c t e r , which is like s e t - m a c r
o - c h a r a c t e r except that it takes two character arguments.
This code defines #? as a read-macro that returns a list of integers.
( s e t - d i s p a t c h - m a c r o - c h a r a c t e r #\# #\?
#'(lambda (stream c h a r l char2) ( LIST 'quote (let ((lst NIL ))
(dotimes (i (+ (read stream t nil t) 1)) (push i lst)) (nreverse
lst)))))

   236

   ADVANCED TOPICS

   Now #?rc will be read as a list of all the integers from 0 to n.
For example: > #?7 (01234567) After simple macro characters, the most
commonly defined macro characters are list delimiters. Another
character combination reserved for the user is #"". Here we define it
as a more elaborate kind of left parenthesis: ( s e t - m a c r o - c
h a r a c t e r # \  (get-macro-character # \ ))) ( s e t - d i s p a
t c h - m a c r o - c h a r a c t e r #\# #\"" #'(lambda (stream c h
a r l char2) (let ((accum NIL ) ( p a i r ( r e a d - d e l i m i t e
d - LIST # \  stream t ))) (do ( ( i (car p a i r ) (+ i 1))) ((> i
(cadr p a i r )) ( LIST 'quote (nreverse accum))) (push i accum)))))
This defines an expression of the form #""x y to read as a list of
all the integers between x and y, inclusive:

   > #""2 7 ( 2 3 4 5 6 7 )

   The function r e a d - d e l i m i t e d - LIST is provided just
for such read-macros. Its first argument is the character to treat as
the end of the list. For  to be recognized as a delimiter, it must
first be given this role, hence the preliminary call to s e t - m a c
r o - c h a r a c t e r . If you want to use a read-macro in the file
in which it is defined, the definition should be wrapped in an
eval-when expression, to ensure that it is evaluated at compile time.
Otherwise the definition will be compiled, but not evaluated until
the compiled file is loaded.


File: long-ANSI-sample.info,  Node: Packages,  Next: The Loop Facility,  Prev: Read-Macros,  Up: Advanced Topics

14.4 Packages
=============

A package is a Lisp object that maps names to symbols. The current
package is always stored in the global variable *package*. When
Common Lisp starts up, the current package will be common-lisp-user,
informally known as the user package. The function package-name
returns the name of a package, and find-package returns the package
with a given name:

   14.4

   PACKAGES

   237

   > (package-name *package*) "COMMON-LISP-USER" > (find-package
"COMMON-LISP-USER") #<Package "COMMON-LISP-USER" 4CD15E> Usually a
symbol is interned in the package that was current at the time it was
read. The function symbol-package takes a symbol and returns the
package in which it is interned. > (symbol-package 'sym) #<Package
"COMMON-LISP-USER" 4CD15E> Interestingly, this expression returns the
value it does because the expression had to be read before it could
be evaluated, and reading the expression caused sym to be interned.
For future use, let's give sym a value: > ( s e t f sym 99) 99 Now we
will create and switch to a new package: > (setf *package*
(make-package 'mine :use '(common-lisp))) #<Package "MINE" 63390E> At
this point there should be eerie music, because we are in a different
world: sym here is not what it used to be. MINE> sym Error: S Y M has
no v a l u e . Why did this happen? Because the sym we set to 99
above is a distinct symbol from sym here in mine. 2 To refer to the
original sym from outside the user package, we must prefix the
package name and two colons: MINE> common-lisp-user::sym 99 So
different symbols with the same print-name can coexist in different
packages. There can be one sym in package common-lisp-user and
another sym in package mine, and they will be distinct symbols.
That's the point of packages. If you're writing your program in a
separate package, you can choose names for your functions and
variables without worrying that someone 2 Some implementations of
Common Lisp print the package name before the toplevel prompt
whenever we are not in the user package.

   238

   ADVANCED TOPICS

   will use the same name for something else. Even if they use the
same name, it won't be the same symbol. Packages also provide a means
of information-hiding. Programs must refer to functions and variables
by their names. If you don't make a given name available outside your
package, it becomes unlikely that code in another package will be
able to use or modify what it refers to. It's usually bad style to
use package prefixes with double colons. By doing so you are
violating the modularity that packages are supposed to provide. If
you have to use a double colon to refer to a symbol, it's because
someone didn't want you to. Usually one should only refer to symbols
that have been exported. If we go back to the user package
(in-package sets *package*) and export a symbol interned there, MINE>
(in-package common-lisp-user) #<Package "COMMON-LISP-USER" 4CD15E> >
(export 'bar) T > (setf bar 5) 5

   we cause it to be visible to other packages. Now when we return to
mine, we can refer to bar with only a single colon, because it is a
publicly available name: > (in-package mine) #<Package "MINE" 63390E>
MINE> common-lisp-user:bar 5 By importing bar into mine, we can go
one step further and make mine actually share the symbol bar with the
user package: MINE> (import T MINE> bar 5 'common-lisp-user:bar)

   After importing bar we can refer to it without any package
qualifier at all. The two packages now share the same symbol; there
can't be a distinct mine: bar. What if there already was one? In that
case, the call to import would have caused an error, as we see if we
try to import sym: MINE> (import 'common-lisp-user::sym) Error: S Y M
i s a l r e a d y p r e s e n t in MINE.

   14.5

   THE LOOP FACILITY

   239

   Before, when we tried unsuccessfully to evaluate sym in mine, we
thereby caused a symbol sym to be interned there. It had no value and
therefore generated an error, but the interning happened simply as a
consequence of typing its name. So now when we try to import sym into
mine, there is already a symbol there with the same name. Another way
to get access to symbols from another package is to use it: MINE>
(use-package ;common-lisp-user) T

   Now all symbols exported by the user package can be used without
any qualifier in mine. (If sym had been exported by the user package,
this call would also have generated an error.) The package containing
the names of built-in operators and variables is called common-lisp.
Since we gave the name of this package in the :use argument of the
make-package that created mine, all of Common Lisp's names will be
visible here: MINE> #'cons #<Compiled-Function CONS 462A3E> As with
compilation, operations on packages are not usually done at the
toplevel like this. More often the calls are contained in source
files. Generally it will suffice to begin a file with a def package
and an in-package, as on page 137. The kind of modularity provided by
packages is actually a bit odd. We have modules not of objects, but
of names. Every package that uses common-lisp has access to the name
cons, because common-lisp includes a function with that name. But in
consequence a variable called cons would also be visible in every
package that used common-lisp. If packages are confusing, this is the
main reason why; they're not based on objects, but on their names.0


File: long-ANSI-sample.info,  Node: The Loop Facility,  Next: Conditions,  Prev: Packages,  Up: Advanced Topics

14.5 The Loop Facility
======================

The loop macro was originally designed to help inexperienced Lisp
users write iterative code. Instead of writing Lisp code, you express
your program in a form meant to resemble English, and this is then
translated into Lisp. Unfortunately, loop is more like English than
its designers ever intended: you can use it in simple cases without
quite understanding how it works, but to understand it in the abstract
is almost impossible.

   If you are one of the many Lisp programmers who have been planning
one day to understand what loop does, there is some good news and
some bad

   240

   ADVANCED TOPICS

   news. The good news is that you are not alone: almost no one
understands it. The bad news is that you probably never will, because
the ANSI standard does not really give a formal specification of its
behavior.

   The only real definition of this macro is its implementation, and
the only way to understand it (so far as one can) is by examples. The
chapter of the ANSI standard dealing with loop consists largely of
examples, and we will use the same approach here to introduce the
basic concepts involved.

   The first thing one notices about the loop macro is that it has
syntax. A loop expression contains not subexpressions but clauses. The
clauses are not delimited by parentheses; instead, each kind has a
distinct syntax. In that, loop resembles traditional Algol-like
languages. But the other distinctive feature of loop, which makes it
as unlike Algol as Lisp, is that the order in which things happen is
only loosely related to the order in which the clauses occur.

   There are three phases in the evaluation of a loop expression, and
a given clause can contribute code to more than one phase. The phases
are as follows:

   1. Prologue. Evaluated once as a prelude to iteration. Includes
setting variables to their initial values.

   2. Body. Evaluated on each iteration. Begins with the termination
 tests, followed by the body proper, then the updating of iteration
 variables.

   3. Epilogue. Evaluated once iteration is completed. Concludes with
the    return of the value(s) of the loop expression.

   We will look at some examples of loop clauses and consider what
kind of code they might contribute to each phase.

   For example, in the simplest kind of loop expression we might see
something like the following:

   > (loop for x from 0 to 9 do (princ x)) 0123456789 NIL

   This loop expression prints the integers from 0 to 9 and returns
NIL . The first clause,

   for x from 0 t o 9

   contributes code to thefirsttwo phases, causing x to be set to 0 in
the prologue, compared to 9 at the beginning of the body, and
incremented at the end. The second clause,

   14.5 do (princ x)

   THE LOOP FACILITY

   241

   contributes code (the princexpression) to the body proper.

   A more general kind of for clause specifies an initial and update
form. Termination can then be controlled by something like a while or
u n t i l clause.

   > (loop for x = 8 then (/ x 2) u n t i l (< x 1) do (princ x))
8421 NIL

   You can use and to create a compound for clause in which two
variables will be initialized and updated in parallel:

   > (loop for x from 1 to 4 and y from 1 to 4 do (princ ( LIST x y
))) (1 1)(2 2 ) ( 3 3)(4 4) NIL

   Otherwise, if there are multiple for clauses, the variables will
be updated sequentially.

   Another thing one typically wants to do in iterative code is
accumulate some kind of value. For example:

   > (loop for x in ' ( 1 2 3 4) c o l l e c t (1+ x)) (2 3 4 5)

   Using in instead of from in the for clauses causes the variable to
be set to successive elements of a list instead of successive
integers.

   In this case the c o l l e c t clause contributes code to all three
phases. In the prologue an anonymous accumulator is set to NIL ; in
the body (1+ x) is appended to this accumulator; and in the epilogue
its value is returned.

   This is the first example to return a particular value. There are
clauses for explicitly specifying the return value, but in the absence
of such clauses, a c o l l e c t clause determines the return value.
So what we've done here is duplicate mapcar.

   The most common use of loop is probably to collect the results of
calling a function a certain number of times:

   > (loop for x from 1 to 5 collect (random 10)) (38650)

   242

   ADVANCED TOPICS

   (defun most (fn lst) (if (null lst) (values nil nil) (let* ((wins
(car lst)) (max (funcall fn wins))) (dolist (obj (cdr lst)) (let
((score (funcall fn obj))) (when (> score max) (setf wins obj max
score)))) (values wins max)))) (defun num-year (n) (if (< n 0) (do*
((y ( - yzero 1) ( - y 1)) (d ( - (year-days y)) ( - d (year-days
y)))) ((<= d n) (values y ( - n d)))) (do* ((y yzero (+ y 1)) (prev 0
d) (d (year-days y) (+ d (year-days y)))) ((> d n) (values y ( - n
prev)))))) Figure 14.1: Iteration without loop.

   Here we get a list of five random numbers. It was for cases like
this that we defined map-int (page 105). Why do we need map-int if we
have loop? One can as easily ask, why do we need loop if we have
map-int?

   0

   A c o l l e c t clause can also accumulate its value into a named
variable. The following function takes a list of numbers and returns
lists of the even and odd elements:

   (defun even/odd (ns) (loop for n in ns if (evenp n) collect n into
evens else collect n into odds finally (return (values evens odds))))

   A f i n a l l y clause contributes code to the epilogue. In this
case it specifies the return value.

   A sum clause is like a c o l l e c t clause, but accumulates a
number instead of a list. To get the sum of the numbers from 1 to n
we could write:

   14.5

   THE LOOP FACILITY

   243

   (defun most (fn lst) (if (null lst) (values nil nil) (loop with
wins = (car lst) with max = (funcall fn wins) for obj in (cdr lst)
for score = (funcall fn obj) when (> score max) do (setf wins obj max
score) finally (return (values wins max)))))

   (defun num-year (n) (if (< n 0) (loop for y downfrom ( - yzero 1)
until (<= d n) sum ( - (year-days y)) into d finally (return (values
(+ y 1) ( - n d)))) (loop with prev = 0 for y from yzero until (> d
n) do (setf prev d) sum (year-days y) into d finally (return (values
( - y 1) ( - n prev)))))) Figure 14.2: Iteration with loop.

   (defun sum (n) (loop for x from 1 to n sum x))

   Further details of loop are covered in Appendix D, beginning on
page 325. As an example, Figure 14.1 contains two iterative functions
from preceding chapters, and Figure 14.2 shows the same functions
rendered into loops.

   One loop clause can refer to variables established by another. In
the definition of even/odd, for example, the f i n a l l y clause
refers to the variables established by the two c o l l e c t clauses.
The relations between such variables are one of the greatest
ambiguities in the definition of loop. Consider the following two
expressions:

   244

   ADVANCED TOPICS

   (loop    for y = 0 then z    for x from 1 to 5    sum 1 into z
finally (return (values y z)))

   (loop    for x from 1 to 5    for y = 0 then z    sum 1 into z
finally (return (values y z)))

   They seem simple enough-they each have only four clauses. Do they
return the same values? What values do they return? You will search
the standard in vain for the answers. Each loop clause is simple
enough by itself. But the way they combine is extremely
complicated-and ultimately, not even well-defined.

   For such reasons, the use of loop cannot be recommended. The most
that can be said for it, in typical examples like those shown in
Figure 14.2, is that it makes the code look easier to understand.


File: long-ANSI-sample.info,  Node: Conditions,  Prev: The Loop Facility,  Up: Advanced Topics

14.6 Conditions
===============

In Common Lisp, conditions include errors and other situations that
can arise at run-time. When a condition is signalled, the
corresponding handler is invoked. The default handler for error
conditions usually invokes a breakloop. But Common Lisp provides a
variety of operators for signalling and handling conditions. It's
possible to override the default handlers, or even write new handlers
of your own. Most programmers will not deal with conditions directly.
However, there are several layers of more abstract operators that use
conditions, and to understand these operators it helps to know about
the underlying mechanism. Common Lisp has several operators for
signalling errors. The most basic is e r r o r . One way to call it
is to give it the same arguments that you might pass to format: >
(error "Your report uses ~A as a verb." Error: Your report uses
STATUS as a verb. Options: :abort, :backtrace » )

   status)

   Unless such a condition is handled, execution will be interrupted,
as above. More abstract operators for signalling errors include
ecase, check-type and a s s e r t . The former is like case, but
signals an error if none of the keys match:

   14.6

   CONDITIONS

   245

   > (ecase 1 (2 3) (4 5)) Error: No applicable clause. Options:
:abort, :backtrace »

   The regular case will return NIL if no key matches, but since it's
bad style to take advantage of this return value, you might as well
use ecase whenever you don't have an otherwise clause. The check-type
macro takes a place, a type name, and an optional string, and signals
a correctable error if the value of the place is not of the
designated type. The handler for a correctable error will give us the
option of providing a new value: > (let ((x '(a b c))) (check-type
(car x) integer "an integer") x) Error: The value of (CAR X), A,
should be an integer. Options: :abort, :backtrace, :continue >>
.-continue New value of (CAR X)? 99 (99 B C) >

   In this example, (car x) was set to the new value that we
supplied, and execution resumed, returning what it would have
returned if (car x) had originally contained the value we supplied.
This macro is defined in terms of the more general a s s e r t ,
which takes a test expression and a list of one or more places,
followed by the arguments you might give to e r r o r : > (let
((sandwich '(ham on rye))) (assert (eql (car sandwich) 'chicken)
((car sandwich)) "I wanted a ~A sandwich." 'chicken) sandwich) Error:
I wanted a CHICKEN sandwich. Options: :abort, :backtrace, :continue
» :continue New value of (CAR SANDWICH)? 'chicken (CHICKEN ON RYE) >

   It's also possible to establish new handlers, but most programmers
will only take advantage of this possibility indirectly, by using
macros like

   246

   ADVANCED TOPICS

   i g n o r e - e r r o r s . This macro behaves like progn if none
of its arguments cause an error. But if an error is signalled during
the evaluation of one of its arguments, execution will not be
interrupted. Instead the i g n o r e - e r r o r s expression will
immediately return two values: NIL and the condition that was
signalled. For example, if at some point you want the user to be able
to enter an expression, but you don't want an error to interrupt
execution if the input is syntactically ill-formed, you could write:
(defun user-input (prompt) (format t prompt) (let ((str (read-line)))
(or (ignore-errors (read-from-string str)) nil)))

   This function just returns NIL if the input contains syntax errors:
> (user-input "Please type an expression> ") Please type an
expression> #°/»\Comma-at#+! ! NIL


File: long-ANSI-sample.info,  Node: Example-- Inference,  Next: Example-- Generating HTML,  Prev: Advanced Topics,  Up: Top

15 Example- Inference
*********************

The next three chapters offer examples of substantial Lisp programs.
These examples were chosen to illustrate the form that longer
programs take, and also the kinds of problems for which Lisp is
especially well-suited. In this chapter we will write a program that
makes inferences based on a collection of if-then rules.

   This is a classic example-not only in the sense that it often
appears in textbooks, but also because it reflects the original idea
of Lisp as a language for "symbolic computation." A lot of the
earliest Lisp programs had the flavor of the example in this chapter.

* Menu:

* The Aim::
* Matching::
* Answering Queries::
* Analysis::


File: long-ANSI-sample.info,  Node: The Aim,  Next: Matching,  Up: Example-- Inference

15.1 The Aim
============

In this program, we're going to represent information in a familiar
form: a list consisting of a predicate followed by zero or more
arguments. To represent the fact that Donald is the parent of Nancy,
we might say: (parent donald nancy) As well as facts, our program is
going to represent rules that tell what can be inferred from the
facts we already have. We will represent such rules as (<- head body)
where head is the then-part and body is the if-part. Within the head
and body we will represent variables as symbols beginning with
question marks. So this rule (<- ( c h i l d ?x ?y) (parent ?y ?x))
247

   248

   EXAMPLE: INFERENCE

   says that if y is the parent of x, then x is the child of y; or
more precisely, that we can prove any fact of the form ( c h i l d x
v) by proving (parent y x). It will be possible for the body
(if-part) of a rule to be a complex expression, containing the
logical operators and, or, and not. So if we want to represent the
rule that if JC is the parent of v, and x is male, then x is the
father of v, we would write: (<- (father ?x ?y) (and (parent ?x ?y)
(male ?x))) Rules may depend on facts implied by other rules. For
example, the first rule we wrote was for proving facts of the form (
c h i l d x y). If we defined a rule (<- (daughter ?x ?y) (and ( c h
i l d ?x ?y) (female ?x))) then using it to prove (daughter x y)
might cause the program to use the first rule to prove ( c h i l d x
y). The proof of an expression can continue back through any number
of rules, so long as it eventually ends up on the solid ground of
known facts. This process is sometimes called backward chaining. The
backward comes from the fact that this kind of inference first
considers the then-part, to see if the rule will be useful, before
going on to prove the if-part. The chaining comes from the way that
rules can depend on other rules, forming a chain (though in fact it's
more like a tree) that leads from what we want to prove back to what
we already know.0


File: long-ANSI-sample.info,  Node: Matching,  Next: Answering Queries,  Prev: The Aim,  Up: Example-- Inference

15.2 Matching
=============

In order to write our backward-chaining program, we are going to need
a function to do pattern-matching: a function that can compare two
lists, possibly containing variables, to see if there is some way of
assigning values to the variables which makes the two equal. For
example, if ?x and ?y are variables, then the two lists (p ?x ?y c
?x) (p a b c a) match when ?x = a and ?y = b, and the lists (p ?x b
?y a) (p ?y b c a) match when ?x = ?y = c. Figure 15.1 contains a
function called match. It takes two trees, and if they can be made to
match, it returns an assoc-list showing how:

   15.2

   MATCHING

   249

   (defun match (x y feoptional binds) (cond ((eql x y) (values binds
t)) ((assoc x binds) (match (binding x binds) y binds)) ((assoc y
binds) (match x (binding y binds) binds)) ((var? x) (values (cons
(cons x y) binds) t)) ((var? y) (values (cons (cons y x) binds) t))
(t (when (and (consp x) (consp y)) (multiple-value-bind (b2 yes)
(match (car x) (car y) binds) (and yes (match (cdr x) (cdr y)
b2))))))) (defun var? (x) (and (symbolp x) (eql (char (symbol-name x)
0) #\?))) (defun binding (x binds) (let ((b (assoc x binds))) (if b
(or (binding (cdr b) binds) (cdr b)))))

   Figure 15.1: Matching function.

   > (match >(p a b c a) ' ( p ?x ?y c ?x)) ((?Y . B) (?X . A)) T >
(match ' ( p ?x b ?y a) ' ( p ?y b c a )) ((?Y . C) (?X . ?Y)) T >
(match ' ( a b c) ' ( a a a )) NIL As match compares its arguments
element by element, it builds up assignments of values to variables,
called bindings, in the parameter binds. If the match is successful,
match returns the bindings generated; otherwise, it returns NIL .
Since not all successful matches generate any bindings, match, like
gethash, returns a second value to show that the match succeeded:

   250

   EXAMPLE: INFERENCE

   > (match ' (p ?x) »(p ?x)) NIL T When match returns NIL and t as
above, it indicates a successful match that yielded no bindings. In
English, the match algorithm works as follows: 1. If x and y are eql
they match; otherwise, 2. If x is a variable that has a binding, they
match if it matches y; otherwise, 3. If y is a variable that has a
binding, they match if it matches x; otherwise, 4. If x is a variable
(without a binding), they match and thereby establish a binding for
it; otherwise, 5. If y is a variable (without a binding), they match
and thereby establish a binding for it; otherwise, 6. They match if
they are both conses, and the cars match, and the cdrs match with the
bindings generated thereby. Here is an example illustrating, in
order, each of the six cases: > (match ' ( p ?v b ?x d (?z ?z)) ' (p
a ?w c ?y ( e e )) >((?v . a) (?w . b ))) ((?Z . E) (?Y . D) (?X . C)
(?V . A) (?W . B)) T To find the value (if there is one) associated
with a variable in a list of bindings, match calls binding. This
function has to be recursive, because matching can build up binding
lists in which a variable is only indirectly associated with its
value: ?x might be bound to a in virtue of the list containing both
(?x . ?y) and (?y . a ) . > (match ; ( ? x a) ' ( ? y ?y)) ((?Y . A)
(?X . ?Y)) T

   By matching ?x with ?y and then ?y with a, we establish indirectly
that ?x must be a.

   15.3

   ANSWERING QUERIES

   251

   (defvar *rules* (make-hash-table)) (defmacro <- (con ^optional
ant) f (length (push (cons (cdr ',con) ',ant) (gethash (car ',con)
*rules*)))) Figure 15.2: Defining rules.


File: long-ANSI-sample.info,  Node: Answering Queries,  Next: Analysis,  Prev: Matching,  Up: Example-- Inference

15.3 Answering Queries
======================

Now that the concept of bindings has been introduced, we can say more
precisely what our program will do: it will take an expression,
possibly containing variables, and return all the bindings that make
it true given the facts and rules that we have. For example, if we
have just the fact (parent donald nancy) and we ask the program to
prove (parent ?x ?y) it should return something like (((?x . donald)
(?y . nancy))) which says that there is exactly one way for the
expression to be true: if ?x is donald and ?y is nancy. Now that we
have a matching function we are already a good part of the way to our
destination. Figure 15.2 contains the code for defining rules. The
rules are going to be contained in a hash table called *rules*,
hashed according to the predicate in the head. This imposes the
restriction that we can't use variables in the predicate position. We
could eliminate this restriction by keeping all such rules in a
separate list, but then to prove something we would have to match it
against every one. We will use the same macro, <-, to define both
facts and rules. A fact will be represented as a rule with a head but
no body. This is consistent with our definition of rules. A rule says
that you can prove the head by proving the body, so a rule with no
body means that you don't have to prove anything to prove the head.
Here are two familiar examples: > (<- (parent donald nancy)) 1 > (<-
(child ?x ?y) (parent ?y ?x)) 1

   252

   EXAMPLE: INFERENCE

   (defun prove (expr feoptional binds) (case (car expr) (and
(prove-and (reverse (cdr expr)) binds)) (or (prove-or (cdr expr)
binds)) (not (prove-not (cadr expr) binds)) (t (prove-simple (car
expr) (cdr expr) binds)))) (defun prove-simple (pred args binds)
(mapcan #'(lambda (r) (multiple-value-bind (b2 yes) (match args (car
r) binds) (when yes (if (cdr r) (prove (cdr r) b2) (list b2)))))
(mapcar #'change-vars (gethash pred *rules*)))) (defun change-vars
(r) (sublis (mapcar #'(lambda (v) (cons v (gensym "?"))) (vars-in r))
r)) (defun vars-in (expr) (if (atom expr) (if (var? expr) (list
expr)) (union (vars-in (car expr)) (vars-in (cdr expr)))))

   Figure 15.3: Inference.

   Calls to <- return the number of rules now stored under a given
predicate; wrapping the push in a call to length saves us from seeing
a big return value at the toplevel. Figure 15.3 contains most of the
code we need for inference. The function prove is the pivot on which
inference turns. It takes an expression and an optional list of
bindings. If the expression doesn't contain logical operators, it
calls prove-simple, and it is here that chaining takes place. This
function works by looking at all the rules with the right predicate,
and trying to match the head of each with the fact it is trying to
prove. For each head that matches,

   15.3

   ANSWERING QUERIES

   253

   it calls prove on the body, with the new bindings generated by the
match. The lists of bindings returned by each call to prove are then
collected by mapcan and returned: > (prove-simple ' p a r e n t
(donald nancy) NIL ) (NIL) > (prove-simple >child ' (?x ?y) NIL ) ( (
( # : ? 6 . NANCY) (#:?5 . DONALD) (?Y . #:?5) (?X . # : ? 6 ))) Both
of the return values above indicate that there is one way to prove
what we asked about. (A failed proof would return NIL . ) The first
example generated one empty set of bindings, and the second generated
one set of bindings in which ?x and ?y were (indirectly) bound to
nancy and donald. Incidentally, we see here a good example of the
point made on page 23. Because our program is written in a functional
style, we can test each function interactively. What about those
gensyms in the second return value? If we are going to use rules
containing variables, we need to avoid the possibility of two rules
accidentally containing the same variable. If we define two rules as
follows (<- (child ?x ?y) (parent ?y ?x)) (<- (daughter ?y ?x) (and
(child ?y ?x) (female ?y))) then we mean that for any x and y, x is
the child of y if y is the parent of x, and for any x and y, y is the
daughter of x if y is the child of x and female. The relationship of
the variables within each rule is significant, but the fact that the
two rules happen to use the same variables is entirely coincidental.
If we used these rules as written, they would not work that way. If
we tried to prove that a was b's daughter, matching against the head
of the second rule would leave ?y bound to a and ?x to b. We could
not then match the head of the first rule with these bindings: >
(match '(child ?y ?x) '(child ?x ?y) '((?y . a) (?x . b))) NIL To
ensure that the variables in a rule imply only something about the
relations of arguments within that rule, we replace all the variables
in a rule with gensyms. This is the purpose of the function
change-vars. A gensym could not possibly turn up as a variable in
another rule. But because rules can be recursive, we also have to
guard against the possibility of a rule clashing with itself, so
change-vars has to be called not just when a rule is defined, but
each time it is used.

   254

   EXAMPLE: INFERENCE

   (defun prove-and (clauses binds) (if (null clauses) (list binds)
(mapcan #'(lambda (b) (prove (car clauses) b)) (prove-and (cdr
clauses) binds)))) (defun prove-or (clauses binds) (mapcan #'(lambda
(c) (prove c binds)) clauses)) (defun prove-not (clause binds)
(unless (prove clause binds) (list binds))) Figure 15.4: Logical
operators.

   , (defmacro with-answer (query &body body) (let ((binds (gensym)))
1 (dolist ( , b i n d s (prove ' , q u e r y )) (let ,(mapcar
#'(lambda (v) ' ( , v (binding ' , v , b i n d s ))) ( v a r s - i n
query)) ,\Comma-atbody)))) Figure 15.5: Interface macro.

   Now all that remains is to define the functions that prove complex
expressions. These are shown in Figure 15.4. Handling an or or not
expression is particularly simple. In the former case we collect all
the bindings returned by each of the expressions within the or. In
the latter case, we return the current bindings iff the expression
within the not yields none. The function prove-and is only a little
more complicated. It works like a filter, proving the first
expression for each set of bindings that can be established for the
remaining expressions. This would cause the expressions within the
and to be considered in reverse order, except that the call to
prove-and within prove reverses them to compensate. Now we have a
working program, but it's not very user-friendly. It's a nuisance to
have to decipher the lists of bindings returned by prove-and

   15.4

   ANALYSIS

   255

   (with-answer (p ?x ?y) (f ?x ?y)) is macroexpanded into: ( d o
LIST ( # : g l (prove ; (P ?x ? y ))) (let ((?x (binding ' ?x #:gD)
(?y (binding ' #:gl))) (f ?x ?y))) Figure 15.6: Exp ansion of a call
to with-answer.

   they only get longer as the rules get more complex. Figure 15.5
contains a macro that will make our program more pleasant to use: a
with-answer expression will take a query (not evaluated) and a body
of expressions, and will evaluate its body once for each set of
bindings generated by the query, with each pattern variable bound to
the value it has in the bindings. > (with-answer (parent ?x ?y)
(format t "~A i s t h e parent of ~A.~°/0" ?x ?y)) DONALD i s t h e
p a r e n t of NANCY. NIL This macro does the work of deciphering the
bindings for us, and gives us a convenient way of using prove in
programs. Figure 15.6 shows what an expansion looks like, and Figure
15.7 shows some examples of it in use.


File: long-ANSI-sample.info,  Node: Analysis,  Prev: Answering Queries,  Up: Example-- Inference

15.4 Analysis
=============

It may seem as if the code we've written in this chapter is simply
the natural way to implement such a program. In fact it is grossly
inefficient. What we've done here, essentially, is to write an
interpreter. We could implement the same program as a compiler. Here
is a sketch of how it would be done. The basic idea would be to pack
the whole program into the macros <- and with-answer, and make them
do at macro-expansion time most of the work the program now does at
run-time. (The germ of this idea is visible in avg, on page 170.)
Instead of representing rules as lists, we would represent them as
functions, and instead of having functions like prove and prove-and
to interpret expressions at run-time, we would have corresponding
functions to transform expressions into code. The expressions are
available at the time a rule is defined. Why wait until it

   256

   EXAMPLE: INFERENCE

   If we do a ( c l r h a s h *rules*) and then define the following
rules and facts, (<(<(<(<(<(<(parent donald (parent donald (male
donald)) ( f a t h e r ?x ?y) (= ?x ?x)) ( s i b l i n g ?x ?y)
nancy)) debbie)) (and (parent ?x ?y) (male ? x ))) (and (parent ?z
?x) (parent ?z ?y) (not (= ?x ? y » » j

   we will be able to make inferences like the following: >
(with-answer ( f a t h e r ?x ?y) (format t "~A i s t h e f a t h e r
of ~A.~°/.M ?x ?y)) DONALD i s t h e f a t h e r of DEBBIE. DONALD i
s t h e f a t h e r of NANCY. NIL > (with-answer ( s i b l i n g ?x
?y) (format t "~A i s t h e s i b l i n g of ~k.~V ?x ? y » DEBBIE i
s t h e s i b l i n g of NANCY. NANCY i s t h e s i b l i n g of
DEBBIE. ! NIL Figure 15.7: The program in use.

   is used in order to analyze them? The same goes for with-answer,
which would call the same functions as <- to generate its expansion.
This sounds like it would be a lot more complicated than the program
we wrote in this chapter, but in fact it would probably only be about
two or three times as long. Readers who would like to learn about
such techniques should see On Lisp or Paradigms of Artificial
Intelligence Programming, which contain several examples of programs
written in this style.


File: long-ANSI-sample.info,  Node: Example-- Generating HTML,  Next: Example-- Objects,  Prev: Example-- Inference,  Up: Top

16 Example- Generating HTML
***************************


File: long-ANSI-sample.info,  Node: Example-- Objects,  Next: A-- Debugging,  Prev: Example-- Generating HTML,  Up: Top

17 Example- Objects
*******************


File: long-ANSI-sample.info,  Node: A-- Debugging,  Next: B-- Lisp in Lisp,  Prev: Example-- Objects,  Up: Top

18 A- Debugging
***************


File: long-ANSI-sample.info,  Node: B-- Lisp in Lisp,  Next: C-- Changes to Common Lisp,  Prev: A-- Debugging,  Up: Top

19 B- Lisp in Lisp
******************


File: long-ANSI-sample.info,  Node: C-- Changes to Common Lisp,  Next: D-- Language Reference,  Prev: B-- Lisp in Lisp,  Up: Top

20 C- Changes to Common Lisp
****************************


File: long-ANSI-sample.info,  Node: D-- Language Reference,  Next: Index,  Prev: C-- Changes to Common Lisp,  Up: Top

21 D- Language Reference
************************


File: long-ANSI-sample.info,  Node: Index,  Prev: D-- Language Reference,  Up: Top



The next chapter of bullshit.


