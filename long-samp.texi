{\input texinfo   @c -*-texinfo-*-
@c %**start of header
@setfilename long-ANSI-sample.info
@settitle ANSI- 1.0
@c %**end of header

@copying
@end copying

@titlepage
@title My Next Title
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

This is a short manual.

This is the next paragraph

@c Output the table of contents at the beginning.
@contents
@ifnottex
@node Top
@top ANSI Common Lisp
@end ifnottex
info

@menu
* Introduction::    The first chapter is not the only chapter in this sample.
* Welcome to Lisp::  The second chapter is the other chapter.
* Lists::
* Specialized Data Structures::
* Control::
* Functions::
* Input/Output::
* Symbols::
* Numbers::
* Macros::
* CLOS::
* Structure::
* Speed::
* Advanced Topics::
* Example-- Inference::
* Example-- Generating HTML::
* Example-- Objects::
* A-- Debugging::
* B-- Lisp in Lisp::
* C-- Changes to Common Lisp::
* D-- Language Reference::
* Index::            Complete index.
@end menu

@node Introduction
@chapter Introduction


John McCarthy and his students began work on the first Lisp
implementation in 1958. After FORTRAN, Lisp is the oldest language
still in use.0 What's more remarkable is that it is still in the
forefront of programming language technology. Programmers who know
Lisp will tell you, there is something about this language that sets
it apart. 
   Part of what makes Lisp distinctive is that it is designed
to evolve. You can use Lisp to define new Lisp operators. As new
abstractions become popular (object-oriented programming, for
example), it always turns out to be easy to implement them in
Lisp. Like DNA, such a language does not go out of style.


@menu
* New Tools::
* New Techniques::
* A New Approach::
@end menu

@node New Tools
@section New Tools
Why learn Lisp? Because it lets you do things that you can't do in
other languages. If you just wanted to write a function to return the
sum of the numbers less than n> say, it would look much the same in
Lisp and C:

@smallexample
@group
@code{
; Lisp 

(defun sum (n) 
  (let ((s 0))
   (dotimes (i n s) 
   (incf s i ))))
}
@end group
@end smallexample

@smallexample
@group
; /* C */

int sum(int n)
    int i, s = 0\;
    for ( i = 0\; i < n\; i++) 
        s += i \;
    return(s)\;
@end group
@end smallexample

If you only need to do such simple things, it doesn't really matter
which language you use. Suppose instead you want to write a function
that takes a number n, and returns a function that adds n to its argument:

@smallexample
@group
@lisp 
; Lisp
(defun my-addn (n)
  #'(lambda (x) (+ x n)))
@end lisp
@end group
@end smallexample

What does addn look like in C? You just can't write it.

You might be wondering, when does one ever want to do things like
this? Programming languages teach you not to want what they cannot
provide. You have to think in a language to write programs in it, and
it's hard to want something you can't describe. When I first started
writing programs--in Basic--I didn't miss recursion, because I didn't
know there was such a thing. I thought in Basic. I could only conceive
of iterative algorithms, so why should I miss recursion?

If you don't miss lexical closures (which is what's being made in the
preceding example), take it on faith, for the time being, that Lisp
programmers use them all the time. It would be hard to find a Common
Lisp program of any length that did not take advantage of closures. By
page 112 you will be using them yourself.

And closures are only one of the abstractions we don't find in other
languages. Another unique feature of Lisp, possibly even more
valuable, is that Lisp programs are expressed as Lisp data
structures. This means that you can write programs that write
programs. Do people actually want to do this?  Yes--they're called
macros, and again, experienced programmers use them all the time. By
page 173 you will be able to write your own.

With macros, closures, and run-time typing, Lisp transcends
object-oriented programming. If you understood the preceding sentence,
you probably should not be reading this book. You would have to know
Lisp pretty well to see why it's true. But it is not just words. It is
an important point, and the proof of it is made quite explicit, in
code, in Chapter 17.

Chapters 2-13 will gradually introduce all the concepts that you'll
need in order to understand the code in Chapter 17. The reward for
your efforts will be an equivocal one: you will feel as suffocated
programming in C++ as an experienced C++ programmer would feel
programming in Basic. It's more encouraging, perhaps, if we think
about where this feeling comes from. Basic is suffocating to someone
used to C++ because an experienced C++ programmer knows techniques
that are impossible to express in Basic. Likewise, learning Lisp will
teach you more than just a new language--it will teach you new and
more powerful ways of thinking about programs.

@node New Techniques
@section New Technqiues

As the preceding section explained, Lisp gives you tools that other
languages don't provide. But there is more to the story than
this. Taken separately, the new things that come with Lisp--automatic
memory management, manifest typing, closures, and so on--each make
programming that much easier. Taken together, they form a critical
mass that makes possible a new way of programming.

Lisp is designed to be extensible: it lets you define new operators
yourself. This is possible because the Lisp language is made out of
the same functions and macros as your own programs. So it's no more
difficult to extend Lisp than to write a program in it. In fact, it's
so easy (and so useful) that extending the language is standard
practice. As you're writing your program down toward the language, you
build the language up toward your program. You work bottom-up, as well
as top-down.

Almost any program can benefit from having the language tailored to
suit its needs, but the more complex the program, the more valuable
bottom-up programming becomes. A bottom-up program can be written as a
series of layers, each one acting as a sort of programming language
for the one above. TgX was one of the earliest programs to be written
this way. You can write programs bottom-up in any language, but Lisp
is far the most natural vehicle for this style.

Bottom-up programming leads naturally to extensible software. If you
take the principle of bottom-up programming all the way to the topmost
layer of your program, then that layer becomes a programming language
for the user. Because the idea of extensibility is so deeply rooted in
Lisp, it makes the ideal language for writing extensible
software. Three of the most successful programs of the 1980s provide
Lisp as an extension language: Gnu Emacs, Autocad, and Interleaf.

Working bottom-up is also the best way to get reusable software. The
essence of writing reusable software is to separate the general from
the specific, and bottom-up programming inherently creates such a
separation. Instead of devoting all your effort to writing a single,
monolithic application, you devote part of your effort to building a
language, and part to writing a (proportionately smaller) application
on top of it. What's specific to this application will be concentrated
in the topmost layer. The layers beneath will form a language for
writing applications like this one--and what could be more reusable
than a programming language?

Lisp allows you not just to write more sophisticated programs, but to
write them faster. Lisp programs tend to be short--the language gives
you bigger concepts, so you don't have to use as many. As Frederick
Brooks has pointed out, the time it takes to write a program depends
mostly on its length.0 So this fact alone means that Lisp programs take
less time to write. The effect is amplified by Lisp's dynamic character:
in Lisp the edit-compile-test cycle is so short that programming is
real-time.

Bigger abstractions and an interactive environment can change the way
organizations develop software. The phrase rapid prototyping describes
a kind of programming that began with Lisp: in Lisp, you can often
write a prototype in less time than it would take to write the spec
for one. What's more, such a prototype can be so abstract that it
makes a better spec than one written in English. And Lisp allows you
to make a smooth transition from prototype to production
software. When Common Lisp programs are written with an eye to speed
and compiled by modern compilers, they run as fast as programs written
in any other high-level language.

Unless you already know Lisp quite well, this introduction may seem a
collection of grand and possibly meaningless claims. Lisp transcends
objectoriented programming? You build the language up toward your
programs? Lisp programming is real-time? What can such statements
mean? At the moment, these claims are like empty lakes. As you learn
more of the actual features of Lisp, and see examples of working
programs, they will fill with real experience and take on a definite
shape.

@node A New Approach
@section A New Approach


One of the aims of this book is to explain not just the Lisp language,
but the new approach to programming that Lisp makes possible. This
approach is one that you will see more of in the future. As
programming environments grow in power, and languages become more
abstract, the Lisp style of programming is gradually replacing the old
plan-and-implement model.

In the old model, bugs are never supposed to happen. Thorough
specifications, painstakingly worked out in advance, are supposed to
ensure that programs work perfectly. Sounds good in
theory. Unfortunately, the specifications are both written and
implemented by humans. The result, in practice, is that the
plan-and-implement method does not work very well.

As manager of the OS/360 project, Frederick Brooks was well acquainted
with the traditional approach. He was also acquainted with its
results:

@quotation
Any OS/360 user is quickly aware of how much better it should
be... Furthermore, the product was late, it took more memory than
planned, the costs were several times the estimate, and it did not
perform very well until several releases after the first.0
@end quotation

And this is a description of one of the most successful systems of its
era.

The problem with the old model was that it ignored human limitations. In
the old model, you are betting that specifications won't contain serious
flaws, and that implementing them will be a simple matter of translating
them into code. Experience has shown this to be a very bad bet
indeed. It would be safer to bet that specifications will be misguided,
and that code will be full of bugs.

This is just what the new model of programming does assume. Instead of
hoping that people won't make mistakes, it tries to make the cost of
mistakes very low. The cost of a mistake is the time required to
correct it. With powerful languages and good programming environments,
this cost can be greatly reduced. Programming style can then depend
less on planning and more on exploration.

Planning is a necessary evil. It is a response to risk: the more
dangerous an undertaking, the more important it is to plan
ahead. Powerful tools decrease risk, and so decrease the need for
planning. The design of your program can then benefit from what is
probably the most useful source of information available: the
experience of implementing it.

Lisp style has been evolving in this direction since the 1960s. You
can write prototypes so quickly in Lisp that you can go through
several iterations of design and implementation before you would, in
the old model, have even finished writing out the specifications. You
don't have to worry so much about design flaws, because you discover
them a lot sooner. Nor do you have to worry so much about bugs. When
you program in a functional style, bugs can only have a local
effect. When you use a very abstract language, some bugs
(e.g. dangling pointers) are no longer possible, and what remain are
easy to find, because your programs are so much shorter. And when you
have an interactive environment, you can correct bugs instantly,
instead of enduring a long cycle of editing, compiling, and testing.

Lisp style has evolved this way because it yields results. Strange as
it sounds, less planning can mean better design. The history of
technology is full of parallel cases. A similar change took place in
painting during the fifteenth century. Before oil paint became
popular, painters used a medium, called tempera, that cannot be
blended or overpainted. The cost of mistakes was high, and this tended
to make painters conservative. Then came oil paint, and with it a
great change in style. Oil "allows for second thoughts." 0 This proved
a decisive advantage in dealing with difficult subjects like the human
figure.

The new medium did not just make painters' lives easier. It made
possible a new and more ambitious kind of painting. Janson writes:

Without oil, the Flemish Masters' conquest of visible reality would
have been much more limited. Thus, from a technical point of view,
too, they deserve to be called the "fathers of modern painting," for
oil has been the painter's basic medium ever since.0

As a material, tempera is no less beautiful than oil. But the
flexibility of oil paint gives greater scope to the imagination--that
was the deciding factor.

Programming is now undergoing a similar change. The new medium is the
"object-oriented dynamic language"--in a word, Lisp. This is not to
say that all our software is going to be written in Lisp within a few
years. The transition from tempera to oil did not happen overnight\;
at first, oil was only popular in the leading art centers, and was
often used in combination with tempera. We seem to be in this phase
now. Lisp is used in universities, research labs, and a few
leading-edge companies. Meanwhile, ideas borrowed from Lisp
increasingly turn up in the mainstream: interactive programming
environments, garbage collection, and run-time typing, to name a few.

More powerful tools are taking the risk out of exploration. That's
good news for programmers, because it means that we will be able to
undertake more ambitious projects. The use of oil paint certainly had
this effect. The period immediately following its adoption was a
golden age for painting. There are signs already that something
similar is happening in programming.


@node Welcome to Lisp
@comment  node-name,  next,  previous,  up
@chapter Welcome to Lisp

This chapter aims to get you programming as soon as possible. By the
end of it you will know enough Common Lisp to begin writing programs.

@menu
* Form::
* Evaluation::
* Data::
* List Operations::
* Truth::
* Functions (as programs)::
* Recursion::
* Reading Lisp::
* Input and Output::
* Variables::
* Assignment::
* Functional Programming::
* Iteration::
* Functions as Objects::
* Types::
* Looking Forward::
* Summary::
* Exercises::
@end menu

@node Form
@section Form

Form

It is particularly true of Lisp that you learn it by using it, because
Lisp is an interactive language. Any Lisp system will include an
interactive front-end called the toplevel. You type Lisp expressions
into the toplevel, and the system displays their values.

Lisp usually displays a prompt to tell you that it's waiting for you
to type something. Many implementations of Common Lisp use > as the
toplevel prompt. That's what we'll use here.

One of the simplest kinds of Lisp expression is an integer. If we
enter 1 after the prompt,

> 1
1
>

the system will print its value, followed by another prompt, to say
that it's ready for more.

In this case, the value displayed is the same as what we typed. A
number like 1 is said to evaluate to itself. Life gets more
interesting when we enter expressions that take some work to
evaluate. For example, if we want to add two numbers together, we type
something like:

> (+ 2 3) 
5

In the expression (+ 2 3), the + is called the operator, and the
numbers 2 and 3 are called the arguments.

In everyday life, we would write this expression as 2 + 3, but in Lisp
we put the + operator first, followed by the arguments, with the whole
expression enclosed in a pair of parentheses: (+ 2 3). This is called
prefix notation, because the operator comes first. It may at first
seem a strange way to write expressions, but in fact this notation is
one of the best things about Lisp.

For example, if we want to add three numbers together, in ordinary
notation we have to use + twice, 2 + 3 + 4 while in Lisp we just add
another argument:

( + 2 3 4)

The way we ordinarily use +, it must have exactly two arguments: one
on the left and one on the right. The flexibility of prefix notation
means that, in Lisp, + can take any number of arguments, including
none:

> (+)
0

> (+ 2)
2

> (+ 2 3)
5

> (+ 2 3 4)
9

> (+ 2 3 4 5)
14

Because operators can take varying numbers of arguments, we need
parentheses to show where an expression begins and ends.

Expressions can be nested. That is, the arguments in an expression may
themselves be complex expressions:

> (/ (- 7 1) (- 4 2))
3

In English, this is seven minus one, divided by four minus two.


Another beauty of Lisp notation is: this is all there is. All Lisp
expressions are either atoms, like 1, or lists, which consist of zero
or more expressions enclosed in parentheses. These are valid Lisp
expressions:


2
( + 2 3)
( + 2 3 4)
(/ (- 7 1) ( - 4 2))

As we will see, all Lisp code takes this form. A language like C has a
more complicated syntax: arithmetic expressions use infix notation\;
function calls use a sort of prefix notation, with the arguments
delimited by commas\; expressions are delimited by semicolons\; and
blocks of code are delimited by curly brackets. In Lisp, we use a
single notation to express all these ideas.


@node Evaluation
@section Evaluation

Evaluation

In the previous section, we typed expressions into the toplevel, and
Lisp displayed their values. In this section we take a closer look at
how expressions are evaluated.

In Lisp, + is a function, and an expression like (+ 2 3) is a function
call. When Lisp evaluates a function call, it does so in two steps:

@enumerate
@item First the arguments are evaluated, from left to right. In this case, each argument evaluates to itself, so the values of the arguments are 2 and 3, respectively.

@item The values of the arguments are passed to the function named by
the operator. In this case, it is the + function, which returns 5.

@end enumerate

If any of the arguments are themselves function calls, they are
evaluated according to the same rules. So when (/ ( - 7 1) ( - 4 2))
is evaluated, this is what happens:

@enumerate 
@item Lisp evaluates (- 7 1): 7 evaluates to 7 and 1 evaluates to 1. These values are passed to the function -, which returns 6.

@item Lisp evaluates (- 4 2): 4 evaluates to 4 and 2 evaluates to 2. These values are passed to the function -, which returns 2.

@item The values 6 and 2 are sent to the function /, which returns 3.
@end enumerate


Not all the operators in Common Lisp are functions, but most are. And
function calls are always evaluated this way. The arguments are
evaluated left-to-right, and their values are passed to the function,
which returns the value of the expression as a whole. This is called
the evaluation rule for Common Lisp.

GETTING OUT OF TROUBLE

If you type something that Lisp can't understand, it will display an
error message and put you into a version of the toplevel called a
break loop. The break loop gives experienced programmers a chance to
figure out what caused an error, but initially the only thing you will
want to do in a break loop is get out of it. What you have to type to
get back to the toplevel depends on your implementation of Common
Lisp. In this hypothetical implementation, :abort does it:

> (/ 1 0)
Error: Division by zero. Options: :abort, :backtrace
» :abort
>

Appendix A shows how to debug Lisp programs, and gives examples of
some of the most common errors.

One operator that doesn't follow the Common Lisp evaluation rule is
quote. The quote operator is a special operator, meaning that it has a
distinct evaluation rule of its own. And the rule is: do nothing. The
quote operator takes a single argument, and just returns it verbatim:

> (quote (+ 3 5))
( + 3 5)

For convenience, Common Lisp defines ' as an abbreviation for
quote. You can get the effect of calling quote by affixing a ' to the
front of any expression: > '( + 3 5) (+ 3 5)

It is much more common to use the abbreviation than to write out the
whole quote expression.

Lisp provides the quote as a way of protecting expressions from
evaluation. The next section will explain how such protection can be
useful.


@node Data
@section Data

Data

Lisp offers all the data types we find in most other languages, along
with several others that we don't. One data type we have used already is
the integer, which is written as a series of digits: 256. Another data
type Lisp has in common with most other languages is the string, which
is represented as a series of characters surrounded by double-quotes:
"ora et labora". Integers and strings both evaluate to themselves.

Two Lisp data types that we don't commonly find in other languages are
symbols and lists. Symbols are words. Ordinarily they are converted to
uppercase, regardless of how you type them:

> 'Artichoke
ARTICHOKE

Symbols do not (usually) evaluate to themselves, so if you want to
refer to a symbol, you should quote it, as above.

Lists are represented as zero or more elements enclosed in
parentheses. The elements can be of any type, including lists. You
have to quote lists, or Lisp would take them for function calls:

> '(my 3 "Sons") (MY 3 "Sons") > '(the list (a b c) has 3 elements)
(THE LIST (A B C) HAS 3 ELEMENTS)

Notice that one quote protects a whole expression, including
expressions within it.

You can build lists by calling list . Since LIST is a function, its
arguments are evaluated. Here we see a call to + within a call to LIST
:
> ( LIST 'my (+ 2 1) "Sons")
(MY 3 "Sons")

We are now in a position to appreciate one of the most remarkable
features of Lisp. Lisp programs are expressed as lists. If the
arguments of flexibility and elegance did not convince you that Lisp
notation is a valuable tool, this point should. It means that Lisp
programs can generate Lisp code. Lisp programmers can (and often do)
write programs to write their programs for them.

Such programs are not considered till Chapter 10, but it is important
even at this stage to understand the relation between expressions and
lists, if only to avoid being confused by it. This is why we need the
quote. If a list is quoted, evaluation returns the list itself\; if it
is not quoted, the list is treated as code, and evaluation returns its
value:

> (LIST '( + 2 1) ( + 2 1))
((+ 2 1) 3)

Here the first argument is quoted, and so yields a list. The second
argument is not quoted, and is treated as a function call, yielding a
number.

In Common Lisp, there are two ways of representing the empty list. You
can represent it as a pair of parentheses with nothing between them,
or you can use the symbol NIL. It doesn't matter which way you write
the empty list, but it will be displayed as NIL :

> 0
NIL
> nil
NIL

You don't have to quote NIL (though it wouldn't hurt) because NIL
evaluates to itself.


@node List Operations
@section List Operations

List Operations

The function cons builds lists. If its second argument is a list, it
returns a new list with the first argument added to the front:

> (cons ' a ' (b c d))
(A B C D)

We can build up lists by consing new elements onto an empty list. The
LIST function that we saw in the previous section is just a more
convenient way of consing several things onto NIL :

> (cons ' a (cons (A B) b nil))

> ( LIST \; a >b) (A B)
;

2

The primitive functions for extracting the elements of lists are car
and cdr.° The car of a list is the first element, and the cdr is
everything after the first element:


> (car ' ( a b c))
A


> (cdr ' ( a b c))
(B C)

You can use combinations of car and cdr to reach any element of a
list. If you want to get the third element, you could say:



> (car (cdr (cdr ' ( a b c d ))))
C

However, you can do the same thing more easily by calling t h i r d :


> (third '( a b c d))
C


@node Truth
@section Truth

Truth

In Common Lisp, the symbol t is the default representation for
truth. Like NIL , t evaluates to itself. The function LIST p returns
true if its argument is a list:

> (listp ( a b c))
Y

A function whose return value is intended to be interpreted as truth
or falsity is called a predicate. Common Lisp predicates often have
names that end with p. Falsity in Common Lisp is represented by NIL ,
the empty list. If we give LIST p an argument that isn't a list, it
returns NIL :

> ( LIST p 27)
NIL

Because NIL plays two roles in Common Lisp, the function n u l l ,
which returns true of the empty list.

> (null NIL )
T

and the function not, which returns true if its argument is false,

> (not NIL )
T

do exactly the same thing.

The simplest conditional in Common Lisp is if. It usually takes three
arguments: a test expression, a then expression, and an else
expression. The test expression is evaluated. If it returns true, the
then expression is evaluated and its value is returned. If the test
expression returns false, the else expression is evaluated and its
value is returned:



> (if (listp '(a b c))
    (+ 1 2)
    (+ 5 6))
3

> (if (listp 27)
    (+ 1 2)
    (+ 5 6))
11

Like quote, if is a special operator. It could not possibly be
implemented as a function, because the arguments in a function call
are always evaluated, and the whole point of if is that only one of
the last two arguments is evaluated.

The last argument to if is optional. If you omit it, it defaults to NIL :

> (if (listp 27) (+ 2 3))
 NIL

Although t is the default representation for truth, everything except
NIL also counts as true in a logical context:

> (if 27 1 2)
1

The logical operators and and or resemble conditionals. Both take any
number of arguments, but only evaluate as many as they need to in
order to decide what to return. If all its arguments are true (that
is, not NIL ) , then and returns the value of the last one:

> (and t (+ 1 2))
3

But if one of the arguments turns out to be false, none of the
arguments after that get evaluated. Similarly for or, which stops as
soon as it finds an argument that is true.

These two operators are macros. Like special operators, macros can
circumvent the usual evaluation rule. Chapter 10 explains how to write
macros of your own.


@node Functions (as programs)
@section Functions (as programs)

Functions
You can define new functions with defun. It usually takes three or
more arguments: a name, a list of parameters, and one or more
expressions that will make up the body of the function. Here is how we
might define THIRD :


> (defun our-third (x) (car (cdr (cdr x ) ) ) )
OUR-THIRD

The first argument says that the name of this function will be
our-third. The second argument, the list (x), says that the function
will take exactly one argument: x. A symbol used as a placeholder in
this way is called a variable. When the variable represents an
argument to a function, as x does, it is also called a parameter.

The rest of the definition, (car (cdr (cdr x))), is known as the
body of the function. It tells Lisp what it has to do to calculate the
return value of the function. So a call to our-third returns
(car (cdr (cdr x))), for whatever x we give as the argument:

> (our-third '(a b c d))
C

Now that we've seen variables, it's easier to understand what symbols
are.

They are variable names, existing as objects in their own right. And
that's why symbols, like lists, have to be quoted. A list has to be
quoted because otherwise it will be treated as code\; a symbol has to
be quoted because otherwise it will be treated as a variable.

You can think of a function definition as a generalized version of a
Lisp expression. The following expression tests whether the sum of 1
and 4 is greater than 3:

> (> (+ 1 4) 3)
T

By replacing these particular numbers with variables, we can write a
function that will test whether the sum of any two numbers is greater
than a third:

> (defun sum-greater (x y z) (> (+ x y) z))
SUM-GREATER

> (sum-greater 1 4 3)
T

Lisp makes no distinction between a program, a procedure, and a
function. Functions do for everything (and indeed, make up most of the
language itself). If you want to consider one of your functions as the
main function, you can, but you will ordinarily be able to call any
function from the toplevel. Among other things, this means that you
will be able to test your programs piece by piece as you write them.

@node Recursion
@section Recursion

Recursion

The functions we defined in the previous section called other
functions to do some of their work for them. For example, sum-greater
called + and >. A function can call any function, including itself.

A function that calls itself is recursive. The Common Lisp function
member tests whether something is an element of a list. Here is a
simplified version defined as a recursive function:

(defun our-member (obj lst)
  (if (null lst)
      nil
      (if (eql (car lst) obj)
	  lst
	  (our-member obj (cdr lst)))))

The predicate eql tests whether its two arguments are identical\;
aside from that, everything in this definition is something we have
seen before. Here it is in action:

> (our-member 'b ) '(a b c)) (B C)
> (our-member 'z '(a b c)) NIL

The definition of our-member corresponds to the following English
description. To test whether an object obj is a member of a list lst,
we

1. First check whether lst is empty. If it is, then obj is clearly not
a member of it, and we're done.

2. Otherwise, if obj is the first element of lst, it is a member.

3. Otherwise obj is only a member of lst if it is a member of the rest of lst.

When you want to understand how a recursive function works, it can
help to translate it into a description of this kind.

Many people find recursion difficult to understand at first. A lot of
the difficulty comes from using a mistaken metaphor for
functions. There is a tendency to think of a function as a sort of
machine. Raw materials arrive as parameters\; some of the work is
farmed out to other functions\; finally the finished product is
assembled and shipped out as the return value. If we use this metaphor
for functions, recursion becomes a paradox. How can a machine farm out
work to itself? It is already busy.

A better metaphor for a function would be to think of it as a process
one goes through. Recursion is natural in a process. We often see
recursive processes in everyday life. For example, suppose a historian
was interested in population changes in European history. The process
of examining a document might be as follows:

1. Get a copy of the document.

2. Look for information relating to population changes.

3. If the document mentions any other documents that might be useful,
examine them.

This process is easy enough to understand, yet it is recursive,
because the third step could entail one or more applications of the
same process.

(an even better example could involve installing open source software
that has dependencies.

e.g. to install application x, first install any dependencies;
     in order to install dependency x-prime, you must install
     dependencies y and z)

So don't think of our-member as a machine that tests whether something
is in a list. Think of it instead as the rules for determining whether
something is in a list. If we think of functions in this light, the
paradox of recursion disappears.0


@node Reading Lisp
@section Reading Lisp

Reading Lisp

The pseudo-member defined in the preceding section ends with five
parentheses. More elaborate function definitions might end with seven
or eight. People who are just learning Lisp find the sight of so many
parentheses discouraging. How is one to read, let alone write, such
code? How is one to see which parenthesis matches which?

The answer is, one doesn't have to. Lisp programmers read and write
code by indentation, not by parentheses. When they're writing code,
they let the text editor show which parenthesis matches which. Any
good editor, particularly if it comes with a Lisp system, should be
able to do parenmatching. In such an editor, when you type a
parenthesis, the editor indicates the matching one. If your editor
doesn't match parentheses, stop now and figure out how to make it,
because it is virtually impossible to write Lisp code without it.1

With a good editor, matching parentheses ceases to be an issue when
you're writing code. And because there are universal conventions for
Lisp indentation, it's not an issue when you're reading code
either. Because everyone uses the same conventions, you can read code
by the indentation, and ignore the parentheses.

Any Lisp hacker, however experienced, would find it difficult to read
the definition of our-member if it looked like this:

1 In vi, you can turn on paren-matching with : s e t sm. In Emacs, M-x
lisp-mode is a good way to get it.

(defun our-member (obj lst) (if (null lst) nil (if (eql (car lst) obj) lst (our-member obj (cdr lst)))))

But when the code is properly indented, one has no trouble. You could
omit most of the parentheses and still read it:

defun our-member (obj lst)
if null lst
nil
if eql (car lst) obj
lst
our-member obj (cdr lst)

Indeed, this is a practical approach when you're writing code on
paper. Later, when you type it in, you can take advantage of
paren-matching in the editor.


@node Input and Output
@section Input and Output

Input and Output

So far we have done I/O implicitly, by taking advantage of the
toplevel. For real interactive programs this is not likely to be
enough. In this section we look at a few functions for input and
output.

The most general output function in Common Lisp is format. It takes
two or more arguments: the first indicates where the output is to be
printed, the second is a string template, and the remaining arguments
are usually objects whose printed representations are to be inserted
into the template. Here is a typical example:

> (format t "~A plus ~A equals ~A. ~%" 2 3 ( + 2 3))
2 plus 3 equals 5.
NIL

Notice that two things get displayed here. The first line is displayed
by f ormat. The second line is the value returned by the call to f
ormat, displayed in the usual way by the toplevel. Ordinarily a
function like format is not called directly from the toplevel, but
used within programs, so the return value is never seen.

The first argument to format, t, indicates that the output is to be
sent to the default place. Ordinarily this will be the toplevel. The
second argument is a string that serves as a template for
output. Within this string, each ~A indicates a position to be filled,
and the ~% indicates a newline. The positions are filled by the values
of the remaining arguments, in order.

The standard function for input is read. When given no arguments, it
reads from the default place, which will usually be the toplevel. Here
is a function that prompts the user for input, and returns whatever is
entered:

(defun askem (string)
  (format t "~A" string)
  (read))

It behaves as follows:

> (askem "How old are you?")  How old are you?  29 29

Bear in mind that read will sit waiting indefinitely until you type
something and (usually) hit return. So it's unwise to call read
without printing an explicit prompt, or your program may give the
impression that it is stuck, while in fact it's just waiting for
input.

The second thing to know about read is that it is very powerful: read
is a complete Lisp parser. It doesn't just read characters and return
them as a string. It parses what it reads, and returns the Lisp object
that results. In the case above, it returned a number.

Short as it is, the definition of askem shows something we haven't
seen before in a function. Its body contains more than one
expression. The body of a function can have any number of
expressions. When the function is called, they will be evaluated in
order, and the function will return the value of the last one.

In all the sections before this, we kept to what is called "pure"
Lisp--that is, Lisp without side-effects. A side-effect is some change
to the state of the world that happens as a consequence of evaluating
an expression. When we evaluate a pure Lisp expression like (+ 1 2),
there are no side-effects\; it just returns a value. But when we call
format, as well as returning a value, it prints something. That's one
kind of side-effect.

When we are writing code without side-effects, there is no point in
defining functions with bodies of more than one expression. The value
of the last expression is returned as the value of the function, but
the values of any preceding expressions are thrown away. If such
expressions didn't have sideeffects, you would have no way of telling
whether Lisp bothered to evaluate them at all.


@node Variables
@section Variables

Variables

One of the most frequently used operators in Common Lisp is l e t ,
which allows you to introduce new local variables:


> (let
      ((x 1)
       (y 2))
    (+ x y ))
3

A l e t expression has two parts. First comes a list of instructions
for creating variables, each of the form (variable expression). Each
variable will initially be set to the value of the corresponding
expression. So in the example above, we create two new variables, x
and y, which are initially set to 1 and 2, respectively. These
variables are valid within the body of the l e t .

After the list of variables and values comes a body of expressions,
which are evaluated in order. In this case there is only one, a call
to +. The value of the last expression is returned as the value of the
l e t . Here is an example of a more selective version of askem
written using l e t :

(defun ask-number () (format t "Please enter a number. ")  (let ((val
  (read))) (if (numberp val) val (ask-number))))

This function creates a variable v a l to hold the object returned by
read. Because it has a handle on this object, the function can look at
what you entered before deciding whether or not to return it. As you
probably guessed, numberp is a predicate that tests whether its
argument is a number.

If the value entered by the user isn't a number, ask-number calls
itself. The result is a function that insists on getting a number:

> (ask-number) Please enter a number, a Please enter a number, (ho
hum) Please enter a number. 52 52

Variables like those we have seen so far are called local
variables. They are only valid within a certain context. There is
another kind of variable, called a global variable, that can be
visible everywhere.2



You can create a global variable by giving a symbol and a value to
defparameter:



> (defparameter *glob* 99) *GLOB*

Such a variable will then be accessible everywhere, except in
expressions that create a new local variable with the same name. To
avoid the possibility of this happening by accident, it's
conventionalto give global variables names



2 The real distinction here is between lexical and special variables,
but we will not need to consider this until Chapter 6.


that begin and end with asterisks. The name of the variable we just
created would be pronounced "star-glob-star". You can also define global
constants, by calling defconstant:

(defconstant limit (+ *glob* 1))

There is no'need to give constants distinctive names, because it will
cause an error if anyone uses the same name for a variable. If you want
to check whether some symbol is the name of a global variable or
constant, use boundp:

> (boundp '*glob*)
T


@node Assignment
@section Assignment

Assignment
In Common Lisp the most general assignment operator is setf. We can use
it to do assignments to either kind of variable:

> (setf *glob* 98)
98


> (let ((n 10)) (setf n 2) n)
2

When the first argument to s e t f is a symbol that is not the name of a
local variable, it is taken to be a global variable:



> (setf x ( LIST 'a 'b 'c))
(A B C)

That is, you can create global variables implicitly, just by assigning
them values. In source files, at least, it is better style to use
explicit def parameters.

You can do more than just assign values to variables. The first argument
to setf can be an expression as well as a variable name. In such cases,
the value of the second argument is inserted in the place referred to by
the first:

> (setf (car x) N)
n

> x
(N B C)
;


The first argument to s e t f can be almost any expression that refers
to a particular place. All such operators are marked as "settable" in
Appendix D.

You can give any (even) number of arguments to setf. An expression of
the form (setf a b c d e f) is equivalent to three separate calls to s e
t f in sequence:

(setf a b) (setf c d) (setf e f)


@node Functional Programming
@section Functional Programming

Functional Programming 

Functional programming means writing programs
that work by returning values, instead of by modifying things. It is the
dominant paradigm in Lisp. Most built-in Lisp functions are meant to be
called for the values they return, not for side-effects.

The function remove, for example, takes an object and a list and returns
a new list containing everything but that object:

> (setf lst '(carat))
(CARAT)
> (remove 'a lst) (C R T)

Why not just say that remove removes an object from a list? Because
that's not what it does. The original list is untouched afterwards:

> lst
(CARAT)

So what if you really do want to remove something from a list? In Lisp
you generally do such things by passing the list as an argument to some
function, and using setf with the return value. To removeall the as from
a list x, we say:

( s e t f x (remove ' a x ) )

Functional programming means, essentially, avoiding setf and things like
it. At first sight it may be difficult to imagine how this is even
possible, let alone desirable. How can one build programs just by
returning values?

It would be inconvenient to do without side-effects entirely. However,
as you read further, you may be surprised to discover how few you really
need. And the more side-effects you do without, the better off you'll
be.

One of the most important advantages of functional programming is that
it allows interactive testing. In purely functional code, you can test
each function as you write it. If it returns the values you expect, you
can be confident that it is correct. The added confidence, in the
aggregate, makes a huge difference. You have instant turnaround when you
make changes anywhere in a program. And this instant turnaround enables
a whole new style of programming, much as the telephone, as compared to
letters, enabled a new style of communication.


@node Iteration
@section Iteration

Iteration 

When we want to do something repeatedly, it is sometimes more
natural to use iteration than recursion. A typical case for iteration is
to generate some sort of table. This function

(defun show-squares (start end)
  (do ((i start (+ i 1)))
      ((> i end) 'done)
    (format t "~A ~k~l" i (* i i))))

prints out the squares of the integers from s t a r t to end:

> (show-squares 2 5)
2 4
3 9
4 16
5 25
DONE

The do macro is the fundamental iteration operator in Common Lisp. Like
l e t , do can create variables, and the first argument is a list of
variable specifications. Each element of this list can be of the form

(variable initial update)

where variable is a symbol, and initial and update are
expressions. Initially each variable will be set to the value of the
corresponding initial, on each iteration it will be set to the value of
the corresponding update. The do in show-squares creates just one
variable, i . On the first iteration i will be set to the value of s t a
r t , and on successive iterations its value will be incremented by one.

The second argument to do should be a list containing one or more
expressions. The first expression is used to test whether iteration
should stop. In the case above, the test expression is (> i end). The
remaining expressions in this list will be evaluated in order when
iteration stops, and the value of the last will be returned as the value
of the do. So show-squares will always return done.

The remaining arguments to do comprise the body of the loop. They will
be evaluated, in order, on each iteration. On each iteration the
variables are updated, then the termination test is evaluated, and then
(\if the test failed) the body is evaluated.

For comparison, here is a recursive version of show-squares:

(defun show-squares (i end)
  (if (> i end) 'done
      (progn (format t "~A ~A~%" i (* i i))
	     (show-squares (+ i 1) end))))

The only thing new in this function is progn. It takes any number of
expressions, evaluates them in order, and returns the value of the last.

Common Lisp has simpler iteration operators for special cases. To
iterate through the elements of a list, for example, you would be more
likely to use d o LIST . Here is a function that returns the length of a
list:

(defun our-length (lst)
  (let ((len 0))
    (dolist (obj lst)
      (setf len (+ len 1)))
    len))

Here d o LIST takes an argument of the form

(variable expression),

followed by a body of expressions. The body will be evaluated with
variable bound to successive elements of the list returned by
expression. So the loop above says, for each obj in lst, increment len.

The obvious recursive version of this function would be:

(defun our-length (lst)
  (if (null lst)
      0
      (+ (our-length (cdr lst))
	 1)))

Or, if the list is empty, its length is zero\; otherwise it is the
length of the cdr plus one. This version of o u r - l e n g t h is
cleaner, but because it's not tail-recursive (Section 13.2), it won't be
as efficient.



FUNCTIONS AS OBJECTS

25


@node Functions as Objects
@section Functions as Objects

Functions as Objects

In Lisp, functions are regular objects, like symbols or strings or
lists. If we give the name of a function to function, it will return the
associated object. Like quote, function is a special operator, so we
don't have to quote the argument:

> (function +)
#<Compiled-Function + 17BA4E>

This strange-looking return value is the way a function might be
displayed in a typical Common Lisp implementation.

Until now we have only dealt with objects that look the same when Lisp
displays them as when we typed them in. This convention does not apply
to functions. Internally, a built-in function like + is likely to be a
segment of machine language code. A Common Lisp implementation may
choose whatever external representation it likes.

Just as we can use ' as an abbreviation for quote, we can use #' as an
abbreviation for function:

> #'+
#<Compiled-Function + 17BA4E>

This abbreviation is known as sharp-quote.

Like any other kind of object, we can pass functions as arguments. One
function that takes a function as an argument is apply. It takes a
function and a list of arguments for it, and returns the result of
applying the function to the arguments:

> (apply #'+ ' ( 1 2 3))
6

> (+ 1 2 3)
6

It can be given any number of arguments, so long as the last is a list:



> (apply #'+ 1 2 15 '( 3 4 5))

The function funcall does the same thing but does not need the arguments
to be packaged in a list:

> (funcall #'+ 1 2 3)
6





WHAT IS LAMBDA?

The lambda in a lambda expression is not an operator. It is just a
symbol.0 In earlier dialects of Lisp it had a purpose: functions were
represented internally as lists, and the only way to tell a function
from an ordinary list was to check if the first element was the symbol
lambda. In Common Lisp, you can express functions as lists, but they are
represented internally as distinct function objects. So lambda is no
longer really necessary. There would be no inconsistency in requiring
that functions be denoted as ((x) (+ x 100)) instead of (lambda (x) (+ x
100)) but Lisp programmers were used to beginning functions with the
symbol lambda, so Common Lisp retained it for the sake of tradition.

The defun macro creates a function and gives it a name. But functions
don't have to have names, and we don't need def un to define them. Like
most other kinds of Lisp objects, we can refer to functions
literally. To refer literally to an integer, we use a series of digits\;
to refer literally to a function, we use what's called a lambda
expression. A lambda expression is a list containing the symbol lambda,
followed by a list of parameters, followed by a body of zero or more
expressions. Here is a lambda expression representing a function that
takes two numbers and returns their sum: (lambda (x y) (+ x y)) The list
(x y) is the parameter list, and after it comes the body of the
function. A lambda expression can be considered as the name of a
function. Like an ordinary function na^ne, a lambda expression can be
thefirstelement of a function call,

> ((lambda (x) (+ x 100)) 1)
101

and by affixing a sharp-quote to a lambda expression, we get the corresponding function,


TYPES

27

> (funcall #'(lambda (x) (+ x 100)) 1)
101

Among other things, this notation allows us to use functions without naming them.


@node Types
@section Types

Types 

Lisp has an unusually flexible approach to types. In many
languages, variables are what have types, and you can't use a variable
without specifying its type. In Common Lisp, values have types, not
variables. You could imagine that every object had a label attached to
it, identifying its type. This approach is called manifest typing. You
don't have to declare the types of variables, because any variable can
hold objects of any type.

Though type declarations are never required, you may want to make them
for reasons of efficiency. Type declarations are discussed in Section
13.3.

The built-in Common Lisp types form a hierarchy of subtypes and
supertypes. An object always has more than one type. For example, the
number 27 is of type f ixnum, i n t e g e r , r a t i o n a l , r e a l
, number, atom, and t , in order of increasing generality. (Numeric
types are discussed in Chapter 9.) The type t is the supertype of all
types, so everything is of type t .

 The function typep takes an object and a type specifier, and returns true if the object is of that type:

> (typep 27 ' i n t e g e r )
T

 We will mention the various built-in types as we encounter them.


@node Looking Forward
@section Looking Forward

In this chapter we have barely scratched the surface of Lisp. And yet a
portrait of a very unusual language is beginning to emerge. To start
with, the language has a single syntax to express all program
structure. This syntax is based on the list, which is a kind of Lisp
object. Functions, which are Lisp objects in their own right, can be
expressed as lists. And Lisp is itself a Lisp program, made almost
entirely of Lisp functions no different from the ones you can define
yourself.

Don't worry if the relations between all these ideas are not entirely
clear. Lisp introduces so many novel concepts that it takes some time
to get used to all the new things you can do with it. One thing should
be clear at least: there are some startlingly elegant ideas here.

Richard Gabriel once half-jokingly described C as a language for
writing Unix.0 We could likewise describe Lisp as a language for
writing Lisp. But this is a different kind of statement. A language
that can be written in itself is fundamentally different from a
language good for writing some particular class of applications. It
opens up a new way of programming: as well as writing your program in
the language, you can improve the language to suit your program. If
you want to understand the essence of Lisp programming, this idea is a
good place to begin.



@node Summary
@section Summary

@enumerate
@item Lisp is an interactive language. If you type an expression into the
toplevel, Lisp will display its value.

@item Lisp programs consist of expressions. An expression can be an atom,
or a list of an operator followed by zero or more arguments. Prefix
syntax means that operators can take any number of arguments.

@item The evaluation rule for Common Lisp function calls: evaluate the
arguments left to right, and pass them to the function denoted by the
operator. The quote operator has its own evaluation rule, which is to
return the argument unchanged.

@item Along with the usual data types, Lisp has symbols and
lists. Because Lisp programs are expressed as lists, it's easy to
write programs that write programs.

@item The three basic list functions are cons, which builds a list\; car,
which returns the first element\; and cdr, which returns everything
after the first element.

@item In Common Lisp, t represents true and NIL represents false. In a
logical context, anything except NIL counts as true. The basic
conditional is if. The and and or operators resemble conditionals.

@item Lisp consists mainly of functions. You can define new ones with
defun.

@item A function that calls itself is recursive. A recursive
function should be considered as a process rather than a machine.

@item Parentheses are not an issue, because programmers read and write
Lisp by indentation.

@item The basic I/O functions are read, which includes a complete Lisp
parser, and format, which generates output based on templates.

@item You can create new local variables with l e t , and global
variables with defparameter.

@item The assignment operator is setf. Its first argument can be an
expression.

@item Functional programming, which means avoiding side-effects, is the
dominant paradigm in Lisp.

@item The basic iteration operator is do.

@item Functions are regular Lisp objects. They can be passed as
arguments, and denoted by lambda expressions.

@item In Lisp, values have types, not variables.
@end enumerate


@node Exercises
@section Exercises


@enumerate
@item Describe what happens when the following expressions are evaluated: (a) (b) (c) (d) (+ (- 5 1) (+ 3 7)) ( LIST 1 ( + 2 3)) ( i f ( LIST p 1) (+ 1 2 ) ( + 3 4)) ( LIST (and ( LIST p 3) t ) (+ 1 2))

@item Give three distinct cons expressions that return (a b c).

@item Using car and cdr, define a function to return the fourth element of a list.

@item Define a function that takes two arguments and returns the greater of the two.
@item What do these functions do?
(a) (defun enigma (x) (and (not (null x)) (or (null (car x)) (enigma (cdr x)))))

(b) (defun mystery (x y) (if (null y) nil (if (eql (car y) x) 0 (let ((z (mystery x (cdr y)))) (and z (+ z 1))))))

@item What could occur in place of the x in each of the following exchanges? (a)


> (car (x (cdr ' ( a (b c) d ) ) ) ) B (b)
> (x 13 (/ 1 0)) 13 (c)
> (x # > LIST
1 NIL ) (1)

@item Using only operators introduced in this chapter, define a function that takes a list as an argument and returns true if one of its elements is a list.

@item Give iterative and recursive definitions of a function that (a) takes a positive integer and prints that many dots. (b) takes a list and returns the number of times the symbol a occurs ink.

@item A friend is trying to write a function that returns the sum of all the non-nil elements in a list. He has written two versions of this function, and neither of them work. Explain what's wrong with each, and give a correct version:

(a)

(defun summit ( lst )
(remove nil lst) (apply #' + lst))

(b)

(defun summit (lst) (let ((x (car lst))) (if (null x) (summit (cdr lst)) (+ x (summit (cdr lst))))))
@end enumerate

@node Lists
@chapter Lists


Lists are one of the fundamental data structures in Lisp. In the
earliest dialects they were the only data structure: the name "Lisp"
originally stood for "LISt Processor." But Lisp has long since
outgrown this acronym. Common Lisp is a general-purpose programming
language with a wide variety of data structures.

The development of Lisp programs often echoes the development of Lisp
itself. In the initial version of a Lisp program, you may use a lot
of lists. Then in later versions you may switch to faster,
specialized data structures. This chapter describes the many things
you can do with lists, and uses them to illustrate some general Lisp
concepts.

@menu
* Conses::
* Equality::
* Why Lisp Has No Pointers::
* Building Lists::
* Example-- Compression::
* Access::
* Mapping Functions::
* Trees::
* Understanding Recursion::
* Sets::
* Sequences::
* Stacks::
* Dotted Lists::
* Assoc-lists::
* Example-- Shortest Path::
* Garbage::
* Summary2::
@end menu

@node Conses
@section Conses 
Section 2.4 introduced cons, car, and cdr, the primitive
list-manipulation functions. What cons really does is combine two
objects into a two-part object called a cons. Conceptually, a cons is
a pair of pointers\; the first one is the car and the second is the
cdr.

Conses provide a convenient representation for pairs of any type. The
two halves of a cons can point to any kind of object, including
conses. It is by taking advantage of the latter possibility that we
use conses to build lists.

 One does not tend to think of lists as pairs, but they can be defined
 that way. Any nonempty list can be considered as a pair of the first
 element and the rest of the list. Lisp lists are the embodiment of
 this idea. We use one half of the cons to point to thefirstelement of
 the list, and the other to point to the rest of the list (which is
 either another cons or NIL ) . The convention

 31

page32

LISTS

a Figure 3.1: A one-element list.

nil

a

b

c

Figure 3.2: A list of three elements.

in Lisp has always been to use the car for the first element and the
cdr for the rest of the list. So now car is synonymous with the first
element of a list, and cdr with the rest. Lists are not a distinct
kind of object, but conses linked together in this way.

When we cons something onto NIL ,




> ( s e t f x (cons ' a NIL ) )
(A)

the resulting list consists of a single cons, as shown in Figure 3.1. This way of representing conses is called box notation, because each cons is shown as a box, with pointers for the car and cdr. When we call car and cdr, we get back what those pointers point to:

> (car x)
A
> (cdr x)
NIL

When we build a list with multiple elements, we get a chain of conses:




> (setf y ( LIST 'a 'b 'c)) (A B C) The resulting structure is shown in Figure 3.2. Now when we ask for the cdr of this list, it is itself a list of two elements:

3.2

CONSES

33



Figure 3.3: A nested list.  > (cdr y) (B C) In a list of several
elements, the car pointers get you the elements, and the cdr pointers
get you the rest of the list.

A list can have any kind of object as an element, including another list:

> (setf z ( LIST ' a ( LIST ' b > c) >d))
(A (B C) D)

When this happens, the underlying structure is as shown in Figure
3.3\; the car pointer of the second cons in the chain also points to a
list:

 > (car (cdr z ) )
(B C)

The last two lists we made both have three elements\; it just happens
that the second element of z is also a list. Such a list is called a
nested list, while a list like y that doesn't contain other lists as
elements is called aflat list.

The function consp returns true if its argument is a cons. So LIST p could be defined:

(defun our-listp (x) (or (null x) (consp x)))

Since everything that is not a cons is an atom, the predicate atom could be defined:

(defun our-atom (x) (not (consp x ) ) )

Note that NIL is both an atom and a list.

page34

@node Equality
@section Equality
Each time you call cons, Lisp allocates a new piece of
memory with room for two pointers. So if we call cons twice with the
same arguments, we get back two values that look the same, but are in
fact distinct objects:

> (eql (cons ' a NIL ) (cons ' a NIL ) ) NIL

It would be convenient if we could also ask whether two lists had the
same elements. Common Lisp provides another equality predicate for
this purpose: equal. While eql 1 returns true only if its arguments
are the same object,



> (setf x (cons 'a NIL ) ) (A)
> (eql x x)
T

equal, essentially, returns true if its arguments would print the same:

> (equal x (cons 'a. NIL ) )
T

This predicate works for other kinds of structures besides lists, but a version for lists alone might be defined:

(defun our-equal (x y) (or (eql x y) (and (consp x) (consp y) (our-equal (car x) (car y)) (our-equal (cdr x) (cdr y)))))

As this definition suggests, if some x and y are eql, they are also equal.

@node Why Lisp Has No Pointers
@section Why Lisp Has No Pointers

One of the secrets to understanding Lisp is to realize that variables
have values in the same way that lists have elements. As conses have
pointers to their elements, variables have pointers to their values.

You may have used other languages in which pointers were manipulated
explicitly. In Lisp you never have to do this, because the language
handles pointers for you. We've already seen how this happens with
lists. Something



3.4

WHY LISP HAS NO POINTERS

35

similar happens with variables. Suppose, for example, we set two
variables to the same list:

> ( s e t f x ' ( a b c)) (A B C)
> (setf y x) (A B C)

What actually happens when we set y to the value of x? The location in
memory associated with the variable x does not contain the list
itself, but a pointer to it. When we assign the same value to y, Lisp
copies the pointer, not the list. (Figure 3.4 shows the situation that
results.) So whenever you assign one variable the value of another,
the two variables will have e q l values:

> (eql x y) T

The reason Lisp has no pointers is that every value is conceptually a
pointer. When you assign a value to a variable or store it in a data
structure, what gets stored is actually a pointer to the value. When
you ask for the contents of the data structure or the value of the
variable, Lisp returns what it points to. But all this happens beneath
the surface. You can just put values in structures or "in" variables
without thinking about it.

For efficiency, Lisp will sometimes choose to use an immediate
representation instead of a pointer. For example, since a small
integer takes no more space than a pointer, a Lisp implementation may
as well handle small integers directly instead of handling pointers to
them. But the bottom line for you, the programmer, is that by default
you can put anything anywhere. Unless you have made declarations to
the contrary, you will be able to store any kind of object in any kind
of data structure, including the structure itself.


'in earlier dialects of Lisp the role of eql was played by eq. In Common Lisp, eq is a stricter function, and eql is the default predicate for identity. For an explanation of eq, see page 228.

page36

LISTS


Figure 3.5: Result of copying.

@node Building Lists
@section Building Lists

The function c o p y - LIST takes a list and returns a copy of it. The
new list will have the same elements, but contained in new conses:

> ( s e t f x ' ( a b c) y ( c o p y - LIST x))
 (A B C)

Figure 3.5 shows the structure that results\; the return value is like a new bus with the same passengers. We could think of c o p y - LIST as being defined:

(defun o u r - c o p y - LIST ( lst ) ( i f (atom lst ) lst (cons (car lst ) ( o u r - c o p y - LIST (cdr lst ) ) ) ) )

This definition implies that x and ( c o p y - LIST x) will always be
equal, and never eql unless x is NIL .

Finally, the function append returns the concatenation of any number of lists:

> (append ' ( a b) >(c d) (A B C D E) '(e))

In doing so, it copies all the arguments except the last.

@node Example-- Compression
@section Example-- Compression 

As an example, this section shows how to
perform a simple form of compression on lists. This algorithm goes by
the impressive name of run-length

3.5

EXAMPLE: COMPRESSION

37

(defun compress (x) (if (consp x) (compr (car x) 1 (cdr x)) x))

(defun compr (elt n lst )
  (if (null lst )
      (LIST (n-elts elt n))
      (let ((next (car lst )))
	(if (eql next e l t )
	    (compr e l t (+ n 1) (cdr lst ))
	    (cons ( n - e l t s e l t n) (compr next 1 (cdr lst )))))))

(defun n-elts (elt n) (if (> n 1) (list n elt) elt))

Figure 3.6: Run-length encoding: Compression. ]

encoding. In restaurants, the algorithm works as follows. A waitress
approaches a table of four customers.

 "What'll ya have?" she asks.

 "I'll have the special," the first customer says.

 "Me too," says the second.

 "Sounds good," says the third.

 Everyone looks at the fourth customer. "I'd like a cilantro souffle,"
 he says quietly.

 With a sniff, the waitress turns on her heel and walks back to the
 counter. "Three specials," she shouts to the cook, "and a cilantro
 souffle."

 Figure 3.6 shows how to implement this compression algorithm for
 lists. The function compress takes a list of atoms and returns a
 compressed representation of it:


> (compress ' ( 1 1 1 0 1 0 0 0 0 1 ))
 ((3 1) 0 1 (4 0) 1)

Whenever the same element occurs several times in a row, the sequence
is replaced by a list indicating the element and the number of
occurrences.

Most of the work is done by the recursive compr. This function takes
three arguments: e l t , the element we last saw\; n, the number of
times in a



page38

LISTS

(defun uncompress ( lst ) (if (null lst) nil (let ( (elt ('car lst )) ( r e s t (uncompress (cdr lst )))) ( i f (consf ) e l t ) (append (apply # ' LIST - o f e l t ) rest) (cons e l t r e s t )))))

(defun LIST - o f (n e l t ) (lf (zerop n) nil (cons e l t ( LIST - o f

1

(- n 1) e l t ))))


1

Figure 3 /7: Run-length encoding: Expansion.


row we've seen it\; and lst, the part of the list we've yet to
examine. If there is nothing left to examine, we just call n - e l t s
to get something representing n e l t s . If the first element of lst
is still e l t , we increment n and keep going. Otherwise we get a
compressed list of what we've seen so far, and cons that onto whatever
compr returns for the rest of the list.

To reconstitute a compressed list, we call uncompress (Figure 3.7):

> (uncompress ' ( ( 3 1 ) 0 1 ( 4

( 1 1 1 0 1 0 0 0 0 1)

This function works recursively through the compressed list, copying
atoms verbatim and expanding lists by calling LIST - o f :

> ( LIST - o f 3 'ho)
(HO HO HO)

We don't really need to write LIST - o f . The built-in m a k e - LIST
can do the same thing--but it uses keyword arguments, which haven't
been introduced yet.

In this and other ways, the code in Figures 3.6 and 3.7 is not written
the way an experienced Lisp programmer would write it. It's
inefficient, it does not compress as tightly as it could, and it only
works for lists of atoms. Within a few chapters we'll have seen
techniques that would make it possible to fix all these problems.



3.6

ACCESS

39

LOADING PROGRAMS

The code in this section is our first example of a substantial
program. When one wants to write functions of more than a couple
lines, it's usual to type the code into a file, and then use load to
get Lisp to read the definitions. If we stored the code in Figures 3.6
and 3.7 in a file called "compress. l i s p " , then typing


(load "compress.lisp")

into the toplevel would have the same effect, more or less, as typing
the expressions in that file into the toplevel directly. Note: In some
implementations, the extension for Lispfileswill be " . l s p " rather
than " . l i s p " .

@node Access
@section Access









Common Lisp has additional access functions defined in terms of car
and cdr. To find the element at a given position in a list we call
nth, > (nth 0 ' ( a b c)) A and to find the nth cdr, we call nthcdr: >
(nthcdr 2 ' ( a b c)) (C) Both nth and nthcdr are zero-indexed\; that
is, the elements are numbered starting at zero rather than one. In
Common Lisp, whenever you use a number to refer to an element of a
data structure, the numbering starts at zero.

 The two functions do almost the same thing\; n t h is equivalent to
 car of nthcdr. Without error-checking, nthcdr could be defined as:






(defun our-nthcdr (n lst) (if (zerop n) lst (our-nthcdr ( - n 1) (cdr lst))))









The function zerop just returns true if its argument is zero. The function l a s t returns the last cons in a list: > ( l a s t ' ( a b c)) (C)

page40

LISTS

This is not the same as getting the last element. To get the last
element of a list, you would take the car of l a s t .

 Common Lisp defines f i r s t through t e n t h as functions that
 retrieve the corresponding element of a list. These functions are not
 zero-indexed: (second x) is equivalent to (nth 1 x).

 In addition, Common Lisp defines functions like caddr, which is an
 abbreviation for car of cdr of cdr. All the functions of the form
 c\;tr, where x is a string of up to four as or ds, are defined in
 Common Lisp. With the possible exception of cadr, which refers to the
 second element, it is not a good idea to use them in code that anyone
 else is going to read.

@node Mapping Functions
@section Mapping Functions



Common Lisp provides several functions for calling functions on the
elements of a list. The most frequently used is mapcar, which takes a
function and one or more lists, and returns the result of applying the
function to elements taken from each list, until some list runs out:

 > (mapcar #'(lambda (x) (+ x 10)) ' ( 1 2 3)) (11 12 13) > (mapcar # ' LIST ' ( a b c) ' ( 1 2 3 4)) ((A 1) (B 2) (C 3))

The related m a p LIST takes the same arguments, but calls the
function on successive cdrs of the lists:

 > (maplist #'(lambda (x) x) ' ( a b c)) ((A B C) (B C) (C)) Other mapping functions include mapc, which is discussed on page 88, and mapcan, which is discussed on page 202.

@node Trees
@section Trees

 Conses can also be considered as binary trees, with the
car representing the right subtree and the cdr the left. For example,
the list

 (a (b c) d)

3.8

TREES

41

is also the tree represented in Figure 3.8. (If you rotate it 45°
counterclockwise, you'll see that it is the same as Figure 3.3.)

 Common Lisp has several built-in functions for use with trees. For example, copy-tree takes a tree and returns a copy of it. It might be defined:
(defun our-copy-tree (tr) (if (atom tr) tr (cons (our-copy-tree (car tr)) (our-copy-tree (cdr tr)))))

Compare this to the sketch of c o p y - LIST on page 36\; c o p y - t
r e e copies both the car and cdr of each cons, while c o p y - LIST
copies only the cdr.

 Binary trees without interior nodes are not useful for much. Common
 Lisp includes functions for operating on trees not because one needs
 trees as such, but because one needs a way to do something to a list
 and all the lists within it. For example, suppose we have a list like


(and (integerp x) (zerop (mod x 2)))

and we want to substitute y for x throughout. It won't do to call s u b s t i t u t e , which replaces elements in a sequence: > ( s u b s t i t u t e 'y 'x '(and ( i n t e g e r p x) (zerop (mod x 2 )))) (AND (INTEGERP X) (ZEROP (MOD X 2 )))

page42

LISTS

This call has no effect because the list has three elements, and none
of them are x. What we need here is subst, which replaces elements in
a tree:


> (subst 'y 'x '(and (integerp x) (zerop (mod x 2)))) (AND (INTEGERP Y) (ZEROP (MOD Y 2)))

If we define a version of subst, it comes out looking a lot like copy-tree:

(defun o u r - s u b s t (new old t r e e ) ( i f (eql t r e e old)
new ( i f (atom t r e e ) tree (cons ( o u r - s u b s t new old (car
t r e e )) ( o u r - s u b s t new old (cdr t r e e ))))))

Functions that operate on trees usually have this form, recursing down
both the car and cdr. Such functions are said to be doubly recursive.

@node Understanding Recursion
@section Understanding Recursion


Students learning about recursion are sometimes encouraged to trace
all the invocations of a recursive function on a piece of paper. (A
trace of a recursive function can be seen on page 288.) This exercise
could be misleading: a programmer defining a recursive function
usually does not think explicitly about the sequence of invocations
that results from calling it.

If one always had to think of a program in such terms, recursion
would be burdensome, not helpful. The advantage of recursion is
precisely that it lets us view algorithms in a more abstract way. You
can judge whether or not a recursive function is correct without
considering all the invocations that result when the function is
actually called.

To see if a recursive function does what it's supposed to, all you
have to ask is, does it cover all the cases? For example, here is a
recursive function for finding the length of a list:



(defun len (lst) (if (null lst) 0 (+ (len (cdr lst)) 1)))

We can assure ourselves that this function is correct by verifying two things: 1. That it works for lists of length 0.

3.10

SETS

43

2. Given that it works for lists of length n, that it also works for
lists of length n+1. If we can establish both points, then we know
that the function is correct for all possible lists.

 Our definition obviously satisfies the first point: if lst is NIL ,
 the function immediately returns 0. Now suppose that the function
 works for lists of length n. We give it a list of length n-f-1. The
 definition says that the function will return the len of the cdr of
 this list, plus 1. The cdr is a list of length n. We know by our
 assumption that its l e n is n. Thus the l e n of the whole list is
 n+1.

 This is all we need to know. The secret to understanding recursion is
 a lot like the secret for dealing with parentheses. How do you see
 which parenthesis matches which? You don't have to. How do you
 visualize all those invocations? You don't have to.

 With more complicated recursive functions, there might be more cases,
 but the procedure is the same. For example, with o u r - c o p y - t
 r e e (page 41) we would have to consider three cases: atoms, single
 conses, and trees of n+1 conses. The first case (here, lists of
 length 0) is known as the base case. When a recursive function
 doesn't behave as you intended, it is usually because the base case
 is wrong. It is a common error to omit the base case entirely, as in
 this incorrect definition of member:2



(defun our-member (obj lst ) (if (eql (car lst ) obj) lst (our-member obj (cdr lst ))))

; wrong

We need the initial n u l l test to ensure that the recursion stops
when it gets to the end of the list without finding what it's looking
for. This version would go into an infinite loop if the object we
sought wasn't in the list. Appendix A looks at this kind of problem in
more detail.

 Being able to judge whether or not a recursive function is correct is
 only the first half of understanding recursion. The other half is
 being able to write a recursive function that does what you
 want. Section 6.9 deals with this question.
 
@node Sets
@section Sets


 Lists are a good way to represent small sets. Every
element of a list is a member of the set it represents:


2 The ; wrong in this definition is a comment. In Lisp code, everything from a semicolon to the end of the line is ignored.

44

> (member 'b (B C)
;

LISTS

( a b c))

When member returns true, instead of simply returning t, it returns
the part of the list beginning with the object it was looking
for. Logically, a cons serves just as well as t, and this way the
function returns more information.

 By default, member compares objects using eql. You can override this
 default by using something called a keyword argument. Many Common
 Lisp functions take one or more keyword arguments. The unusual thing
 about these arguments is that they are not matched with the
 corresponding parameters by their position, but by special tags,
 called keywords, that must precede them in the call. A keyword is a
 symbol preceded by a colon.

 One of the keyword arguments accepted by member is a : t e s t
 argument. If you pass some function as the : t e s t argument in a
 call to member, then that function will be used to test for equality
 instead of eql. So if we want to find a member of a list that is
 equal to a given object, we might say:

 > (member ' ( a ) ' ( ( a ) (z)) : t e s t # ' e q u a l ) ((A) (Z))

Keyword arguments are always optional. If any are included in a call,
they come last\; if more than one keyword argument is given, their
order doesn't matter.

 The other keyword argument accepted by member is a : key argument. By
 providing this argument you can specify a function to be applied to
 each element before comparison:

 > (member ' a \; ( ( a b) ( e d )) ((A B) (C D)) :key # ' c a r )





In this example, we asked if there was an element whose car was a.

 If we wanted to give both keyword arguments, we could give them in
 either order. The following two calls are equivalent:

 > (member 2 '((1) (2)) :key #\;car :test #'equal) ((2)) > (member 2 >((1) (2)) :test #'equal :key #>car) ((2)) Both ask if there is an element whose car is equal to 2. If we want to find an element satisfying an arbitrary predicate--like oddp, which returns true for odd integers--we can use the related member-if: > (member-if #>oddp ' ( 2 3 4)) (3 4)

3.11

SEQUENCES

45

We could imagine a limited version of member-if being written:





(defun our-member-if (fn lst ) (and (consp lst ) (if ( funcall fn (car lst )) lst (our-member-if fn (cdr lst )))))



The function adjoin is like a conditional cons. It takes an object and
a list, and conses the object onto the list only if it is not already
a member:

 > (adjoin 'b '(a b c)) (A B C) > (adjoin  z '(a b c)) (Z A B C)

 In the general case it takes the same keyword arguments as
 member. The operations of set union, intersection, and complement are
 implemented by the functions union, i n t e r s e c t i o n , and s e
 t - d i f f e r e n c e . These functions expect exactly two lists
 (but also take the same keyword arguments as member).

 > (union ' ( a b c) '(c b s )) (A C B S) > ( i n t e r s e c t i o n
   ' ( a b c) ' ( b b c)) (B C) > ( s e t - d i f f e r e n c e ' ( a
   b c d e) ' ( b e )) (A C D)

Since there is no notion of ordering in a set, these functions do not
necessarily bother to preserve the order of elements found in the
original lists. The call to s e t - d i f f e r e n c e might just as
well have returned (d c a ) , for example.

@node Sequences
@section Sequences 

Another way to think of a list is as a series of
objects in a particular order. In Common Lisp, sequences include both
lists and vectors. This section introduces some of the sequence
functions that are especially applicable to lists. Operations on
sequences are covered in more detail in Section 4.4.

The function length returns the number of elements in a sequence:
> (length >(a b c)) 3

page46

LISTS

We wrote a version of this function (limited to lists) on page 24.

 To copy part of a sequence, we use subseq. The second argument
 (required) is the position of the first element to be included, and
 the third argument (optional) is the position of the first element
 not to be included.

 > (subseq ' ( a b c d) 1 2 ) (B)
> (subseq (a b c d) 1) (B C D)

If the third argument is omitted, the subsequence goes all the way to the end of the original sequence.

 The function r e v e r s e returns a sequence with the same elements
 as its argument, but in the reverse order: > ( r e v e r s e >(a b
 c)) (C B A)

A palindrome is a sequence that reads the same in either
direction--for example, (a b b a ) . If a palindrome has an even
number of elements, then the second half will be a mirror of the
first. Using length, subseq, and r e v e r s e , we can define a
function

(defun mirror? (s) (let ((len (length s))) (and (evenp len) (let ((mid ( / len 2))) (equal (subseq s 0 mid) (reverse (subseq s mid)))))))

that detects such palindromes: > (mirror? T '(abba))

Common Lisp has a built-in sort function called s o r t . It takes a
sequence and a comparison function of two arguments, and returns a
sequence with the same elements, sorted according to the function:

 > ( s o r t ' ( 0 2 1 3 8 ) #>>) (83210)

You have to be careful when using s o r t , because it's
destructive. For efficiency reasons, s o r t is allowed to modify the
sequence given to it as an argument. So if you don't want your
original sequence modified, pass a copy.0

 Using s o r t and nth, we can write a function that takes an integer
 n, and returns the nth greatest element of a list:



3.12

STACKS

47


(defun nthmost (n lst ) (nth (- n 1) (sort (copy-list lst) #'>)))

We subtract one from the integer because n t h is zero-indexed, but it
would be unintuitive if nthmost were.

 > (nthmost 2 ' ( 0 2 1 3 8)) 3

With some effort we could write a more efficient version of this
function.

 The functions every and some take a predicate and one or more
 sequences. When given just one sequence, they test whether the
 elements satisfy the predicate:

 > (every #'oddp ' ( 1 3 5)) T
> (some #'evenp ' ( 1 2 3)) T

If they are given more than one sequence, the predicate must take as
many arguments as there are sequences, and arguments are drawn one at
a time from all the sequences:

 > (every #>> ' ( 1 3 5) ' ( 0 2 4)) T

If the sequences are of different lengths, the shortest one determines
the number of tests performed.

@node Stacks
@section Stacks


The representation of lists as conses makes it natural
to use them as pushdown stacks. This is done so often that Common Lisp
provides two macros for the purpose: (push x y) pushes x onto the
front of the list v, and (pop x) removes and returns the first element
of the list x.

 Both are defined in terms of setf. It's easy to translate calls if
 the arguments are constants or variables. The expression

 (push obj lst )

is equivalent to

(setf lst (cons obj lst ))

page48

LISTS



F i g u r e 3 . 9 : Effect of push and pop.

and the expression

(pop lst )

is equivalent to


(let ((x (car lst))) (setf lst (cdr lst)) x)

 So, for example:

> (setf x >(b)) (B)
> (push 'a x) (A B)
> x (A B)
> (setf y x) (A B)
> (pop x) A
> x (B)
> y (A B)

All this follows from the equivalences given above. Figure 3.9 shows
the structure that remains after these expressions are evaluated.

You could use push to define an iterative version of r e v e r s e for
lists:



(defun o u r - r e v e r s e ( lst ) (let ((ace NIL )) (dolist (elt lst) (push e l t ace)) ace))


3.13

DOTTED LISTS

49

In this version we start with an empty list and push each element of
lst onto it. When we're finished, the last element of lst will be on
the front.

 The pushnew macro is a variant of push that uses adjoin instead of
 cons:

 > (let ((x ' ( a b ))) (pushnew 'c x) (pushnew 'a x) x) (C A B)

Here, c gets pushed onto the list, but a, because it is already a
member, does not.

@node Dotted Lists
@section Dotted Lists


The kind of lists that can be built by calling LIST are more precisely
known as proper lists. A proper list is either NIL , or a cons whose
cdr is a proper list. That is, we could define a predicate that would
return true only for proper lists as:3


(defun proper-list? (x) (or (null x) (and (consp x) (proper-list? (cdr x)))))

All the lists we've built so far have been proper lists.

Conses are not just for building lists, however. Whenever you need a
structure with two fields you can use a cons. You will be able to use
car to refer to the first field and cdr to refer to the second.

 > (setf p a i r (cons ' a >b)) (A . B)

Because this cons is not a proper list, it is displayed in dot
notation. In dot notation, the car and cdr of each cons are shown
separated by a period. The structure of this cons is shown in Figure
3.10.

 A cons that isn't a proper list is called a dotted list. This is not
 a very good name, because conses that aren't proper lists are usually
 not meant to represent lists at all: (a . b) is just a two-part data
 structure.

 You could express proper lists in dot notation as well, but when Lisp
 displays a proper list, it will always use regular list notation:


3 This description is a little misleading, because the function would
not return NIL for everything that wasn't a proper list. If given a
cdr-circular list, it would fail to terminate. Circular lists are
covered in Section 12.7.



page50

LISTS

a

b

Figure 3.10: A cons used as a pair.

a

b

e d

Figure 3.11: A dotted list.

> '(a . (b . (c . NIL ))) (A B C)

Incidentally, notice the
  correspondence between the way this list looks in dot notation and
  the way it looks in box notation in Figure 3.2.

 There is an intermediate form of notation, between list notation and
 pure dot notation, for dotted lists whose cdrs are conses:

 > (cons 'a (cons 'b (cons ' c (A B C . D)
J

d)))

Such conses are displayed like proper lists, except that the final cdr
is shown, preceded by a period. The structure of this list is shown in
Figure 3.11\; notice how similar it is to the structure shown in
Figure 3.2.

 So there are actually four ways you could denote the list (a b),

(a (a (a (a . (b . NIL )) . (b)) b . nil) b)

though when Lisp displays this list, it will always use the latter
form.





3.75

ASSOC-LISTS

51

@node Assoc-lists
@section Assoc-lists


It is also natural to use conses to represent mappings. A list of
conses is called an assoc-list or alist. Such a list could represent a
set of translations, for example:

> (setf trans '((+ . "add")
		(- . "subtract" )))
((+ . "add") (- . "subtract" ))

Assoc-lists are slow, but convenient in the first stages of a
program. Common Lisp has a built-in function, assoc, for retrieving
the pair associated with a given key:

> (assoc '+ trans)
(+ . "add")

> (assoc '* trans)
NIL

If assoc doesn't find what it's looking for, it returns NIL . We could
write a limited version of assoc as:

(defun our-assoc (key alist)
  (and (consp alist)
       (let ((pair (car alist)))
	 (if (eql key (car pair))
	     pair
	   (our-assoc key (cdr alist))))))

Like member, the real assoc takes keyword arguments, including :test
and :key. Common Lisp also defines an assoc-if , which is to
assoc what member-if is to member.

@node Example-- Shortest Path
@section Example-- Shortest Path


Figure 3.12 contains a program for finding the shortest path through a
network. The function shortest-path takes a start node, a
destination node, and a network, and returns the shortest path, if
there is one.

 In this example, nodes are represented as symbols, and networks are
 represented as assoc-lists with elements of the form

 (node . neighbors)

So the minimal network shown in Figure 3.13 would be represented as

(setf min '((a b c) (b c) (c d)))

page52

LISTS

(defun shortest-path (start end net) (bfs end (list (list start)) net))

(defun bfs (end queue net) (if (null queue) nil (let ((path (car queue))) (let ((node (car path))) (if (eql node end) (reverse path) (bfs end (append (cdr queue) (new-paths path node net)) net))))))

(defun new-paths (path node net) (mapcar #'(lambda (n) (cons n path)) (cdr (assoc node net))))

Figure 3.12: Breadth-first search

and to find the nodes we can reach from a we would say:

 > (cdr (assoc ' a min)) (B C)

The program in Figure 3.12 works by searching the network
breadth-first. To search breadth-first you have to maintain a queue of
unexplored nodes. Each time you get to a node, you check to see if it
is the one you want. If not, you append each of its children to the
end of the queue, then take a node from



3.16

EXAMPLE: SHORTEST PATH

53

the front of the queue and continue the search there. By always
putting deeper nodes at the end of the queue, we ensure that the
network gets searched one layer at a time.

 The code in Figure 3.12 represents a slight complication of this
 idea. We don't just want to find the destination, but to keep a
 record of how we got there. So instead of maintaining a queue of
 nodes, we maintain a queue of paths we've followed, each of which is
 a list of nodes. When we take an element from the queue to continue
 the search, it will not be a node but a list, with the node on the
 front.

 The function bf s does the searching. Initially there will be only
 one element in the queue, a path representing the start node with no
 history. So s h o r t e s t - p a t h calls bf s with ( LIST ( LIST s
 t a r t )) as the initial queue.

 Within bf s the first thing to consider is whether there are any
 nodes left to explore. If the queue is empty, bf s returns NIL to
 indicate that no path could be found. If there are still nodes to
 search, bf s looks at the element on the front of the queue. If the
 car is the node we're looking for, we've found a path and we just
 return it, reversing for readability. If we haven't found the node
 we're looking for, it might still be a descendant of the current
 node, so we add each of its children (or paths for each of them) to
 the end of the queue. Then we call bf s recursively to continue
 searching the rest of the queue.

 Because bf s searches breadth-first, the first path it finds will be
 the shortest, or one of the shortest:

 > (shortest-path 'a 'd min)
 (A C D)

Here is what the queue looks like in successive calls to bfs:
((A)) ((B A) (C A)) ((C A) (C B A)) ((C B A) (DC A)) ((D C A) (D C B A))

 The second element in a queue becomes the first element in the next
 queue. The first element in a queue becomes the cdr of any new
 elements at the end of the next queue.

 The code in Figure 3.12 is not the fastest way to search a network,
 but it does give an idea of the versatility of lists. In this simple
 program we use lists in three distinct ways: we use a list of symbols
 to represent a path, a list of paths to represent the queue used in
 breadth-first search,4 and an assoc-list to represent the network
 itself.


4 Section 12.3 will show how to implement queues more efficiently.

page54

LISTS


@node Garbage
@section Garbage
Lists can be slow for several reasons. They offer
sequential instead of random access, so retrieving a given element
takes longer in a list than an array, for the same reason that it
takes longer to find something on a tape than on a disk. Internally,
conses tend to be represented as pointers, so traversing a list means
traversing a series of pointers, instead of simply incrementing an
index, as in an array. But these two costs can be small compared to
the cost of allocating and recycling cons cells.

 Automatic memory management is one of Lisp's most valuable
 features. The Lisp system maintains a segment of memory called the
 heap. The system keeps track of unused memory in the heap and doles
 it out as new objects are created. The function cons, for example,
 returns a newly allocated cons. Allocating memory from the heap is
 sometimes generically known as consing.

 If such memory were never freed, Lisp would run out of space for new
 objects and have to shut down. So the system must periodically search
 through the heap, looking for memory that is no longer needed. Memory
 that is no longer needed is called garbage, and the scavenging
 operation is called garbage collection, or GC.

 Where does garbage come from? Let's create some:

> (setf lst (list 'a >b )c)) (A B C) > (setf lst nil) NIL

Initially we call LIST , which calls cons, which allocates new cons
cells on the heap. In this case we made three. After we set lst to NIL
, we no longer have any way of reaching the old value of lst, the list
(a b c) .5

 Since we have no way of reaching this list, it might as well not
 exist. Objects that we no longer have any way of reaching are
 garbage. The system can safely reuse these three cons cells.

 This way of managing memory is a great convenience to the
 programmer. You never have to allocate or deallocate memory
 explicitly. And this means that you never have to deal with the bugs
 that come from doing so. Memory leaks and dangling pointers are
 simply impossible in Lisp.

 But, like any technical advance, automatic memory management can work
 against you if you're not careful. The costs associated with using
 and recycling heap space are sometimes referred to simply as the
 costs of consing. This is reasonable, because unless a program never
 throws anything away,


5 Actually, we do have a way of reaching the list, for a bit. The
globals *, **, and *** are always set to the the last three values
returned to the toplevel. These variables are useful in debugging.



SUMMARY

55

most of those conses are going to end up as garbage sooner or
later. The trouble with consing is, allocating storage and scavenging
memory to reclaim it can be expensive compared to the routine
operations of a program. Recent research has produced greatly improved
garbage collection algorithms, but consing will always cost something,
and in some existing Lisp systems, it is quite expensive.

 Unless you're careful, it's easy to write programs that cons
 excessively. For example, remove has to copy all the conses up to the
 last element removed from a list. You can avoid some of this consing
 by using destructive functions, which try to re-use most of the
 structure of the lists passed to them as arguments. Destructive
 functions are discussed in Section 12.4.

 While it's easy to write programs that cons a lot, it's possible to
 write programs that don't cons at all. The typical approach would be
 to write the initial version of a program in a purely functional
 style and using a lot of lists. As the program evolves, you can use
 destructive operations and/or other data structures in critical
 portions of the code. But it's hard to give general advice about
 consing, because some Lisp implementations now do memory management
 so well that it can sometimes be faster to cons than not to. The
 whole issue is covered in more detail in Section 13.4.

 Consing is ok in prototypes and experiments, at least. And if you
 take advantage of the flexibility that lists give you in the early
 stages of a program, you're more likely to produce something that
 survives to the later stages.



@node Summary2
@section Summary2


@enumerate
@item A cons is a two-part data structure. Lists are made of conses
linked together.

@item The predicate equal is less strict than eql. Essentially, it
returns true if its arguments print the same.

@item All Lisp objects behave like pointers. You never have to manipulate
pointers explicitly.



@item You can copy lists with c o p y - LIST , and join their elements
with append.



@item Run-length encoding is a simple compression algorithm for use in
restaurants.



@item Common Lisp has a variety of access functions defined in terms of
car and cdr.


@item Mapping functions apply a function to successive elements, or
successive tails, of a list.



@item Operations on nested lists are sometimes considered as operations
on trees.



@item To judge a recursive function, you only have to consider whether it
covers all the cases.



@item Lists can be used to represent sets. Several built-in functions
view lists this way.



@item Keyword arguments are optional, and are identified not by
position, but by symbolic tags that precede them.



@item Lists are a subtype of sequences. Common Lisp has a large number
of sequence functions.



@item A cons that isn't a proper list is called a dotted list.


@item Lists with conses as elements can be used to represent
mappings. Such lists are called assoc-lists.



@item Automatic memory management saves you from dealing with memory
allocation, but generating excessive garbage can make programs slow.
@end enumerate


Exercises

1. Show the following lists in box notation: (a) (a b ( e d )) (b) (a (b (c ( d )))) (c) ( ( ( a b) c) d) (d) (a (b . c) . d)

2. Write a version of union that preserves the order of the elements in the original lists: > (new-union ' ( a b c) (A B C D) '(bad))

3. Define a function that takes a list and returns a list indicating the number of times each (eql) element appears, sorted from most common element to least common: > (occurrences ' ( a b a d a c d e a )) ((A . 4) (C . 2) (D . 2) (B . 1))

3.16

EXERCISES

57

4. Why does (member ' ( a ) ' ( ( a ) ( b ))) return NIL ?

 5. Suppose the function pos+ takes a list and returns a list of each
 element plus its position:

> (pos+ ' ( 7 5 1 4 )) (7 6 3 7)

 Define
 this function using (a) recursion, (b) iteration, (c) mapcar.



6. After years of deliberation, a government commission has decided that lists should be represented by using the cdr to point to the first element and the car to point to the rest of the list. Define the government versions of the following functions: (a) cons (b) LIST (c) length (for lists) (d) member (for lists\; no keywords)

7. Modify the program in Figure 3.6 to use fewer cons cells. (Hint: Use dotted lists.)

8. Define a function that takes a list and prints it in dot notation: > (showdots ' ( a b c)) (A . (B . (C . NIL))) NIL

9. Write a program to find the longest finite path through a network represented as in Section 3.15. The network may contain cycles.



@node Specialized Data Structures
@chapter Specialized Data Structures


The preceding chapter discussed the list, Lisp's most versatile data
structure. This chapter shows how to use Lisp's other data structures:
arrays (including vectors and strings), structures, and hash
tables. They may not be as flexible as lists, but they can make access
faster, and take up less space.

@menu 
* Arrays::
* Example-- Binary Search::
* Strings and Characters::
* Sequences--vectors and lists::
* Example-- Parsing Dates::
* Structures::
* Example-- Binary Search Trees::
* Hash Tables::
@end menu


@node Arrays
@section Arrays


In Common Lisp, you can make an array by calling make-array with a
list of dimensions as the first argument. To make a 2x3 array we would
say:

 > ( s e t f a r r (make-array '(2 3) : i n i t i a l - e l e m e n t NIL )) #<Simple-Array T (2 3) BFC4FE>

Arrays in Common Lisp can have at least seven dimensions, and each
dimension can have at least 1023 elements.

 The : i n i t i a l - e l e m e n t argument is optional. If it is
 provided, the whole array will be initialized to that value. The
 consequences of trying to retrieve an element of an uninitialized
 array are undefined.

 To retrieve an array element we call aref. As usual for Common Lisp
 access functions, aref is zero-indexed:

 > (aref a r r 0 0)
NIL

58

4.2

ARRAYS

59


To replace some element of an array, we use s e t f with aref:

 > (setf (aref a r r 0 0) 'b) B
> (aref a r r 0 0) B

To denote a literal array, we use the #na syntax, where n is the
number of dimensions in the array. For example, we could denote an
array equivalent to a r r as:

 #2a((b NIL NIL ) ( NIL NIL NIL )) If the global * p r i n t - a r r
  a y * is t, arrays will be displayed in this form:

 > (setf * p r i n t - a r r a y * t ) T > arr #2A((B NIL NIL) (NIL NIL NIL))

If you want just a one-dimensional array, you can give an integer
instead of a list as the first argument to make-array:

 > (setf vec (make-array 4 : i n i t i a l - e l e m e n t NIL ))
#(NIL NIL NIL NIL)

 A one-dimensional array is also called a vector. You can create and
 fill one in a single step by calling vector, which will return a
 vector of whatever arguments you give it:

> (vector "a" 'b 3)
#(*'a\" B 3)

A literal vector can be expressed using this syntax, just as a literal
array can be expressed using #na.

 You can use aref for vector access, but there is a faster function
 called svref for use with vectors.

 > (svref vec 0) NIL

The "sv" in the name stands for "simple vector," which is what all
vectors are by default.1


1 A simple array is one that is neither adjustable, nor displaced, nor
has a fill-pointer. Arrays are simple by default. A simple vector is a
simple array of one dimension that can contain elements of any type.



page60

SPECIALIZED DATA STRUCTURES





(defun bin-search (obj vec) (let ((len (length vec))) (and (not (zerop len)) (finder obj vec 0 ( - len 1)))))





(defun finder (obj vec start end) (let ((range ( - end start))) (if (zerop range) (if (eql obj (aref vec start)) obJ ! !
nil) (let ((mid (+ start (round ( / range 2))))) (let ((obj2 (aref vec mid))) (if (< obj obj2) (finder obj vec start ( - mid D) (if (> obj obj2) (finder obj vec (+ mid 1) end) obj)))))))

Figure 4.1: Searching a sorted vector.

 Common Lisp has one other data structure: the instance. Instances are
covered in Chapter 11, which describes CLOS.


@node Example-- Binary Search
@section Example-- Binary Search


As an example, this section shows how to write a function to search
for an object in a sorted vector. If we know that a vector is sorted,
we can do better than f ind (page 65), which must look at each element
in turn. Instead we jump right into the middle of the vector. If the
middle element is the object we're looking for, then we're
done. Otherwise, we continue searching in either the left or right
half of the vector, depending on whether the object was less than or
greater than the middle element.

 Figure 4.1 contains a function that works this way. Two functions
 actually: b i n - s e a r c h sets the initial bounds and sends
 control to finder, which searches for obj between the s t a r t t h
 and endth elements of a vector vec.

 If the range to be searched has narrowed to one element, then finder
 returns that element if it is obj, and NIL otherwise. If the range
 includes several elements, we find the middle (round returns the
 nearest integer to its argument) and look at the element there (obj
 2). If obj is less than obj 2, the search continues recursively in
 the left half of the vector. If it's greater, the search continues in
 the right half of the vector. The only remaining alternative is that
 obj = obj 2, in which case we've found what we were looking for, and
 simply return it.



4.3

STRINGS AND CHARACTERS

61

COMMENTING CONVENTIONS

In Common Lisp code, anything following a semicolon is treated as a
comment. Some Lisp programmers use multiple semicolons to indicate the
level of the comment: four semicolons in a heading, three in a
description of a function or macro, two to explain the line below, and
one when a comment is on the same line as the code it applies
to. Using this convention, Figure 4.1 might begin:






\;\;\;\; Utilities for operations on sorted vectors.

\;\;\; Finds an
element in a sorted vector.

(defun bin-search (obj vec) (let ((len
(length vec))) ;; if a real vector, send it to finder
 (and (not (zerop len)) ; returns nil if empty
(finder obj vec 0 ( - len 1)))))

For extensive comments, it may be preferable to use the # I... I #
readmacro. Everything between a # I and I # is ignored by read. 0



If we insert the following line at the beginning of finder,

 (format t "~A~°/8" (subseq vec s t a r t (+ end 1)))

 then we can watch as the number of elements left to be searched is
 halved in each step:

 > (bin-search 3 #(0 1 2 3 4 5 6 7 8 9))
 #(0123456789) #(0 1 2 3) #(3) 3

@node Strings and Characters
@section Strings and Characters


Strings are vectors of characters. We denote a constant string as a
series of characters surrounded by double-quotes, and an individual
character c as #\c.

 Each character has an associated integer--usually, but not
 necessarily, the ASCH number. In most implementations, the function
 char-code returns



page62

SPECIALIZED DATA STRUCTURES

the number associated with a character, and code-char returns the
character associated with a number.0

 The functions char< (less than), char<= (less than or equal), char=
 (equal), char>= (greater than or equal), char> (greater than), and
 char/= (different) compare characters. They work like the numeric
 comparison operators described on page 146.

 > ( s o r t "elbow" #'char<) "below"

 Because strings are vectors, both sequence functions and array
 functions work on them. You could use aref to retrieve elements, for
 example,

 > (aref "abc" 1) #\b

but with a string you can use the faster char:

 > (char "abc" 1) #\b

You can use s e t f with char (or aref) to replace elements:

 > (let ( ( s t r (copy-seq "Merlin"))) ( s e t f (char s t r 3) #\k) str) "Merkin"

If you want to compare two strings, you can use the general equal, but
there is also a function s t r i n g - e q u a l that ignores case:

 > (equal "fred" "fred") T
> (equal "fred" "Fred") NIL
> (string-equal "fred" "Fred") T

Common Lisp provides a large number of functions for comparing and
manipulating strings. They are listed in Appendix D, starting on page
364.

 There are several ways of building strings. The most general is to
 use format. Calling format with NIL as the first argument makes it
 return as a string what it would have printed:

 > (format nil "~A or ~A" "truth" "dare")
"truth or dare"

4.4

SEQUENCES

63

But if you just want to join several strings together, you can use
concatenate, which takes a symbol indicating the type of the result,
plus one or more sequences:

 > (concatenate ' s t r i n g "not " "to worry") "not to worry"

@node Sequences--vectors and lists
@section Sequences--vectors and lists





In Common Lisp the type sequence includes both lists and vectors (and
therefore strings). Some of the functions that we have been using on
lists are actually sequence functions, including remove, length,
subseq, reverse, sort, every, and some. So the function that we wrote
on page 46 would also work with other kinds of sequences:

 > (mirror? "abba") T

We've already seen four functions for retrieving elements of
sequences: nth for lists, aref and svref for vectors, and char for
strings. Common Lisp also provides a function e l t that works for
sequences of any kind:

 > (elt ' (a b c) 1) B

For sequences of specific types, the access functions we've already
seen should be faster, so there is no point in using e l t except in
code that is ^supposed to work for sequences generally.

 Using e l t , we could write a version of mirror? that would be more
 efficient for vectors:

(defun mirror? (s) (let ((len (length s))) (and (evenp len) (do
((forward 0 (+ forward 1)) (back ( - len 1) ( - back 1))) ((or (>
forward back) (not (eql (elt s forward) (elt s back)))) (> forward
back))))))

This version would work with lists too, but its implementation is
better suited to vectors. The frequent calls to e l t would be
expensive with lists, because



page64

SPECIALIZED DATA STRUCTURES

lists only allow sequential access. In vectors, which allow random
access, it is as cheap to reach one element as any other.

 Many sequence functions take one or more keyword arguments from the standard set listed in this table:


PARAMETER PURPOSE DEFAULT

:key :test :from-end :start :end

a function to apply to each element
the test function for comparison if true,
work backwards
position at which to start
position, if any, at which to stop

identity eql nil 0 j nil |



One function that takes the full set is p o s i t i o n , which
returns the position of an element in a sequence, or NIL if it is not
found. We'll use p o s i t i o n to illustrate the roles of the
keyword arguments.



> (position #\a "fantasia")
1
> (position #\a "fantasia" :start 3 :end 5)
4

The second example asks for the position of the first a between the
fourth and sixth characters. The : s t a r t argument is the position
of the first element to be considered, and defaults to the first
element of the sequence. The : end argument is the position of the
first element, if any, not to be considered.

 If we give the : from-end argument,

> (position #\a "fantasia" :from-end t)
7

we get the position of the a closest to the end. But the position is
calculated in the usual way; it does not represent the distance from
the end.

 The :key argument is a function that is applied to each element of a
 sequence before it is considered. If we ask something like this,


> ( p o s i t i o n 'a '( ( c d) (a b)) :key # ' c a r )
1

then what we are asking for is the position of the first element whose
car is the symbol a.

 The : t e s t argument is a function of two arguments, and defines
 what it takes for a successful match. It always defaults to eql. If
 you're trying to match a list, you might want to use equal instead:



4A

SEQUENCES

65

> ( p o s i t i o n ' ( a b) ' ( ( a b) (c d )))
NIL

> ( p o s i t i o n ' ( a b) ' ( ( a b) (c d)) : t e s t # ' e q u a l
) 0

The :test argument can be any function of two arguments. For example,
by giving <, we can ask for the position of the first element such
that the first argument is less than it:

> (position 3 ' ( 1 0 7 5 ) 2 : t e s t #'<)

Using subseq and p o s i t i o n , we can write functions that take
sequences apart. For example, this function


(defun second-word (str) (let ((pi (+ (position #\ str) 1))) (subseq
str pi (position #\ str :start pi))))

returns the second word in a string of words separated by spaces:



> (second-word "Form follows function.") "follows"

To find an element satisfying a predicate of one argument, we use p o
s i t ion-if. It takes a function and a sequence, and returns the
position of the first element satisfying the function:




> (position-if #'oddp ' ( 2 3 4 5))
 1

It takes all the keyword arguments except : t e s t .

 There are functions similar to member and member-if for
 sequences. They are, respectively, find (which takes all the keyword
 arguments) and f i n d - i f (which takes all except : t e s t ) :



> (find #\a "cat") #\a


> ( f i n d - i f # ' c h a r a c t e r p "ham") #\h Unlike member and
  member-if, they return only the object they were looking for.

 Often a call to f i n d - i f will be clearer if it is translated
 into a find with a : key argument. For example, the expression



page66

SPECIALIZED DATA STRUCTURES



( f i n d - i f #'(lambda (x) (eql (car x) 'complete))
    lst)

would be better rendered as



(find 'complete lst :key #'car)


The functions remove (page 22) and remove-if both work on sequences
generally. They bear the same relation to one another as find and f i
n d - i f . A related function is remove-duplicates, which preserves
only the last of each occurrence of any element of a sequence:

 > (remove-duplicates "abracadabra") "cdbra"

This function takes all the keyword arguments listed in the preceding
table.

 The function reduce is for boiling down a sequence into a single
 value. It takes at least two arguments, a function and a
 sequence. The function must be a function of two arguments. In the
 simplest case, it will be called initially with the first two
 elements, and thereafter with successive elements as the second
 argument, and the value it returned last time as the first. The value
 returned by the last call is returned as the value of the
 reduce. Which means that an expression like

 (reduce # ' f n ' ( a b c d))

 is equivalent to

(fn (fn (fn ' a 'b) ' c ) >d)

 We can use reduce to extend functions that only take two
 arguments. For example, to get the intersection of three or more
 lists, we could write something like

 > (reduce # ' i n t e r s e c t i o n ' ( ( b r a d (A) 's) ( b a d ) (cat)))

@node Example-- Parsing Dates
@section Example-- Parsing Dates


As an example of operations on sequences, this section shows how\to
write a program to parse dates. We will write a program that can take
a string \ like "16 Aug 1980 " and return a list of integers
representing the day, month, and year.



4.5

EXAMPLE: PARSING DATES

67



(defun tokens ( s t r t e s t s t a r t ) (let ((pi (position-if t e s t s t r : s t a r t s t a r t )))
(if Pi

#'(lambda ( c ) (not ( funcall t e s t c ))) s t r : s t a r t PD)) 1 (cons (subseq s t r p i p2) (if p2 (tokens s t r t e s t p2) nil))) nil)))

(defun c o n s t i t u e n t (c) (and ( g r a p h i c - c h a r - p c) (not (char= c #\ )))) Figure 4.2: Identifying tokens.

(let ((p2 ( p o s i t i o n - i f


Figure 4.2 contains some general-purpose parsing functions that we'll
need in this application. The first, tokens, is for extracting the
tokens from a string. Given a string and a test function, it returns a
list of the substrings whose characters satisfy the function. For
example, if the test function is alpha-char-p, which returns true of
alphabetic characters, we get:

 > (tokens M abl2 3cde.f" ("ab n "cde" "f") tt'alpha-char-p 0)

All characters that do not satisfy the function are treated as
whitespace--they separate tokens but are never part of them.

 The function c o n s t i t u e n t is defined for use as an argument
 to tokens. In Common Lisp, graphic characters are all the characters
 we can see, plus the space character. So if we use c o n s t i t u e
 n t as the test function,





> (tokens "abl2 3cde.f gh" # \; c o n s t i t u e n t 0) M ( abl2" "3cde.f" "gh") "

then tokens will have the conventional notion of whitespace.

 Figure 4.3 contains functions specifically for parsing dates. The
 function p a r s e - d a t e takes a date in the specified form and
 returns a list of integers representing its components:



page68

SPECIALIZED DATA STRUCTURES

(defun parse-date (str) (let ((toks (tokens str #'constituent 0))) (list (parse-integer (first toks)) (parse-month (second toks)) (parse-integer (third toks)))))
 (defconstant month-names #("jan" "feb" "mar" "apr" "may" "jun" "Jul" "aug" "sep" "oct" "nov" "dec"))
 (defun parse-month (str) (let ((p (position str month-names :test #'string-equal))) (if p (+ p 1) nil)))

 Figure 4.3: Functions for parsing dates.



> ( p a r s e - d a t e "16 Aug 1980")
 (16 8 1980)

 It uses tokens to break up a date string, and then calls parse-month
 and p a r s e - i n t e g e r to interpret the elements. To find the
 month, it calls parse-month, which is not case-sensitive because it
 uses s t r i n g - e q u a l to match the name of the month. To find
 the day and year, it calls the built-in p a r s e - i n t e g e r ,
 which takes a string and returns the corresponding integer.

 If we had to write code to parse integers, we might say something
 like:


(defun r e a d - i n t e g e r ( s t r ) ( i f (every # ' d i g i t -
c h a r - p s t r ) (let ((accum 0)) (dotimes (pos ( l e n g t h s
t r )) ( s e t f accum (+ (* accum 10) ( d i g i t - c h a r - p
(char s t r p o s ))))) accum) nil))

 This definition illustrates how to get from a character to a number
 in Common Lisp--the function d i g i t - c h a r - p not only tests
 whether a character is a digit, but returns the corresponding
 integer.



4.6

STRUCTURES

69

@node Structures
@section Structures


A structure can be considered as a deluxe kind of
vector. Suppose you had to write a program that kept track of a number
of rectangular solids. You might consider representing them as vectors
of three elements: height, width, and depth. Your program would be
easier to read if, instead of using raw svref s, you defined functions
like

 (defun block-height (b) (svref b 0))

and so on. You can think of a structure as a vector in which all these
kinds of functions get defined for you.

 To define a structure, we use def s t r u c t . In the simplest case
 we just give the name of the structure and the names of the fields:


(defstruct point
  x
  y)

This defines a point to be a structure with twofields,x and y. It also
implicitly defines the functions make-point, p o i n t - p ,
copy-point, p o i n t - x , and point-y.

 Section 2.3 mentioned that Lisp programs could write Lisp
 programs. This is one of the most conspicuous examples we have seen
 so far. When you call def s t r u c t , it automatically writes code
 defining several other functions. With macros you will be able to do
 the same thing yourself. (You could even write d e f s t r u c t if
 you had to.)

 Each call to make-point will return a new p o i n t . We can specify
 the values of individual fields by giving the corresponding keyword
 arguments:

 > (setf p (make-point :x 0 :y 0))
#S(POINT X 0 Y 0)

The access functions for p o i n t fields are defined not only to
retrieve values, but to work with setf.

 > ( p o i n t - x p) 0 > (setf (point-y p) 2) 2 > P #S(POINT X 0 Y 2)

Defining a structure also defines a type of that name. Each point will
be of type point, then s t r u c t u r e , then atom, then t . So as
well as using p o i n t - p to test whether something is a point,

70 > ( p o i n t - p p) T
> (typep p ' p o i n t ) T

SPECIALIZED DATA STRUCTURES

we can also use general-purpose functions like typep.

 We can specify default values for structure fields by enclosing the
 field name and a default expression in a list in the original
 definition.

 (defstruct polemic (type (progn (format t "What kind of polemic was it? ")
				 (read)))
	    (effect nil))

If a call to make-polemic specifies no initial values for these
fields, they will be set to the values of the corresponding
expressions:

 > (make-polemic) What kind of polemic was it? scathing #S(POLEMIC TYPE SCATHING EFFECT NIL)

We can also control things like the way a structure is displayed, and
the prefix used in the names of the access functions it creates. Here
is a more elaborate definition for p o i n t that does both:

(defstruct (point (:cone-name p) (.·print-function (x 0) (y o)) print-point))

(defun print-point (p stream depth) (format stream "#<~A,~A>M (px p) (py p))) "

The : cone-name argument specifies what should be concatenated to the
front of the field names to make access functions for them. By default
it was p o i n t - \; now it will be simply p. Not using the default
makes your code a little less readable, so you would only want to do
this kind of thing if you're going to be using the access functions
constantly.

 The : pr i n t - f unct ion is the name of the function that should
 be used to print a point when it has to be displayed--e.g. by the
 toplevel. This function must take three arguments: the structure to
 be printed, the place where it is to be printed, and a third argument
 that can usually be ignored.2 We will


In ANSI Common Lisp, you can give instead a : p r i n t - o b j e c t
argument, which only takes the first two arguments. There is also a
macro p r i n t - u n r e a d a b l e - o b j e c t , which should be
used, when available, to display objects in # < . . . > syntax.
2

4.7

EXAMPLE: BINARY SEARCH TREES

71

2ij

CO 4 ) CO CO CO
3

CO

)

\7J

Figure 4.4: A binary search tree.


deal with streams in Section 7.1. For now, suffice it to say that the
stream argument can simply be passed on to format.

 The function p r i n t - p o i n t will display points in an
 abbreviated form:

 > (make-point) #<0,0>

@node Example-- Binary Search Trees
@section Example-- Binary Search Trees



Because s o r t comes built-in, you will rarely, if ever, have to
write sort routines in Common Lisp. This section shows how to solve a
related problem for which no ready-made solution is provided:
maintaining a sorted collection of objects. The code in this section
will store objects in binary search trees, or BSTs. When balanced,
BSTs allow us to find, add, or delete elements in time proportional to
log n, where n is the size of the set.

 A BST is a binary tree in which, for some ordering function <, the
 left child of each element is < the element, and the element is < its
 right child. Figure 4.4 shows an example of a BST ordered according
 to <.

 Figure 4.5 contains functions for inserting and finding objects in
 BSTs. The fundamental data structure will be the node, which has
 three fields: one for the object stored at that node, and one each
 for the left and right children of the node. You could think of a
 node as a cons cell with one car and two cdrs.

 A BST is either NIL , or a node whose 1 and r fields are BSTs. As
 lists can be built by successive calls to cons, BSTs will be built by
 successive calls to b s t - i n s e r t . This function takes an
 object, a BST, and an ordering function, and returns a BST that
 contains the object. Like cons, b s t - i n s e r t does not modify
 the BST given as the second argument. Here's how we would use it to
 build a BST:



page72

SPECIALIZED DATA STRUCTURES

(defstruct
    (node (:print-function (lambda (n s d) (format s "#<~A>" (node-elt n)-))))
  elt (1 nil) (r nil))

(defun bst-insert (obj bst <)
  (if (null bst)
      (make-node :elt obj)
    (let ((elt (node-elt bst)))
      (if (eql obj elt)
	  bst 
	(if (funcall < obj elt)
	    (make-node :elt elt 
		       :1 (bst-insert obj (node-1 bst) <)
		       :r (node-r bst))
	  (make-node :elt elt 
		     :r (bst-insert obj (node-r bst) <) 
		     :1 (node-1 bst)))))))
 
(defun bst-find (obj bst <) (if (null bst) nil (let ((elt (node-elt bst))) (if (eql obj elt) bst (if (funcall < obj elt) (bst-find obj (node-1 bst) <) (bst-find obj (node-r bst) <))))))

(defun bst-min (bst) (and bst (or (bst-min (node-1 bst)) bst)))

(defun bst-max (bst) (and bst (or (bst-max (node-r bst)) bst)))

Figure 4.5: Binary search trees: Lookup and insertion.

4.7

EXAMPLE: BINARY SEARCH TREES

73

> (setf nums NIL ) NIL
> ( d o LIST ( x ' ( 5 8 4 2 1 9 6 7 3)) (setf nums ( b s t - i n s e r t x nums # ' < ))) NIL

At this point the structure of nums corresponds to the tree shown in
Figure 4.4.

We can use b s t - f ind, which takes the same arguments as b s t - i
n s e r t , to find objects within a BST. The description of the node
structure mentioned that it was like a cons cell with two cdrs. The
analogy becomes clearer when we compare the definition of b s t - f
ind to the definition of our-member on page 16.

 Like member, b s t - f ind returns not just the sought-for element,
 but the subtree of which it is the root:


> (bst-find 12 nums #'<) NIL
> (bst-find 4 nums #'<) #<4>

This allows us to distinguish between failing to find something, and
succeeding in finding NIL .

 Finding the least and greatest elements of a BST is easy. To find the
 least, we keep following left children, as in bst-min. To find the
 greatest, we keep following right children, as in bst-max:

 > (bst-min nums) > (bst-max nums) #<9>

Removing an element from a BST is just as fast, but requires more
code. Figure 4.6 shows how to do it. The function bst-remove takes an
object, a BST, and an ordering function, and returns a BST like the
original one, but without the object. Like remove, it does not modify
the BST given as the second argument:


> (setf nums (bst-remove 2 nums #'<)) #<5> > (bst-find 2 nums #'<) NIL

At this point nums might have the structure shown in Figure 4.7. (The
other possibility is that 1 took the place of 2.)



74

SPECIALIZED DATA STRUCTURES

(defun bst-remove (obj bst <) (if (null bst) nil (let ((elt (node-elt bst))) (if (eql obj elt) (percolate bst) (if (funcall < obj elt) (make-node :elt elt :1 (bst-remove obj (node-1 bst) <) :r (node-r bst)) (make-node :elt elt :r (bst-remove obj (node-r bst) <) :1 (node-1 bst)))))))

(defun percolate (bst) (cond ((null (node-1 bst)) (if (null (node-r bst)) nil (rperc bst))) ((null (node-r bst)) (lperc bst)) (t (if (zerop (random 2)) (lperc bst) (rperc bst)))))

 (defun rperc (bst) (make-node :elt (node-elt (node-r bst)) :1 (node-1 bst) :r (percolate (node-r bst))))

 (defun lperc (bst) (make-node :elt (node-elt (node-1 bst)) :1 (percolate (node-1 bst)) :r (node-r bst)))

Figure 4.6: Binary search trees: Deletion.

4.7

EXAMPLE: BINARY SEARCH TREES

75

CO CO CO
Figure 4.7: Binary search tree after removal of an element.

(defun bst-traverse (fn bst) (when bst (bst-traverse fn (node-1 bst)) (funcall fn (node-elt bst)) (bst-traverse fn (node-r bst))))

Figure 4.8: Binary search trees: Traversal.

Deletion is more work because an object removed from an interior node
leaves an empty space that has to be filled by one or the other of the
children. This is the purpose of the function percolate. It replaces
the topmost element of a BST with one of its children, then replaces
the child with one of its children, and so on.

 In order to maintain the balance of the tree, percolate chooses
 randomly if there are two children. The expression (random 2) will
 return either 0 or 1, so (zerop (random 2)) will return true half the
 time.

 Once we have a collection of objects inserted into a BST, an inorder
 traversal will yield them in ascending order. This is the purpose of
 bst-traverse, in Figure 4.8:

 > (bst-traverse #'princ nums) 13456789 NIL

(The function princ just displays a single object.)

The code given in this section provides a skeleton implementation of
BSTs. You would probably want to flesh it out somewhat, depending on
the application. For example, the code given here has only a single e
l t field in each node\; in many applications, it would make sense to
have two fields, key



76

SPECIALIZED DATA STRUCTURES

and value. The version in this chapter also treats BSTS as sets, in
the sense that duplicate insertions are ignored. But the code could
easily be modified to handle duplicate elements.

 BSTS are not the only way to maintain a sorted collection of
 objects. Whether they are the best way depends on the
 application. Generally, BSTs work best when insertions and deletions
 are evenly distributed. So one of the things they are not good for is
 maintaining priority queues. In a priority queue, the insertions may
 be evenly distributed, but the deletions will always happen at one
 end. This would cause a BST to become unbalanced, and our expected
 0(log n) insertions and deletions would become 0(n) instead. If you
 used a BST to represent a priority queue, you might as well use an
 ordinary list, because the BST would end up behaving like one.0


@node Hash Tables
@section Hash Tables


Chapter 3 showed that lists could be used to represent both sets and
mappings. When either grow to a substantial size (say 10 elements) it
will be faster to use hash tables. You create a hash table by calling
make-hash-table, which has no required arguments:


> (setf ht (make-hash-table)) #<Hash-Table BF0A96>

Like functions, hash tables are always displayed in #<.. .> form.

 A hash table, like an assoc-list, is a way of associating pairs of
 objects. To retrieve the value associated with a given key, we call
 gethash with a key and a hash table. By default, gethash returns nil
 when there is no value associated with the key.



> (gethash ' c o l o r h t )
NIL
NIL

Here we see for the first time one of the distinctive features of
Common Lisp: an expression can return multiple values. The function
gethash returns two. The first is the value associated with the key,
and the second says whether the hash table has any value stored under
that key. Because the second value is NIL , we know that the first NIL
was returned by default, not because NIL was explicitly associated
with color.

 Most implementations will display all the return values of a call
 made at the toplevel, but code that expects only one return value
 will get just the first. Section 5.5 will explain how code can
 receive multiple return values.



4.8

HASH TABLES

77

To associate a value with a key, we use s e t f with gethash:

> (setf (gethash ' c o l o r h t ) RED 'red)

Now if we call gethash again we'll get the value we just inserted:

> (gethash ' c o l o r h t )
RED
T

The second return value proves that now we're getting a real stored
object and not just a default.

 The objects stored in a hash table or used as keys can be of any
 type. For example, if we wanted to keep some kind of information
 about functions, we could use a hash table with functions as keys and
 strings as entries:


> (setf bugs (make-hash-table))
#<Hash-Table BF4C36>

> (push "Doesn't t a k e keyword arguments." (gethash #'our-member bugs)) ("Doesn't take keyword arguments.")

 Since gethash returns NIL by default, and push is an abbreviation for
 a setf, we can simply push new strings into the entry for a
 function. (The offending our-member is defined on page 16.)

 You can use hash tables instead of lists to represent sets. When the
 sets become large, lookups and deletions should be much faster with
 hash tables. To add a member to a set represented as a hash table, se
 t f the gethash of it t o t:





> ( s e t f f r u i t (make-hash-table))
#<Hash-Table BFDE76>

> (setf (gethash ' a p r i c o t f r u i t ) t )
T

Then to test for membership you just call gethash:

 > (gethash ' a p r i c o t T
T
fruit)

Since gethash returns NIL by default, a new-made hash table is also,
conveniently, an empty set.

 To remove an object from a set, you would call remhash, which removes
 an entry from a hash table:



78

SPECIALIZED DATA STRUCTURES

> (remhash ' a p r i c o t T

fruit)

The return value shows whether there was an entry to remove\; in this
case there was.

 There is an iteration function for hash tables: maphash, which takes
 a function of two arguments and a hash table. The function will be
 called on every key/value pair in the table, in no particular order:



> (setf (gethash 'shape ht) 'spherical (gethash 'size ht) 'giant) GIANT

> (maphash #'(lambda (k v) (format t "~A = ~k~V%" k v)) ht)

SHAPE = SPHERICAL SIZE = GIANT COLOR = RED
NIL

It always returns NIL , but you can save the values by passing a
function that will accumulate them in a list.

 Hash tables can accommodate any number of elements, because they are
 expanded when they run out of space. If you want to ensure that a
 hash table starts with room for a particular number of elements, you
 can give the optional : s i z e argument to make-hash-table. There
 are two reasons to do this: because you know the hash table is going
 to be huge, and you want to avoid expanding it\; or because you know
 the hash table is going to be small, and you don't want to waste
 memory. The : s i z e argument specifies not the number of spaces in
 the hash table, but the number of elements, on the average, it will
 be able to accommodate before being expanded. So

 (make-hash-table : s i z e 5)

 would return a hash table intended to hold up to five elements.

 Like any structure involved in lookups, hash tables must have some
 notion of equality for keys. By default they use eql, but you can
 specify that a hash table should use eq, equal, or equalp instead by
 providing the optional : t e s t argument:



> (setf writers (make-hash-table :test #'equal)) #<Hash-Table C005E6> > (setf (gethash '(ralph waldo emerson) writers) t ) T

SUMMARY

79

This is one of the trade-offs we have to make for the efficiency of
hash tables. With lists, we could specify the equality predicate in
the call to member. With hash tables we have to decide ahead of time,
and specify it when the hash table is created.

 Most of the trade-offs in Lisp programming (or life, for that matter)
 have this character. Initially you try to keep things fluid, even at
 the cost of efficiency. Later, as the program hardens, you can
 sacrifice some flexibility for speed.



Summary

1. Common Lisp supports arrays of at least 7
dimensions. One-dimensional arrays are called vectors.


2. Strings are vectors of characters. Characters are objects in their
own right.



3. Sequences include lists and vectors. Many sequence functions take
keyword arguments from a standard set.



4. Parsing is easy in Lisp because it has so many functions that work
on strings.


5. Calling def struct defines a structure with named fields. It is a
good example of a program that writes programs.



6. Binary search trees are useful for maintaining a sorted collection
of objects.


7. Hash tables provide a more efficient way to represent sets and
mappings.



Exercises

1. Define a function to take a square array (an array whose dimensions
are (n n)) and rotate it 90° clockwise:

 > (quarter-turn #2A((a b) (c d)))
 #2A((C A) (D B))

You'll need array-dimensions (page 361).

80

SPECIALIZED DATA STRUCTURES

2. Read the description of reduce on page 368, then use it to define:
(a) c o p y - LIST (b) r e v e r s e (for lists)

3. Define a structure to represent a tree where each node contains
some data and has up to three children. Define (a) a function to copy
such a tree (so that no node in the copy is eql to a node in the
original) (b) a function that takes an object and such a tree, and
returns true if the object is eql to the data field of one of the
nodes



4. Define a function that takes a BST and returns a list of its
elements ordered from greatest to least.



5. Define b s t - a d j oin. This function should take the same
arguments as b s t - i n s e r t , but should only insert the object
if there is nothing eql to it in the tree.



6. The contents of any hash table can be described by an assoc-list
whose elements are (k . v), for each key-value pair in the hash
table. Define a function that

 (a) takes an assoc-list and returns a corresponding hash table

(b) takes a hash table and returns a corresponding assoc-list



@node Control
@chapter Control


Section 2.2 introduced the Common Lisp evaluation rule, which by now
should be familiar from long experience. What the operators in this
chapter have in common is that they all violate the evaluation
rule. They let you direct the course that evaluation will take through
the text of a program. If ordinary function calls are the leaves of a
Lisp program, these operators are used to build the branches.

@menu 
* Blocks::
* Context::
* Conditionals::
* Iteration-basic operators::
* Multiple Values::
* Aborts::
* Example-- Date Arithmetic::
@end menu



@node Blocks
@section Blocks


Common Lisp has three basic operators for creating blocks Of code:
progn, block, and tagbody. We have seen progn already. The expressions
within its body are evaluated in order, and the value of the last is
returned:0

> (progn
    (format t "a")
    (format t "b")
    (+ 11 12))
ab
23

Since only the value of the last expression is returned, the use of
progn (or any block) implies side-effects.

A block is like a progn with a name and an emergency exit. The first
argument should be a symbol. This becomes the name of the block. At
any point within the body, you can halt evaluation and return a value
immediately by using r e t u r n - from with the block's name:

 81

82

CONTROL

> (block head (format t "Here we go.") (return-from head 'idea) (format t "We'll never see t h i s . " ))
Here we go.
IDEA

Calling return-from allows your code to make a sudden but graceful
exit from anywhere in a body of code. The second argument to
return-from is returned as the value of the block named by the
first. Expressions after the return-from are not evaluated.

 There is also a return macro, which returns its argument as the value
 of an enclosing block named NIL :

 > (block NIL (return 27)) 27

Many Common Lisp operators that take a body of expressions implicitly
enclose the body in a block named NIL . All iteration constructs do,
for example:


> (dolist (x ' (a b c d e)) (format t "~A " x) (if (eql x >c) (return
  'done))) ABC DONE

The body of a function defined with def un is implicitly enclosed in a
block with the same name as the function, so you can say:


(defun foo () (return-from foo 27))

 Outside of an explicit or implicit block, neither return-from nor
 return will work.

 Using return-from we can write a better version of read-integer:


(defun read-integer (str) (let ((accum 0)) (dotimes (pos (length str)) (let ((i (digit-char-p (char str pos)))) (if i (setf accum (+ ( * accum 10) i)) (return-from read-integer nil)))) accum))

5.2

CONTEXT

83

The version on page 68 had to check all the characters before building
the integer. Now the two steps can be combined, because we can abandon
the calculation if we encounter a character that's not a digit.

 The third basic block construct is tagbody, within which you can use
 gotos. Atoms appearing in the body are interpreted as labels\; giving
 such a label to go sends control to the expression following it. Here
 is an exceedingly ugly piece of code for printing out the numbers
 from 1 to 10:


> (tagbody (setf x 0) top (setf x (+ x 1)) (format t "~A " x) (if (< x 10) (go top))) 1 2 3 4 5 6 7 8 9 10 NIL

This operator is mainly something that other operators are built upon,
not something you would use yourself. Most iteration operators have an
implicit tagbody, so it's possible (though rarely desirable) to use
labels and go within their bodies.

 How do you decide which block construct to use? Nearly all the time
 you'll use progn. If you want to allow for sudden exits, use block
 instead. Most programmers will never use tagbody explicitly.

@node Context
@section Context



Another operator we've used to group expressions is l e t . It takes a
body of code, but also allows us to establish new variables for use
within the body:

 > (let ((x 7) (y 2)) (format t "Number") (+ x y)) Number 9

An operator like l e t creates a new lexical context. Within this
context there are two new variables, and variables from outer contexts
may have thereby become invisible.

 Conceptually, a l e t expression is like a function call. Section
 2.14 showed that, as well as referring to a function by name, we
 could refer to literally by using a lambda expression. Since a lambda
 expression is like the



84

CONTROL





name of a function, we can use one, as we would a function name, as
the first element in a function call:

 > ((lambda (x) (+ x 1)) 3) 4

The preceding l e t expression is exactly equivalent to:

 ((lambda (x y) (format t "Number") (+ x y)) 7 2)

Any questions you have about l e t should be dealt with by passing the
buck to lambda, because entering a l e t is conceptually equivalent to
doing a function call.0

 One of the things this model makes clear is that the value of one l e
 t created variable can't depend on other variables created by the
 same l e t . For example, if we tried to say

 (let ((x 2) (y (+ x 1))) (+ x y))

then the x in (+ x 1) would not be the x established in the previous
line, because the whole expression is equivalent to

 ((lambda (x y) (+ x y)) 2 (+ x 1))

Here it's obvious that the (+ x 1) passed as an argument to the
function cannot refer to the parameter x within the function.

 So what if you do want the value of one new variable to depend on the
 value of another variable established by the same expression? In that
 case you would use a variant called l e t * :

 > (let * ((x 1) (y (+ x 1))) (+ x y)) 3

A l e t * is functionally equivalent to a series of nested lets. This
particular example is equivalent to:

5.3 (let ((x 1)) (let ((y (+ x 1))) (+ x y )))

CONDITIONALS

85

In both l e t and l e t * , initial values default to NIL . Such
variables need not be enclosed within lists:

 > (let (x y) ( LIST x y))
(NIL NIL)

The d e s t r u c t u r i n g - b i n d macro is a generalization of l
e t . Instead of single variables, it takes a pattern--one or more
variables arranged in the form of a tree--and binds them to the
corresponding parts of some actual tree. For example:

 > ( d e s t r u c t u r i n g - b i n d (w (x y) . z) ' ( a (b c) d
   e) ( LIST w x y z)) (A B C (D E))

It causes an error if the tree given as the second argument doesn't
match the pattern given as the first.

@node Conditionals
@section Conditionals



The simplest conditional is if\; all the others are built upon it. The
simplest after if is when, which takes an expression and a body of
code. The body will be evaluated if the test expression returns
true. So

 (when (oddp t h a t ) (format t "Hmm, t h a t ' s odd.") (+ t h a t 1))

 is equivalent to

(if (oddp t h a t ) (progn (format t "Hmm, t h a t ' s odd.") (+ t h a t 1)))

The opposite of when is u n l e s s \; it takes the same arguments,
but the body will be evaluated only if the test expression returns
false.

 The mother of all conditionals (in both senses) is cond, which brings
 two new advantages: it allows multiple conditions, and the code
 associated with each has an implicit progn. It's intended for use in
 situations where we would otherwise have to make the third argument
 of an if another if. For example, this pseudo-member



86

CONTROL

(defun our-member (obj lst) (if (atom lst) nil (if (eql (car lst) obj) lst (our-member obj (cdr lst)))))

could also be defined as

(defun our-member (obj lst) (cond ((atom lst) nil) ((eql (car lst) obj) lst) (t (our-member obj (cdr lst)))))

In fact, a Common Lisp implementation will probably implement cond by
translating the latter into the former.

 In general, cond takes zero or more arguments. Each one must be a
 list consisting of a condition followed by zero or more
 expressions. When the cond expression is evaluated, the conditions
 are evaluated in order until one of them returns true. When it does,
 the expressions associated with it are evaluated in order, and the
 value of the last is returned as the value of the cond. If there are
 no expressions after the successful condition



> (cond (99))
99

the value of the condition itself is returned.

 Since a cond clause with a condition of t will always succeed, it is
 conventional to make the final, default clause have t as the
 condition. If no clause succeeds, the cond returns NIL , but it is
 usually bad style to take advantage of this return value. (For an
 example of the kind of problem that can occur, see page 292.)

 When you want to compare a value against a series of constants, there
 is CASE. We might use CASE to define a function to return the number
 of days in a month:



(defun month-length (mon)
  (case mon
    ((jan mar may jul aug oct dec) 31)
    ((apr jun sept nov) 30)


    (feb ( i f (leap-year) 29 28)) (otherwise "unknown month")))

A case expression begins with an argument whose value will be compared
against the keys in each clause. Then come zero or more clauses, each
one



5.4

ITERATION

87

beginning with either a key, or a list of keys, followed by zero or
more expressions. The keys are treated as constants\; they will not be
evaluated. The value of the first argument is compared (using eql) to
the key/s at the head of each clause. If there is a match, the
expressions in the rest of that clause are evaluated, and the value of
the last is returned as the value of the case.

 The default clause may have the key t or otherwise. If no clause
 succeeds, or the successful clause contains only keys,



> (case 99 (99))
NIL

then the case returns NIL .

The typecase macro is similar to case, except that the keys in each
clause should be type specifiers, and the value of the first argument
is compared to the keys using typep instead of eql. (An example of
typecase appears on page 107.)

@node Iteration-basic operators
@section Iteration-basic operators

 The basic iteration operator is do, which was
introduced in Section 2.13. Since do contains both an implicit block
and an implicit tagbody, we now know that it's possible to use return,
return-from, and go within the body of a do.

Section 2.13 mentioned that the first argument to do had to be a list
of specifications for variables, each possibly of the form

 ""variable initial update)

The initial and update forms are optional. If the update form is
omitted, the variable won't be updated on successive iterations. If
the initial form is also omitted, the variable will be initially NIL .

 In the example on page 23,



(defun show-squares (start end) (do ((i start (+ i 1))) ((> i end) 'done) (format t "~A ~k~V." i ( * i i))))

the update form refers to the variable created by the do. This is
commonplace. It would be rare to find a do whose update forms didn't
refer to at least one of its own variables.

 When more than one variable is to be updated, the question arises, if
 an update form refers to a variable that has its own update form,
 does it get the



88

CONTROL

updated value or the value from the previous iteration? With do, it
gets the latter:





> (let ((x ' a )) (do ((x 1 (+ x 1)) (y x x)) ((> x 5)) (format t M(~A ~A) " x . y )))
(1 A) (2 1) (3 2) (4 3) (5 4) NIL "

On each iteration, x gets its previous value plus 1\; y also gets the
previous value of x.

 But there is also a do*, which has the same relation to do as l e t *
 does to l e t . Any initial or update form can refer to a variable
 from a previous clause, and it will get the current value:

 > (do* ((x 1 (y x ((> x (format t (1 1) (2 2) NIL (+ x 1)) x)) 5))
   "(~A ~A) " x y)) (3 3) (4 4) (5 5)

Besides do and do* there are several special-purpose iteration
operators. To iterate over the elements of a list, we can use doLIST:


> (dolist (x ' ( a b e d ) 'done) (format t "~A " x))
 A B C D
DONE

The third expression within the initial list will be evaluated and
returned as the value of the d o LIST when iteration terminates. It
defaults to NIL.

Similar in spirit is dotimes, which for some n iterates over the
integers from O to w-1:



> (dotimes (x 5 x) (format t "~A " x)) 0 12 3 4 5 As with d o LIST ,
  the third expression in the initial list is optional and defaults to
  NIL . Notice that it can refer to the iteration variable.

The function mapc is like mapcar but does not cons up a new list as a
return value, so the only reason to use it is for side-effects. It is
more flexible than d o LIST , because it can traverse multiple lists
in parallel:



5.5

MULTIPLE VALUES

89

THE POINT OF do

In "The Evolution of Lisp," Steele and Gabriel express the point of do
so well that the passage is worth quoting in its entirety:

 Arguments over syntax aside, there is something to be said for
 recognizing that a loop that steps only one variable is pretty
 useless, in any programming language. It is almost always the case
 that one variable is used to generate successive values while another
 is used to accumulate a result. If the loop syntax steps only the
 generating variable, then the accumulating variable must be stepped
 "manually" by using assignment statements.. .or some other side
 effect. The multiple-variable do loop reflects an essential symmetry
 between generation and accumulation, allowing iteration to be
 expressed without explicit side effects:

 (defun f a c t o r i a l (n) (do ( ( j n (- j 1)) (f 1 (* j f )))
 ((= j 0) f )))

 It is indeed not unusual for a do loop of this form to have an empty
 body, performing all its real work in the step forms.0



> (mapc #'(lambda (x y) (format t "~A ~A " x y)) '(hip flip slip) '(hop flop slop)) HIP HOP FLIP FLOP SLIP SLOP (HIP FLIP SLIP)

It always returns its second argument.

@node Multiple Values
@section Multiple Values



One used to say, in order to emphasize the importance of functional
programming, that every Lisp expression returned a value. Now things
are not so simple\; in Common Lisp, an expression can return zero or
more values. The maximum number of return values is
implementation-dependent, but it will be at least 19.

 Multiple values allow a function that calculates several things to
 return them without having to build a structure to contain them
 all. For example, the built-in get-decoded-time returns the current
 time in nine values: second,



90

CONTROL



minute, hour, date, month, day, and two others.

 Multiple values also make it possible to have lookup functions that
 can distinguish between finding NIL and failing to find
 something. This is why gethash returns two values. Because it uses
 the second value to indicate success or failure, we can store NIL in
 a hash table just like any other value.

 The values function returns multiple values. It returns exactly the
 values you give it as arguments:

 > (values 'a NIL ( + 2 4)) A NIL 6

If a values expression is the last thing to be evaluated in the body
of a function, its return values become those of the
function. Multiple values are passed on intact through any number of
returns:

> ((lambda () ((lambda () (values 1 2 )))))
1
2

However, if something is expecting only one value, all but the first
will be discarded:

 > (let ((x (values 1 2 ))) x)
1

By using values with no arguments, it's possible to return no
values. In that case, something expecting one will get NIL :

> (values)
> (let ((x (values))) x)
NIL

To receive multiple values, we use multiple-value-bind:

> (multiple-value-bind (x y z) (values 1 2 3) ( LIST x y z)) (1 2 3)
> (multiple-value-bind (x y z) (values 1 2) (list x y z)) (1 2 NIL)

5.6

ABORTS

91

If there are more variables than values, the leftover ones will be NIL
. If there are more values than variables, the extra values will be
discarded. So to print just the time we might write:0


> (multiple-value-bind (s m h) (get-decoded-time)
    (format nil "~A:~A:~A" h m s))
"4:32:13"

You can pass on multiple values as the arguments to a second function
using m u l t i p l e - v a l u e - c a l l :

> ( m u l t i p l e - v a l u e - c a l l #' + (values 1 2 3)) 6

There is also a function m u l t i p l e - v a l u e - LIST :

> ( m u l t i p l e - v a l u e - LIST (values ' a ' b ' c)) (A B C)

which is like using m u l t i p l e - v a l u e - c a l l with # '
LIST as the first argument.

@node Aborts
@section Aborts


You can use r e t u r n to exit from a block at any
point. Sometimes we want to do something even more drastic, and
transfer control back through several function calls. To do this we
use catch and throw. A cat ch expression takes a tag, which can be any
kind of object, followed by a body of expressions.



(defun super () (catch abort (sub) (format t "We'll never see t h i s . " )))
 (defun sub () (throw ' a b o r t 99))

 The expressions are evaluated in order, as if in a progn. At any
 point within this code or code called by it, a throw with the
 corresponding tag will cause the catch expression to return
 immediately:

> (super)
99

92

CONTROL



A throw with a given tag will pass control through (and thereby kill)
any catches with other tags in order to reach the one with the
matching tag. If there is no pending catch with the right tag, the
throw causes an error.

 Calling e r r o r also interrupts execution, but instead of
 transferring control to another point higher up in the calling tree,
 it transfers control to the Lisp error handler. Usually the result
 will be to invoke a break loop. Here is what might happen in a
 hypothetical Common Lisp implementation:

 > (progn ( e r r o r "Oops!")
(format t "After the error.")) Error: Oops! Options: :abort, :backtrace »



For more on errors and conditions, see Section 14.6 and Appendix A.

 Sometimes you want code to be proof against interruptions like throws
 and errors. By using an unwind-protect, you can ensure that such
 interruptions won'tleave your program in an inconsistent state. An
 unwind-protect takes any number of arguments and returns the value of
 the first. However, the remaining expressions will be evaluated even
 if the evaluation of the first is interrupted.

 > ( s e t f x 1) 1 > (catch ' a b o r t
(unwind-protect (throw 'abort 99) (setf x 2))) 99

> x 2

Here, even though the throw sends control back to the waiting catch,
unwind-protect ensures that the second expression gets evaluated on
the way out. Whenever certain actions have to be followed by some kind
of cleanup or reset, unwind-protect may be useful. One example is
mentioned on page 121.


@node Example-- Date Arithmetic
@section Example-- Date Arithmetic
In some applications it's useful to be able to add and subtract
dates--to be able to calculate, for example, that the date 60 days
after December 17,1997

5.7

EXAMPLE: DATE ARITHMETIC

93

is February 15,1998. In this section we will write a utility for date
arithmetic. We will convert dates to integers, with zero fixed at
January 1, 2000. We will be able to manipulate such integers using the
built-in + and - functions, and when we're finished, convert the
result back to a date.

 To convert a date to an integer, we will add together the number of
 days represented by each of its components. For example, the integer
 value of November 13, 2004 is the sum of the number of days up to
 2004, plus the number of days up to November, plus 13.

 One thing we'll need here is a table listing the number of days up to
 the start of each month in a non-leap year. We can use Lisp to derive
 the contents of this table. We start by making a list of the lengths
 of each of the months:

 > (setf mon '(31 28 31 30 31 30 31 31 30 31 30 31))
(31 28 31 30 31 30 31 31 30 31 30 31)

We can test that the lengths add up properly by applying + to the
list:

> (apply #'+ mon)
365

Now if we reverse the list and use m a p LIST to apply + to successive
cdrs, we can get the number of days up to the beginning of each month:

 > (setf nom (reverse mon)) (31 30 31 30 31 31 30 31 30 31 28 31) > (setf sums (maplist #'(lambda (x) (apply #'+ x)) nom)) (365 334 304 273 243 212 181 151 120 90 59 31) > (reverse sums) (31 59 90 120 151 181 212 243 273 304 334 365)

These numbers indicate that there are 31 days up to the start of
February, 59 up to the start of March, and so on.

 The list we just created is transformed into a vector in Figure 5.1,
 which contains the code for converting dates to integers.

 There are four stages in the life of a typical Lisp program: it is
 written, then read, then compiled, then run. One of the distinctive
 things about Lisp is that it's there at every stage. You can invoke
 Lisp when your program is running, of course, but you can also invoke
 it when your program is compiled (Section 10.2) and when it is read
 (Section 14.3). The way we derived month shows how you can use Lisp
 even as you're writing a program.

 Efficiency usually only matters in the last of the four stages,
 run-time. In the first three stages you can feel free to take
 advantage of the power and flexibility of lists without worrying
 about the cost.



94

CONTROL



(defconstant month #(0 31 59 90 120 151 181 212 243 273 304 334 365)) (defconstant yzero 2000) (defun leap? (y) (and (zerop (mod y 4)) (or (zerop (mod y 400)) (not (zerop (mod y 100)))))) (defun date->num (d m y) (+ ( - d 1) (month-num m y) (year-num y)))


(defun month-num (m y) (+ (svref month ( - m l )) (if (and (> m 2) (leap? y)) 1 0)))
(defun year-num (y)
  (let ((d 0)) (if (>= y yzero)
		   (dotimes (i ( - y yzero) (incf d (year-days (+ (dotimes (i ( - yzero y) (incf d (year-days (+ d) yzero i)))) ( - d)) y i)))))))

(defun year-days (y) (if (leap? y) 366 365))

Figure 5.1: Date arithmetic: Converting dates to integers.

If you used the code in Figure 5.1 to drive a time machine, people
would probably disagree with you about the date when you
arrived. European dates have shifted, even in comparatively recent
times, as people got a more precise idea of the length of a year. In
English-speaking countries, the last such discontinuity was in 1752,
when the date went straight from September 2 to September 14.°

The number of days in a year depends on whether it is a leap year. A
year is a leap year if it is divisible by 4, unless it is divisible by
100, in which case it isn't--unless it is divisible by 400, in which
case it is. So 1904 was a leap year, 1900 wasn't, and 1600 was.

 To determine whether one number is divisible by another we use the
 function mod, which returns the remainder after division:



SUMMARY

95



> (mod 23 5) 3 > (mod 25 5) 0

The first argument is divisible by the second if the remainder is
zero. The function leap? uses this technique to determine whether its
argument is a leap year:

 > (mapcar #'leap? '(1904 1900 1600))
(T NIL T)

The function we'll use to convert dates to integers is date->num. It
returns the sum of the values for each component of a date. To find
the number of days up to the start of the month, it calls month-num,
which looks in month, then adds 1 if the month is after February in a
leap year.

 To find the number of days up to the start of the year, date->num
 calls year-num, which returns the integer representing January 1 of
 that year. This function works by counting up or down from the year y
 given as an argument toward year zero (2000).

 Figure 5.2 shows the second half of the code. The function num->date
 converts integers back to dates. It calls num-year, which returns the
 year in the date, and the number of days left over. It passes the
 latter to num-month, which extracts the month and day.

 Like year-num, num-year counts up or down from year zero, one year at
 a time. It accumulates days until it has a number whose absolute
 value is greater than or equal to that of n. If it was counting down,
 then it can return the values from the current iteration. Otherwise
 it will overshoot the year, and must return the values from the
 previous iteration. This is the point of prev, which on each
 iteration will be given the value that days had on the previous
 iteration.

 The function num-month and its subroutine nmon behave like month-num
 in reverse. They go from value to position in the constant vector
 month, while month-num goes from position to value.

 The first two functions in Figure 5.2 could have been combined in
 one. Instead of returning values to another function, num-year could
 invoke num-month directly. The code is easier to test interactively
 when it's broken up like this, but now that it works, the next step
 might be to combine them.

 With date->num and num->date, date arithmetic is easy.0 We use them
 as in date+, which can add or subtract days from a date. If we ask
 date+ for the date 60 days from December 17,1997,

 > ( m u l t i p l e - v a l u e - LIST (date+ 17 12 1997 60))
(15 2 1998)

we get February 15,1998.

96

CONTROL

(defun num->date (n) (multiple-value-bind (y left) (num-year n) (multiple-value-bind (m d) (num-month left y) (values d m y))))


(defun num'-year (n) (if (< n 0) (do* ((y ( - yzero 1) ( - y 1)) (d ( - (year-days y)) ( - d (year-days y)))) ((<= d n) (values y ( - n d)))) (do* ((y yzero (+ y 1)) (prev 0 d) (d (year-days y) (+ d (year-days y)))) ((> d n) (values y ( - n prev))))))

 (defun num-month (n y) (if (leap? y) (Gond ((= n 59) (values 2 29)) ((> n 59) (nmon ( - n 1))) (t (nmon n))) (nmon n)))

 (defun nmon (n) (let ((m (position n month :test #*<))) (values m (+ 1 ( - n (svref month ( - m 1)))))))

 (defun d a t e * - (d m y n) (num->date (+ (date->num d m y) n))) Figure 5.2: Date arithmetic: Converting integers to dates.

Summary

1. Common Lisp has three basic block constructs: progn\; block, which
allows returns\; and tagbody, which allows gotos. Many built-in
operators have implicit blocks.


2. Entering a new lexical context is conceptually equivalent to a
function call.


3. Common Lisp provides conditionals suited to various situations. All
can be denned in terms of if.

EXERCISES


97


4. There is a similar variety of operators for iteration.


5. Expressions can return multiple values.

6. Computations can be interrupted, and protected against the
consequences of interruption.



Exercises


1. Translate the following expressions into equivalent expressions
that don't use l e t or l e t * , and don't cause the same expression
to. he evaluated twice.
(a) (let ((x (car y ))) (cons x x))
(b) (l e t * ((w (car x)) (y (+ v z ))) (cons w y))



2. Rewrite mystery (page 29) to use cond.

3. Define a function that returns the square of its argument, and
which does not compute the square if the argument is a positive
integer less than or equal to 5.


4. Rewrite num-month (Figure 5.1) to use case instead of svref.


5. Define iterative and recursive versions of a function that takes an
object x and vector v, and returns a list of all the objects that
immediately precede x in v: > (precedes #\a "abracadabra") (#\c #\d #
\ r )


6. Define iterative and recursive versions of a function that takes an
object and a list, and returns a new list in which the object appears
between each pair of elements in the original list: > (intersperse ' -
' ( a b e d )) (A - B - C - D)



98

CONTROL

7. Define a function that takes a list of numbers and returns true iff
the difference between each successive pair of them is 1, using
(a)recursion (b) do (c) mapc and r e t u r n

8. Define a single recursive function that returns, as two values, the
maximum and minimum elements of a vector.



9. The program in Figure 3.12 continues to search as the first
complete path works its way through the queue. In broad searches this
would be a problem.

 (a) Using catch and throw, modify the program to return the first
complete path as soon as it is discovered.

(b) Rewrite the program to
do the same thing without using catch and throw.



@node Functions
@chapter Functions


Understanding functions is one of the keys to understanding
Lisp. Conceptually, functions are at the core of Lisp. Practically,
they are one of the most useful tools at your disposal.

@menu 
* Global Functions::
* Local Functions::
* Parameter Lists::
* Example-- Utilities::
* Closures::
* Example-- Function Builders::
* Dynamic Scope::
* Compilation::
* Using Recursion::
@end menu

@node Global Functions
@section Global Functions



The predicate f boundp tells whether there is a function with a given
symbol as its name. If a symbol is the name of a function,
symbol-function will return it:

 > (fboundp '+) T
> (symbol-function '+) #<Compiled-Function + 17BA4E>

By setting the symbol-function of some name to a function,

(setf (symbol-function 'add2) #'(lambda (x) (+ x 2)))

we thereby define a new global function, which we can use just as if
we had defined it with defun:

> (add2 1)
3

99

100

FUNCTIONS

In fact, def un does little more than translate something like

(defun add2 (x) (+ x 2))

 into the s e t f expression above. Using defun makes programs look
 nicer, and may help the compiler, but strictly speaking you don't
 need it to write programs.

 By making the first argument to defun a list of the form (setf / ) ,
 you define what happens when the first argument to s e t f is a call
 to f.° The following pair of functions defines primo as a synonym for
 car:

(defun primo ( lst ) (car lst ))

(defun (setf primo) (val lst) (setf (car lst) val))


 In the definition of a function whose name is of the form (setf / ) ,
 the first parameter represents the new value, and the remaining
 parameters represent arguments to/.°

 Now any s e t f of primo will be a call to the latter function above:
> (let ((x ( LIST ' a 5 b >c))) ( s e t f (primo x) 480) x) (480 B C)

It's not necessary to define primo in order to define ( s e t f
primo), but such definitions usually come in pairs.

 Since strings are Lisp expressions, there is no reason they can't
 appear within bodies of code. A string by itself does not have
 side-effects, and so doesn't make any difference unless it's the last
 expression. If you make a string the first expression in the body of
 a function defined with defun,

(defun foo (x) "Implements an enhanced paradigm of diversity." x)

 then that string will become the function's documentation string. The
 documentation for a globally defined function can be retrieved by
 calling documentation:

 > (documentation 'foo ' f u n c t i o n )
"Implements an enhanced paradigm of d i v e r s i t y . "

6.2

LOCAL FUNCTIONS

101

@node Local Functions
@section Local Functions


Functions defined via def un or s e t f of symbol-function are global
functions. Like global variables you have access to them anywhere. It
is also possible to define local functions, which, like local
variables, are only accessible within a certain context.

 Local functions can be defined with l a b e l s , which is a kind of
 l e t for functions. Its first argument, instead of being a list of
 specifications for new local variables, is a list of definitions of
 new local functions. Each element of the list is of the form

 (name parameters . body)

 Within the remainder of the l a b e l s expression, calling name is
 equivalent to calling (lambda parameters . body).

> (labels ((addlO (x) (+ x 10))
	    (consa (x) (cons 'a x)))
     (consa (addlO 3))) 

(A . 13)

The analogy to l e t breaks down in one respect. Local functions
defined by a l a b e l s expression can refer to any other functions
defined there, including themselves. So it's possible to define
recursive local functions this way:


> (labels ((len (lst) 
		(if (null lst)
		    0 
		  (+ (len (cdr lst)) 1)))) 
    (len '(a b c)))

3

Section 5.2 showed how a l e t expression could be understood as a
function call. A do expression can be similarly explained as a call to
a recursive function. A do of the form

 (do ((x a (b x)) 
      (y c (d y )))
     ((test x y) (z x y))
   (f x y))

is equivalent to

102

FUNCTIONS


(labels ((rec (x y) 
	    (cond ((test x y) 
		   (z x y))
		  (t 
		   (f x y) 
		   (rec (b x) (d y )))))) 
  (rec a c))

This model can be used to resolve any questions you might still have
about the behavior of do.

@node Parameter Lists
@section Parameter Lists


Section 2.1 showed that with prefix notation + could take any number
of arguments. Since then we have seen several functions that could
take varying numbers of arguments. To write such functions ourselves,
we need to use something called a rest parameter.

 If we insert the token ferest before the last variable in the
 parameter list of a function, then when the function is called, this
 variable will be set to a list of all the remaining arguments. Now we
 can see how funcall would be written in terms of apply. It
 might be defined as:



(defun o u r - funcall (fn ferest args) (apply fn a r g s ))

 We have also seen operators in which arguments could be omitted, and
 would default to certain values. Such parameters are called optional
 parameters. (By contrast, ordinary parameters are sometimes called
 required parameters.) If the symbol feoptional occurs in the
 parameter list of a function,


(defun philosoph ( t h i n g feoptional ( LIST thing ' i s property)) property)

then all the arguments after it are optional, and default to NIL :

 > (philosoph 'death) (DEATH IS NIL)

We give an explicit default by enclosing it in a list with the
parameter. This version of philosoph







(defun philosoph ( t h i n g feoptional ( LIST thing ' i s property)) (property 'fun))

6.4 has a more cheerful default:

> (philosoph 'death) (DEATH IS FUN)

PARAMETER LISTS

103

The default for an optional parameter need not be a constant. It can
be any Lisp expression. If this expression isn't a constant, it will
be evaluated anew each time a default is needed.

 A keyword parameter is a more flexible kind of optional parameter. If
 you put the symbol &key in a parameter list, then all the parameters
 after it are optional. Moreover, when the function is called, these
 parameters will be identified not by their position, but by symbolic
 tags that precede them:



> (defun keylist (a &key x y z) (list a x y z))
 KEYLIST
 > (keylist 1 :y 2)
 (1 NIL 2 NIL)
 > (keylist 1 :y 3 :x 2)


 ( 1 2 3 NIL)

 Like ordinary optional parameters, keyword parameters default to NIL,
 but explicit defaults may be specified in the parameter list.



 Keywords and their associated arguments can be collected in rest
 parameters and passed on to other functions that are expecting
 them. For example, we could define adjoin as:

(defun our-adjoin (obj lst &rest args) (if (apply #>member obj lst args) lst (cons obj lst )))

 Since adjoin takes the same keyword arguments as member, we just
 collect them in a rest argument and pass them on to member.

 Section 5.2 introduced the d e s t r u c t u r i n g - b i n d
 macro. In the general case, each subtree in the pattern given as the
 first argument may be as complex as the parameter list of a function:

 > ( d e s t r u c t u r i n g - b i n d ((&key w x) &rest y) ' ( ( : w 3) a) ( LIST w x y)) (3 NIL (A))

104

FUNCTIONS

@node Example-- Utilities
@section Example-- Utilities



Section 2.6 mentioned that Lisp consists mostly of Lisp functions,
just like the ones you can define yourself. This is a useful feature
to have in a programming language: you don't have to modify your ideas
to suit the language, because you can modify the language to suit your
ideas. If you find yourself wishing that Common Lisp included a
certain function, you can write it yourself, and it will be just as
much a part of the language as + or eql.

Experienced Lisp programmers work bottom-up as well as top-down. While
they're writing their program down toward the language, they also
build the language up toward their program. This way, language and
program meet sooner, and more neatly.

 Operators written to augment Lisp are called utilities. As you write
 more Lisp programs, you will find that you develop a collection of
 them, and that many of the utilities you write during one project
 will turn out to be useful in the next one.

 Professional programmers often find that the program they're working
 on now has a great deal in common with some program they wrote in the
 past. It is this feeling that makes the idea of software reuse so
 attractive. Somehow reuse has become associated with object-oriented
 programming. But software does not have to be object-oriented to be
 reusable--this is obvious when we look at programming languages (that
 is, compilers), which are the most reusable software of all.

 The way to get reusable software is to write programs bottom-up, and
 programs don't have to be object-oriented to be written bottom-up. In
 fact, the functional style seems even better adapted for writing
 reusable software. Consider s o r t . You are unlikely ever to have
 to write your own sort routines in Common Lisp\; s o r t is so fast
 and so general that it would not be worth the trouble. That's
 reusable software.

 You can do the same thing in your own programs by writing
 utilities. Figure 6.1 contains a selection of them. The first two,
 single? and append1, are included to show that even very short
 utilities can be useful. The former returns true when its argument is
 a list of one element,

 > (single? T '(a))

and the latter is like cons, but adds an element to the end of the
list instead of the front:

 > (appendl ' ( a b c) >d) (A B C D)

The next utility, map-int, takes a function and an integer n, and
returns a list of the results of calling the function on the integers
from 0 to n-1



6.4

EXAMPLE: UTILITIES

105

(defun single? (lst) (and (consp lst) (null (cdr lst))))
(defun appendl (lst obj) (append lst (list obj)))
(defun map-int (fn n) (let ((ace nil)) (dotimes (i n) (push (funcall fn i) ace)) (nreverse ace)))
(defun filter (fn lst) (let ((ace nil)) (dolist (x lst) (let ((val (funcall fn x))) (if val (push val ace)))) (nreverse ace)))
(defun most (fn lst)
  (if (null lst)
      (values nil nil)
      (let* ((wins (car lst))
	     (max (funcall fn wins)))
	(dolist (obj (cdr lst))
	  (let ((score (funcall fn obj)))
	    (when (> score max) (setf wins obj max score))))
	(values wins max))))

 Figure 6.1: Utility functions.

This turns out to be especially useful when one is testing code. (One of the advantages of Lisp's interactive environment is that it's easy to write programs to test your programs.) If we just wanted a list of the numbers from 0 to 9, we could say:

> (map-int # ' i d e n t i t y 10) (0 1 2 3 4 5 6 7 8 9)

106

FUNCTIONS









And if we wanted a list of 10 random numbers between 0 and 99
(inclusive), we could ignore the parameter and just say:

 > (map-int #'(lambda (x) (random 100)) 10) (85 40 73 64 28 21 40 67 5 32)

 The definition of map-int illustrates one of the standard Lisp idioms
 for building a list. We create an accumulator ace, initially NIL ,
 and push successive objects onto it. When we're finished, we reverse
 the accumulator.1

 We see the same idiom in f i l t e r . This function takes a function
 and a list, and returns all the non-nil values returned by the
 function as it is applied to the elements of the list:

 > (filter #>(lambda (x) (and (evenp x) (+ x 10))) ' ( 1 2 3 4 5 6 7))
 (12 14 16)

Another way to think of f i l t e r is as a generalized version of
remove-if. The last function in Figure 6.1, most, returns the element
of a list with the highest score, according to some scoring
function. It returns two values, the winning element, and its score:

 > (most #'length ' ( ( a b) (a b c) ( a ))) (A B C)
3

If there is a tie, the element occurring first is returned.

 Notice that the last three functions in Figure 6.1 all take functions
 as arguments. Lisp makes it convenient to pass functions as
 arguments, and that's one of the reasons it is so well suited to
 bottom-up programming.0 A successful utility must be general, and
 it's easier to abstract out the general when you can pass the
 specific as a functional argument.

 The functions given in this section were general-purpose
 utilities. They could be used in almost any kind of program. But you
 can write utilities for specific classes of programs as well. Indeed,
 as we'll see when we get to macros, you can write your own
 specialized languages on top of Lisp, if you want to. If you are
 trying to write reusable software, this would seem the surest way to
 do it.


'In this context, nreverse (described on page 222) does the same thing
as reverse, but is more efficient.



6.5

CLOSURES

107

@node Closures
@section Closures


A function can be returned as the value of an expression just like any
other kind of object. Here is a function that takes one argument, and
returns a function to combine arguments of that type:



(defun combiner (x) (typecase x (number #'+) (list #'append) (t #'list)))

 On top of this we can build a general combination function

(defun combine (ferest args) (apply (combiner (car args)) args))

 which takes arguments of any type and combines them in a way
 appropriate to their type. (To simplify the example, we assume that
 the arguments will all be of the same type.)

 > (combine 2 3) 5 > (combine '(a b) '(c d)) (A B C D)

Section 2.10 mentioned that lexical variables are only valid within
the context where they are defined. Along with this restriction comes
the promise that they will continue to be valid for as long as
something is using the context.

If a function is defined within the scope of a lexical variable, it
can continue to refer to that variable, even if it is returned as a
value outside the context where the variable was created. Here we
create a function that adds 3 to its argument:

 > (setf fn (let ((i 3)) #'(lambda (x) (+ x i))))
   #<Interpreted-Function C0A51E> > (funcall fn 2) 5

When a function refers to a variable defined outside it, it's called a
free variable. A function that refers to a free lexical variable is
called a closure.2 The variable must persist as long as the function
does.


2 The name "closure" is left over from earlier Lisp dialects. It
derives from the way closures have to be implemented under dynamic
scope.



108

FUNCTIONS

A closure is a combination of a function and an environment. Closures
are created implicitly whenever a function refers to something from
the surrounding lexical environment. This happens quietly in a
function like the following one, but it is the same idea:



(defun add-to-list (num lst) (mapcar #5(lambda (x) (+ x num)) lst))

 This function takes a number and a list, and returns a list of the
 sum of each element and the number. The variable num within the
 lambda expression is free, so in cases like this we're passing a
 closure to mapcar.

 A more conspicuous example would be a function that returned a
 different closure each time it was called. The following function
 returns an adder:




(defun make-adder (n) #>(lambda (x) (+ x n)))

It takes a number, and returns a function that adds that number to its argument:

> (setf add3 (make-adder 3)) #<Interpreted-Function C0EBF6>

> (funcall add3 2) 5 > (setf add27 (make-adder 27)) #<Interpreted-Function C0EE4E>

> (funcall add27 2) 29

We can even make several closures share variables. Here we define two
functions that share a counter.

(l e t ((counter 0))
   (defun r e s e t ()
	  (setf counter 0))
   (defun stamp () (setf counter (+ counter 1))))

Such a pair of functions might be used to create time-stamps. Each
time we call stamp we get a number one higher than the previous, and
by calling r e s e t we can set the counter back to zero:

 > ( LIST (stamp) (stamp) ( r e s e t ) ( 1 2 0 1) (stamp))

6.6

EXAMPLE: FUNCTION BUILDERS

109

You could do the same thing with a global counter, but this way the
counter is protected from unintended references.

 Common Lisp has a built-in function complement that takes a predicate
 and returns the opposite predicate. For example:

 > (mapcar (complement #,oddp) '(123456)) (NIL T NIL T NIL T)

 With closures such a function is easy to write:

 (defun our-complement (f) #'(lambda (&rest args) (not (apply f
 args))))

 If you stop to think about it, this is a remarkable little example\;
 yet it is just the tip of the iceberg. Closures are one of the
 uniquely wonderful things about Lisp. They open the door to
 programming techniques that would be inconceivable in other
 languages.0

@node Example-- Function Builders
@section Example-- Function Builders


Dylan is a hybrid of Scheme and Common Lisp, with a syntax like
Pascal.0 It has a large number of functions that return functions:
besides complement, which we saw in the previous section, Dylan
includes compose, d i s j o i n , conjoin, curry, rcurry, and
always. Figure 6.2 contains Common Lisp implementations of these
functions, and Figure 6.3 shows some equivalences that follow from
their definitions.

 The first, compose, takes one or more functions and returns a new
 function in which all of them are applied in succession. That is,

 (compose # ' a # ' b # ' c )

 returns a function equivalent to

 #'(lambda (ferest args) (a (b (apply # ' c a r g s ))))

 This means that the last argument to compose can take any number of
 arguments, but the other functions all have to take exactly one
 argument.

 Here we build a function that takes the square root of its argument,
 then rounds it, then returns a list containing it:

 > (mapcar (compose #'list #''round #'sqrt) '(4 9 16 25)) ((2) (3) (4) (5))

110

FUNCTIONS

(defun compose (ferest fns)
  (destructuring-bind (fnl . rest) (reverse fns) #'(lambda (forest args) (reduce #'(lambda (v f) (funcall f v)) rest :initial-value (apply fnl args)))))

(defun disjoin (fnferestfns)
  (if (null fns) fn (let ((disj (apply #'disjoin fns))) #'(lambda (ferest args) (or (apply fn args) (apply disj args))))))

(defun conjoin (fnferestfns)
  (if (null fns) fn (let ((conj (apply #>conjoin fns))) #'(lambda (ferest args) (and (apply fn args) (apply conj args))))))

(defun curry (fn ferest args)
  #'(lambda (ferest args2) (apply fn (append args args2))))

(defun rcurry (fn ferest args)
  #'(lambda (ferest args2) (apply fn (append args2 args))))

(defun always (x)
  #'(lambda (ferest args) x))

 Figure 6.2: Dylan function builders.

The next two functions, d i s j o i n and conjoin, both take one or
more predicates as arguments: d i s j o i n returns a predicate that
returns true when any of the predicates return true, and con j oin
returns a predicate that returns true when all of the predicates
return true.

> (mapcar (disjoin #'integerp #'symbolp) '(a "a" 2 3)) (T NIL T T)

6.7

EXAMPLE: FUNCTION BUILDERS

111

cddr = (compose #'cdr # 'cdr)
nth = (compose #'car #'nthcdr)
atom = (compose #'not # 'consp)
1 = (rcurry #'typep 'atom)
<= = (disjoin #'< #' =)
listp = (disjoin #'null #'consp) = (rcurry #'typep 'list)
1+ = (curry #' + 1) ss (rcurry #' + 1)
1- = (rcurry #>- 1) mapcan ^ (compose (curry #'apply #'nconc) #'mapcar)
complement = (curry #'compose #'not)

Figure 6.3: Somei equivalences.

> (mapcar (conjoin #'integerp #'oddp) '(a "a" 2 3)) (NIL NIL NIL T)

If predicates are considered as defining sets, d i s j oin returns the
union of its arguments, and conjoin returns the intersection.

 The functions curry and rcurry ("right curry") are similar in spirit
 to make-adder in the previous section. Both take a function and some
 of the arguments to it, and return a new function that expects the
 rest of the arguments. Either of the following is equivalent to
 (make-adder 3):

 (curry #'+ 3) (rcurry #'+ 3)

The difference between curry and rcurry becomes evident when the
function is one for which the order of arguments matters. If we curry
-, we get a function that subtracts its argument from a certain
number,

 > (funcall (curry # ' - 3) 2) 1

while if we rcurry -, we get a function that subtracts a certain
number from its argument:

 > (funcall (rcurry # ' - 3) 2) -1

Finally, always is the Common Lisp function constantly. It takes an
argument and returns a function that returns it. Like identity, it is
useful mainly in situations where functional arguments are required.



112

FUNCTIONS

@node Dynamic Scope
@section Dynamic Scope





Section 2.11 distinguished between local and global variables. The
real distinction here is between lexical variables, which have lexical
scope, and special variables, which have dynamic scope. But it's
almost the same distinction, because local variables are nearly always
lexical variables, and global variables are always special variables.

 Under lexical scope, a symbol refers to the variable that has that
 name in the context where the symbol appears. Local variables have
 lexical scope by default. So if we define a function in an
 environment where there is a variable called x,

 (let ((x 10)) (defun foo () x))

then the x in the body will refer to that variable, regardless of any
x that might exist where foo is called:

 > (let ((x 20)) 10 (foo))


With dynamic scope, we look for a variable in the environment where
the function is called, not in the environment where it was defined.0
To cause a variable to have dynamic scope, we must declare it to be s
p e c i a l in any context where it occurs. If we defined foo instead
as

 (let ((x 10)) (defun foo () ( d e c l a r e ( s p e c i a l x)) x))

 then the x within the function will no longer refer to the lexical
 variable existing where the function was defined, but will refer to
 whatever special x exists at the time the function is called:

 > (let ((x 20)) ( d e c l a r e ( s p e c i a l x)) (foo)) 20

A d e c l a r e can begin any body of code where new variables are
created. The s p e c i a l declaration is unique, in that it can
change the way a program behaves. Chapter 13 discusses other kinds of
declarations. All other declarations are simply advice to the
compiler\; they may make a program run faster, but they will not
change what it does.



6.8

COMPILATION

113

Global variables established by calling s e t f at the toplevel are
implicitly special:

 > (setf x 30) 30 > (foo) 30

Within a file of code, it makes a program clearer if you don't rely on
the implicit special declaration, and instead use defparameter.

 Where is dynamic scope useful? Usually it is used to give some global
 variable a new value temporarily. For example, there are 11 global
 variables that control the way objects are printed, including * p r i
 n t - b a s e * , which is 10 by default. If you want to display
 numbers in hexadecimal (base 16), you can do it by rebinding * p r i
 n t - b a s e * :

 > (let ( ( * p r i n t - b a s e * 16)) (princ 32)) 20 32

Two things are displayed here: the output generated by princ, and
the value it returns. They represent the same number, displayed first
in hexadecimal because * p r i n t - b a s e * was 16 when it was
printed, and the second time in decimal because, outside the l e t
expression, * p r i n t - b a s e * reverts to its previous value, 10.

@node Compilation
@section Compilation


Common Lisp functions can be compiled either individually or by the
file. If you just type a def un expression into the toplevel,

 > (defun foo (x) (+ x 1)) FOO

 many implementations will create an interpreted function. You can
 check whether a function is compiled by passing it to compiled-f
 unction-p:

 > (compiled-function-p #'foo) NIL

If you give the name of foo to compile


> (compile 'foo) FOO

114

FUNCTIONS

its definition will be compiled, and the interpreted definition will
be replaced by the compiled one. Compiled and interpreted functions
behave the same, except with respect to compiled-f unction-p.

 You can also give lists as arguments to compile. This use of compile
 is discussed on page 161.

 There is one kind of function you can't give as an argument to
 compile: a function like stamp or r e s e t that was typed into the
 toplevel within a distinct lexical context (e.g. a l e t ) . 3 It
 would be ok to define these functions within a file, and then compile
 and load the file. The restriction is imposed on interpreted code for
 implementation reasons, not because there's anything wrong with
 defining functions in distinct lexical environments.

 The usual way to compile Lisp code is not to compile functions
 individually, but to compile whole files with compile-f i l e . This
 function takes a filename and creates a compiled version of the
 source file--typically with the same base name but a different
 extension. When the compiled file is loaded, compiled-f u n c t i o n
 - p should return true for all the functions defined in the file.

 When one function occurs within another, and the containing function
 is compiled, the inner function should also be compiled. So when
 make-adder (page 108) is compiled, it will return compiled functions:

> (compile 'make-adder) MAKE-ADDER > (compiled-function-p (make-adder 2)) T


@node Using Recursion
@section Using Recursion

Recursion plays a greater role in Lisp than in most other
languages. There seem to be three main reasons why:

1. Functional programming. Recursive algorithms are less likely to
involve side-effects.

2. Recursive data structures. Lisp's implicit use of pointers makes it
easy to have recursively defined data structures. The most common is
the list: a list is either NIL , or a cons whose cdr is a list.

 3. Elegance. Lisp programmers care a great deal about the beauty of
 their programs, and recursive algorithms are often more elegant than
 their iterative counterparts.

3 In pre-ANSl Common Lisps, the first argument to compile also could
not be a function that was already compiled.




6.9

USING RECURSION

115

Students sometimes find recursion difficult to understand at
first. But as Section 3.9 pointed out, you don't have to think about
all the invocations of a recursive function if you want to judge
whether or not is correct.

 The same is true if you want to write a recursive function. If you
 can describe a recursive solution to a problem, it's usually
 straightforward to translate your solution into code. To solve a
 problem using recursion, you have to do two things:

 1. You have to show how to solve the problem in the general case by
 breaking it down into a finite number of similar, but smaller,
 problems.

 2. You have to show how to solve the smallest version of the
 problem--the base case--by some finite number of operations.

 If you can do this, you're done. You know that a finite problem will
 get solved eventually, because each recursion makes it smaller, and
 the smallest problem takes a finite number of steps.

For example, in the following recursive algorithm for finding the
length of a proper list, we find the length of a smaller list on each
recursion:

 1. In the general case, the length of a proper list is the length of
 its cdr plus 1.

 2. The length of an empty list is 0.

 When this description is translated into code, the base case has to
 come first\; but when formulating recursive algorithms, one usually
 begins with the general case.

 The preceding algorithm is explicitly described as a way of finding
 the length of a proper list. When you define a recursive function,
 you have to be sure that the way you break up the problem does in
 fact lead to smaller subproblems. Taking the cdr of a proper list
 yields a smaller subproblem for length, but-taking the cdr of a
 circular list would not.

 Here are two more examples of recursive algorithms. Again, both
 assume finite arguments. Notice in the second that we break the
 problem into two smaller problems on each recursion:

 member copy-tree

 Something is a member of a list if it is the first element, or a
 member of the cdr. Nothing is a member of the empty list.



The copy-tree of a cons is a cons made of the c o p y - t r e e of its
car, and the c o p y - t r e e of its cdr. The c o p y - t r e e of an
atom is itself.



Once you can describe an algorithm this way, it is a short step to
writing a recursive definition.



116

FUNCTIONS


Some algorithms are most naturally expressed in such terms and some
are not. You would have to bend over backwards to define our-copy-tree
(page 41) without using recursion. On the other hand, the iterative
version of show-squares on page 23 is probably easier to understand
than the recursive version on page 24. Sometimes it may not be obvious
which form will be more natural until you try to write the code.

 If you're concerned with efficiency, there are two more issues to
 consider. One, tail-recursion, will be discussed in Section
 13.2. With a good compiler there should be little or no difference in
 speed between a tail-recursive function and a loop. However, if you
 would have to go out of your way to make a function tail-recursive,
 it may be better just to use iteration.

The other issue to bear in mind is that the obvious recursive
algorithm is not always the most efficient. The classic example is the
Fibonacci function. It is defined recursively,

1. Fib(0) = F i b ( l ) = l .

2. Fib(n) = Fib(n-1) + Fib(rc-2).

 but the literal translation of this definition,

(defun f i b (n) ( i f « = n 1) 1 (+ ( f i b (- n 1)) ( f i b (- n 2 )
))))

 is appallingly inefficient. The same computations are done over and
 over. If you ask for ( f i b 10), the function computes ( f i b 9)
 and ( f i b 8). But to compute ( f i b 9), it has to compute ( f i b
 8) again, and so on.

 Here is an iterative function that computes the same result:

 (defun f i b (do ( ( i (fl (f2 («= (n) n (- i 1)) 1 (+ f l f2)) 1
 fl)) i 1) f l )))

The iterative version is not as clear, but it is far more
efficient. How often does this kind of thing happen in practice? Very
rarely--that's why all textbooks use the same example--but it is
something one should be aware of.



EXERCISES

117

Summary

1. A named function is a function stored as the symbol-function of a
symbol. The def un macro hides such details. It also allows you to
define documentation strings, and specify how s e t f should treat
calls.


2. It is possible to define local functions, similar in spirit to
local variables.


3. Functions can have optional, rest, and keyword parameters.


4. Utilities are additions to Lisp. They are an example of bottom-up
programming on a small scale.


5. Lexical variables persist as long as something refers to
them. Closures are functions that refer to free variables. You can
write functions that return closures.


6. Dylan provides functions for building functions. Using closures,
it's easy to implement them in Common Lisp.


7. Special variables have dynamic scope.


8. Lisp functions can be compiled individually, or (more usually) by
the file.


9. A recursive algorithm solves a problem by dividing it into a finite
number of similar, but smaller, problems.



Exercises


1. Define a version of tokens (page 67) that takes : t e s t and : s t
a r t arguments defaulting to # ' c o n s t i t u e n t and 0
respectively.

2. Define a version of b i n - s e a r c h (page 60) that takes :key,
: t e s t , : s t a r t , and : end arguments with the usual meanings
and defaults.

 3. Define a function that takes any number of arguments and returns
 the number of arguments passed to it.

 4. Modify most (page 105) to return, as two values, the two
 highestscoring elements of a list.

 5. Define remove-if (no keywords) in terms of f i l t e r (page 105).

 6. Define a function that takes one argument, a number, and returns the greatest argument passed to it so far.

118

FUNCTIONS

7. Define a function that takes one argument, a number, and returns
true if it is greater than the argument passed to the function the
last time it was called. The function should return NIL the first time
it is called.

8. Suppose expensive is a function of one argument, an integer between
0 and 100 inclusive, that returns the result of a time-consuming
computation. Define a function frugal that returns the same answer,
but only calls expensive when given an argument it has not seen
before.

 9. Define a function like apply, but where any number printed out before it returns will be printed, by default, in octal (base 8).



@node Input/Output
@chapter Input/Output


Common Lisp has powerful I/O facilities. For input, along with the
usual functions for reading characters, we get read, which includes a
complete parser. For output, along with the usual functions for
writing characters, we get format, which is almost a language in its
own right. This chapter introduces all the basic concepts.

 There are two kinds of streams, character streams and binary
 streams. This chapter describes operations on character streams\;
 binary streams are covered in Section 14.2.

@menu 
* Streams::
* Input::
* Output::
* Example-- String Substitution::
* Macro Characters::
@end menu

@node Streams
@section Streams


Streams are Lisp objects representing sources and/or destinations of
characters. To read from or write to a file, you open it as a
stream. But streams are not identical with files. When you read or
print at the toplevel, you also use a stream. You can even create
streams that read from or write to strings.



By default, input is read from the stream *standard-input*. The
default place for output is *standard-output*. Initially they will
probably be the same place: a stream representing the toplevel.



Already we have seen READ and FORMAT used to read from and print to
the toplevel. The former takes an optional argument, which should be a
stream, and defaults to *standard-input*. The first argument to format
can also be a stream, but when it is t, the output is sent to
*standard-output*. So what we have been doing so far is using the
defaults. We could do the same I/O operations on any stream.



119

120

INPUT AND OUTPUT

A pathname is a portable way of specifying a file. A pathname has six
components: host, device, directory, name, type, and version. You can
make one by calling make-pathname with one or more of the
corresponding keyword arguments. In the simplest case, you could just
specify the name and let the rest of the pathname default:



> (setf path (make-pathname :name "myfile"))
 #P"myfile"

The basic function for opening a file is OPEN. It takes a pathname1
and a large number of optional keyword arguments, and if successful,
returns a stream that points to the file.

You specify how you intend to use a stream when you create it. The
:direction argument signals whether you are going to write to the
stream, read from it, or both. The three corresponding values are :
input, : output, and : io. If the stream is used for output, the
:if-exists argument says what to do if the destination file already
exists\; usually it should be : supersede. So to create a stream on
which you can write to the file "myfile", you might say:



> (setf str (open path :direction :output :if-exists :supersede))
#<Stream C017E6>

The printed representation of streams is implementation-dependent.

Now if we give this stream as the first argument to format, it will
print to the stream instead of the toplevel:


> (format str "Something~%") NIL

If we look at the file at this point, the output may or may not be
there. Some implementations save up output to write in chunks. It may
not all appear until we close the stream:


> (close s t r ) NIL

Always close a file when you are finished using it\; nothing is
guaranteed about its contents until you do. Now if we look in the file
"myfile", there should be single line:

 Something

1You can give a string instead of a pathname, but this is not
portable.





7.2

INPUT

121

If we just want to read from a file, we open a stream with : d i r e c
t i o n :input:



> (setf str (open path :direction :input)) #<Stream C01C86>

We can use any input function on a file. Section 7.2 describes input
in more detail. Here as an example we will use r e a d - l i n e to
read a line of text from the file:


> (read-line str) "Something" NIL > (close str) NIL

Remember to close a file when you're finished reading from it.



Much of the time one does not use open and c l o s e directly to do
file I/O. The w i t h - o p e n - f i l e macro is often more
convenient. Its first argument should be a list containing a variable
name followed by arguments you might give to open. After this it takes
a body of code, which is evaluated with the variable bound to a stream
created by passing the remaining arguments to open. Afterward the
stream is automatically closed. So our entire file-writing operation
could be expressed:

( w i t h - o p e n - f i l e ( s t r path : d i r e c t i o n :output
    : i f - e x i s t s :supersede) (format s t r "Something%"))

The with-open-file macro puts the c l o s e within an unwind-protect
(page 92), so the file is guaranteed to get closed, even if an error
interrupts the evaluation of the body.

@node Input
@section Input


The two most popular input functions are READ-LINE and READ. The
former reads all the characters up to a newline, returning them in a
string. It takes an optional stream argument\; if the stream is
omitted, it will default to *standard-input*:


> (progn
    (format t "Please enter your name: ")
    (read-line))

Please enter your name: Rodrigo de Bivar
"Rodrigo de Bivar"
 NIL

122

INPUT AND OUTPUT

This is the function to use if you want verbatim input. (The second
return value is true only if r e a d - l i n e ran out of input before
encountering a newline.)

 In the general case, r e a d - l i n e takes four optional arguments:
 a stream\; an argument to tell whether or not to cause an error on
 encountering endof-file\; what to return instead if the previous
 argument is NIL \; and a fourth argument (discussed on page 235) that
 can usually be ignored.

 So to display the contents of a file at the toplevel, we might use
 the following function:



(defun pseudo-cat (file)
  (with-open-file (str file rdirection :input)
    (do ((line (read-line str nil 'eof) (read-line str nil 'eof)))
	((eql line 'eof))
      (format t "~A~%" line))))

If you want input parsed into Lisp objects, use READ. This function
reads exactly one expression, and stops at the end of it. So it could
read less than a line or more than a line. And of course what it reads
has to be valid Lisp syntax.

If we use read at the toplevel, it will let us use as many newlines as
we want within an expression:

 > (read) (a b c) (A B C)

 On the other hand, if we type several expressions on a single line,
 read will stop processing characters after the first, leaving the
 remaining characters to be picked up by whatever reads next from this
 stream. So if in response to the prompt printed by ask-number (page
 20) we type several expressions on a line, the following will happen:

 > (ask-number) Please enter a number, a b Please enter a
number. Please enter a number. 43 43

Two successive prompts are printed on the second line. The first call
to read returns a, which is not a number, so the function asks again
for a number. But the first read only read up to the end of a. So the
next call to read returns b, causing another prompt.



7.3

OUTPUT

123



You may want to avoid using read directly to process user input. The
preceding function would be better off if it used r e a d - l i n e to
get what the user typed, then called read-f r o m - s t r i n g on the
resulting string.0 This function takes a string and returns the first
expression read from it:

 > ( r e a d - f r o m - s t r i n g "a b c") A
2

It also returns a second value, a number indicating the position in
the string at which it stopped reading.

 In the general case, read-f r o m - s t r i n g can take two optional
 and three keyword arguments. The two optional arguments are the third
 and fourth arguments to read: whether an end-of-file (or in this case
 string) should cause an error, and if not, what to return
 instead. The keyword parameters : s t a r t and : end can be used to
 delimit the portion of the string read.

 All these input functions are defined in terms of the primitive r e a
 d - char, which reads a single character. It takes the same four
 optional arguments as read and r e a d - l i n e . Common Lisp also
 defines a function called peek-char, which is like r e a d - c h a r
 but does not remove the character from the stream.

@node Output
@section Output



The three simplest output functions are p r i n l , princ, and t
e r p r i . For all three the last argument is an optional stream
argument, which defaults to *standard-output*.

 The difference between p r i n l and princis roughly that p r i
 n l generates output for programs, and pr inc generates output for
 people. So, for example, p r i n l prints the double-quotes around a
 string, and princdoesn't:

 > ( p r i n l "Hello") "Hello" "Hello" > (princ "Hello") Hello
   "Hello"

Both return their first argument--which, incidentally, is displayed by
p r i n l . The function t e r p r i just prints a newline. It is
useful to have these functions as background when explaining the
behavior of the more general format. This function can be used for
almost all output. It takes a stream (or t or NIL ) , a format string,
and zero or more



124

INPUT AND OUTPUT

additional arguments. The format string may containformat directives,
which are preceded by a ~ (tilde). Some format directives act as
placeholders in the string. Their places will be taken by the
representations of the arguments given after the format string.

 If we give t as the first argument, output is sent to * s t a n d a r
 d - output*. If we give NIL , format returns as a string what it
 would have printed. For the sake of brevity we'll do this in all the
 examples here.

 Depending on one's point of view, format is either amazingly powerful
 or horribly complex. There are a large number of format directives,
 only a few of which most programmers will ever use. Two of the most
 commonly used format directives are ~A and ~%. (It doesn't matter
 whether you say "a or "A, but the latter form is more common because
 it makes the format directive stand out.) A ~A is a placeholder for a
 value, which will be printed as if by princ. A ~V, represents a
 newline.


> (format nil "Dear ~k,~% Our records indicate..." "Mr. Malatesta") "Dear Mr. Malatesta, Our records indicate..."

Here format has returned a single value, consisting of a string
containing a newline.

 The ~S format directive is just like "A", but prints objects as if by
 p r i n l , rather than princ:


> (format t "~S "z" z NIL ~A" "z" "z")

Format directives can take arguments. ~F, which is used for printing
right-justified floating-point numbers, can take up to five:

 1. The total number of characters to be printed. Defaults to the
 exact length of the number.

 2. The number of digits to print after the decimal. Defaults to all
 of them.

 3. The number of digits to shift the decimal point to the left
 (thereby effectively multiplying the number by 10). Defaults to none.

 4. The character to print instead of the number if it is too long to
 fit in the space allowed by the first argument. If no character is
 specified, an over-long number will be printed using as much space as
 it needs.

5. The character to print to the left before the digits start. Defaults to a blank.

7.4

EXAMPLE: STRING SUBSTITUTION

125

Here is a rare example with all five arguments:

> (format NIL " " 1 0 , 2 , 0 , ' * , ' F" 26.21875)
26.22"

This is the original number rounded to 2 decimal places, (with the
decimal point shifted left 0 places), right-justified in a field of 10
characters, padded on the left by blanks. Notice that a character
given as an argument is written as ' *, not the usual #\*. Since the
number fit in 10 characters, the fourth argument didn't have to be
used.

 All these arguments are optional. To use the default you can simply
 omit the corresponding argument. If all we want to do is print a
 number rounded to two decimal places, we can say:



> (format NIL " ~ , 2 , , , F " 26.21875) "26.22"

You can also omit a series of trailing commas, so the more usual way
to write the preceding directive would be:



> (format NIL "~,2F" 26.21875) "26.22"

Warning: When format rounds, it does not guarantee to round up or to
round down. That is, (format NIL "~,1F" 1.25) could yield either "
1.2" or " 1.3". So if you are using format to display information that
the user expects to see rounded in one particular way (e.g. dollar
amounts), you should round the number explicitly before printing it.

@node Example-- String Substitution
@section Example-- String Substitution


As an example of I/O, this section shows how to write a simple program
to do string substitution in text files. We're going to write a
function that can replace each instance of a string old in a file with
some other string new. The simplest way to do this is to look at each
character in the input file and compare it to the first character of
old. If they don't match, we can just print the input character
straight to the output file. If they do match, we compare the next
input character against the second character of old, and so on. If the
characters are the same all the way to the end of old, we have a
successful match, and we print new to the output file.0

What happens, though, if we get part of the way through old and the
match fails? For example, suppose we are looking for the pattern
"abac", and the input file contains "ababac". The input will seem to
match the pattern until we get to the fourth character, which is c in
the pattern and b in the input. At



126

INPUT AND OUTPUT

this point we can write the initial a to the output file, because we
know that no match begins there. But some of the characters that we
have read from input file we still need: for example, the third
character, a, does begin a successful match. So before we can
implement this algorithm, we need a place to store characters that
we've read from the input file but might still need.

 A queue for storing input temporarily is called a buffer. In this
 case, because we know we'll never need to store more than a
 predetermined number of characters, we can use a data structure
 called a ring buffer. A ring buffer is a vector underneath. What
 makes it a ring is the way it's used: we store incoming values in
 successive elements, and when we get to the end of the vector, we
 start over at the beginning. If we never need to store more than n
 values, and we have a vector of length n or greater, then we never
 have to overwrite a live value.

 The code in Figure 7.1 implements operations on ring buffers. The buf
 structure has five fields: a vector that will contain the objects
 stored in the buffer, and four other fields that will contain indices
 into the vector. Two of these indices, s t a r t and end, we would
 need for any use of ring buffers: s t a r t points to the first value
 in the buffer, and will be incremented when we pop a value\; end
 points to the last value in the buffer, and is incremented when we
 insert a new one.

 The other two indices, used and new, are something we need to add to
 the basic ring buffer for this application. They will range between s
 t a r t and end. In fact, it will always be true that s t a r t <
 used < new < end You can think of used and new as being like s t a r
 t and end for the current match. When we start a match, used will be
 equal to s t a r t and new will be equal to end. We will increment
 used as we match successive characters from the buffer. When used
 reaches new, we have read all the characters that were in the buffer
 at the time the match started. We don't want to use more than the
 characters that were in the buffer when the match started, or we
 would end up using the same characters multiple times. Hence the
 distinct new index, which starts out equal to end, but is not
 incremented as new characters are inserted into the buffer during a
 match.

 The function bref takes a buffer and an index, and returns the
 element stored at that index. By using the index mod the length of
 the vector, we can pretend that we have an arbitrarily long
 buffer. Calling (new-buf ri) yields a new buffer able to hold up to n
 objects.

 To insert new values into a buffer, we will use b u f - i n s e r t
 . It simply increments the end and puts the new value at that
 location. The converse is buf-pop, which returns the first value in a
 buffer, then increments its s t a r t . These two functions would
 come with any ring buffer.



7.4

EXAMPLE: STRING SUBSTITUTION

127

(defstruct buf vec (start -1) (used -1) (new -1) (end -1)) (defun bref (buf n) (svref (buf-vec buf) (mod n (length (buf-vec buf))))) (defun (setf bref) (val buf n) (setf (svref (buf-vec buf) (mod n (length (buf-vec buf)))) val)) (defun new-buf (len) (make-buf :vec (make-array len))) (defun buf-insert (x b) (setf (bref b (incf (buf-end b))) x)) (defun buf-pop (b) (progl (bref b (incf (buf-start b))) (setf (buf-used b) (buf-start b) (buf-new b) (buf-end b)))) (defun buf-next (b) (when (< (buf-used b) (buf-new b)) (bref b (incf (buf-used b))))) (defun buf-reset (b) (setf (buf-used b) (buf-start b) (buf-new b) (buf-end b))) (defun buf-clear (b) (setf (buf-start b) -1 (buf-used (buf-new b) -1 (buf-end b) -1 b) -1))

(defun buf-flush (b str) (do ((i (1+ (buf-used b)) (1+ i))) ((> i (buf-end b))) (princ (bref b i) str)))

Figure 7.1: Operations on ring buffers.

128

INPUT AND OUTPUT

The next two functions are ones that we need specifically for this
application: buf-next reads a value from a buffer without popping it,
and b u f - r e s e t resets the used and new indices to their initial
values, s t a r t and end. If we have already read all the values up
to new, buf-next returns NIL . It won't be a problem distinguishing
this from a real value because we're only going to store characters in
the buffer.

 Finally, b u f - f l u s h flushes a buffer by writing all the live
 elements to a stream given as the second argument, and b u f - c l e
 a r empties a buffer by resetting all the indices to - 1 .

 The functions defined in Figure 7.1 are used in Figure 7.2, which
 contains the code for string substitution. The function f i l e - s u
 b s t takes four arguments\; a string to look for, a string to
 replace it, an input file, and an output file. It creates streams
 representing each of the files, then calls stream-subst to do the
 real work.

 The second function, stream-subst, uses the algorithm sketched at the
 beginning of this section. It reads from the input stream one
 character at a time. Until the input character matches the first
 element of the sought-for string, it is written immediately to the
 output stream (1). When a match begins, the characters involved are
 queued in the buffer buf (2).

The variable pos points to the position of the character we are trying
to match in the sought-for string. When and if pos is equal to the
length of this string, we have a complete match, and we write the
replacement string to the output stream, also clearing the buffer
(3). If the match fails before this point, we can pop the first
character in the buffer and write it to the output stream, after which
we reset the buffer and start over with pos equal to zero (4).

The following table shows what happens when we substitute " b a r i c
" for "baro" in a file containing just the word barbarous:


CHAR b a r b a r b a r o u s SOURCE file file file file buffer buffer buffer file file file file file MATCH b a r o b b b a r o b b CASE OUTPUT BUFFER ~b b a b a r b.a r b. a.r b. r.b. r b: r b:a r b:a r

2
·2

2 4 1 1 1 2 2 3 1 1

b a r

baric u s

7.4

EXAMPLE: STRING SUBSTITUTION

129

1 (defun file-subst (old new filel file2) 1 (with-open-file (in filel .-direction .-input) (with-open-file (out file2 :direction :output :if-exists :supersede) (stream-subst old new in out))))

(defun stream-subst (old new in out) (let* ((pos 0) (len (length old)) (buf (new-buf len)) (from-buf nil)) (do ((c (read-char in nil :eof) (or (setf from-buf (buf-next buf)) (read-char in nil :eof)))) ((eql c :eof)) (cond ((char= c (char old pos)) (incf pos) (cond ((= pos len) ; 3
(princ new out) (setf pos 0) (buf-clear buf)) ((not from-buf) ; 2
 (buf-insert c buf)))) ((zerop pos) ; l
 (princ c out) (when from-buf (buf-pop buf) (buf-reset buf))) (t ; 4
(unless from-buf (buf-insert c buf)) (princ (buf-pop buf) out) (buf-reset buf) (setf pos 0)))) (buf-flush buf out)))

Figure 7.2: String substitution.

|

130

INPUT AND OUTPUT

The first column is the current character--the value of c; the second
shows whether it was read from the buffer or directly from the input
stream; the third shows the character it has to match--the posth
element of old; the fourth shows which case is evaluated as a result;
the fifth shows what is thereby written to the output stream; and the
last column shows the contents of the buffer afterwards. In the last
column, the positions of used and new are shown by a period after the
character they point to; when both point to the same position, it is
indicated by a colon.

 If the file " t e s t l " contained the following text


The struggle between Liberty and Authority is the most conspicuous
feature in the portions of history with which we are earliest
familiar, particularly in that of Greece, Rome, and England.

then after evaluating (file-subst " th" " z" "testl" "test2M),the file
"test2" would read:

The struggle between Liberty and Authority is ze most conspicuous
feature in ze portions of history with which we are earliest familiar,
particularly in zat of Greece, Rome, and England.

To keep this example as simple as possible, the code shown in Figure
7.2 just replaces one string with another. It would be easy to
generalize it to search for a pattern instead of a literal string. All
you would have to do is replace the call to char= with a call to
whatever more general matching function you wanted to write.


@node Macro Characters
@section Macro Characters


A macro character is a character that gets special treatment from
read. A lowercase a, for example, is ordinarily handled just like a
lowercase b, but a left parenthesis is something different: it tells
Lisp to begin reading a list.

 A macro character or combination of macro characters is also known as
 a read-macro. Many of Common Lisp's predefined read-macros are
 abbreviations. Quote, for example: as an expression like ' a is read,
 it is expanded by the reader into a list, (quote a ) . When you type
 quoted expressions into the toplevel, they are evaluated as soon as
 they are read, so ordinarily you never see this transformation. You
 can make it visible by invoking read explicitly:


> (car (read-from-string '"a")) QUOTE

SUMMARY

131



Quote is unusual for a read-macro in that it's expressed as a single
character. With a limited character set, you can only have so many
one-character read-macros; most of the read-macros in Common Lisp are
expressed using two or more characters.

 Such read-macros are called dispatching read-macros, and the first
 character is called the dispatching character. All the predefined
 dispatching read-macros use the sharp sign, #, as the dispatching
 character. We have seen quite a few of them already. For example, # '
 is an abbreviation for (function ...) in the same way that ' is an
 abbreviation for (quote . . . ) .

 Other dispatching read-macros we've seen include # ( . . . ) , which
 yields a vector; #nA(...) which yields an array; #\, which yields a
 character; and #S(n . . . ) , which yields a structure. When objects
 of each of these types are displayed by p r i n l (or format with
 ~S), they are displayed using the corresponding read-macros.2 This
 means that you can write such objects out and read them back in:


> (let ((*print-array* t)) (vectorp (read-from-string (format nil "~S" (vector 1 2))))) T

Of course, what we get back is not the same vector, but a new one with
the same elements.

 Not all objects are displayed in a distinct, readable form. Both
 functions and hash tables, for example, tend to be displayed as
 #<. . . >. In fact, #< is also a read-macro, but one that exists
 specifically to cause an error if it is encountered by
 read. Functions and hash tables can't be written out and read back
 in, and this read-macro ensures that users will have no illusions on
 this point.3

When you're defining your own representations for things (the
printfunctions of structures, for example), you should keep this
principle in mind. Either use a representation that can be read back
in, or use #<. . . >.



Summary

1. Streams are sources of input or destinations of output. In
character streams, the input and output consists of characters.


2. The default stream points to the toplevel. New streams can be made
by opening files.


To get vectors and arrays displayed this way, set * p r i n t - a r r a y * to t. Lisp couldn't just use sharp-quote to represent functions, because sharp-quote by itself offers no way to represent a closure.

3 2


132

INPUT AND OUTPUT


3. You can get input as parsed objects, as strings of characters, or
as individual characters.


4. The format function provides elaborate control over output.


5. To substitute one string for another in a text file, you have to
read characters into a buffer.


6. When read encounters a macro character like ', it calls the
associated function.



Exercises

1. Define a function that takes a filename and returns a list of
strings representing each line in the file.

 2. Define a function that takes a filename and returns a list of the
 expressions in the file.

3. Suppose that in some format for text files, comments are indicated
by a °/, character. Everything from this character to the end of the
line is ignored. Define a function that takes two filenames, and
writes to the second file a copy of the first, minus comments.

4. Define a function that takes a two-dimensional array of floats and
displays it in neat columns. Each element should be printed with two
digits after the decimal point, in a field 10 characters wide. (Assume
all will fit.) You will need array-dimensions (page 361).

5. Modify stream-subst to allow wildcards in the pattern. If the
character + occurs in old, it should match any input character.

6. Modify stream-subst so that the pattern can include an element that matches any digit character, an element that matches any alphanumeric character, or an element that matches any character. The pattern must also be able to match any specific input character. (Hint: old can no longer be a string.)



@node Symbols
@chapter Symbols

We've used symbols quite a bit already. There is more to them than
meets the eye. It may be best not to bother about the underlying
mechanism at first. You can use symbols as data objects and as names
for things without understanding how the two roles are related. But at
a certain point, it's useful to stop and consider what's really going
on. This chapter explains the details.

 8 Symbols

@menu 
* Symbol Names::
* Property Lists::
* Symbols Are Big::
* Creating Symbols::
* Multiple Packages::
* Keywords::
* Symbols and Variables::
* Example-- Random Text::
@end menu

@node Symbol Names
@section Symbol Names



Chapter 2 described symbols as variable names existing as objects in
their own right. But the range of possible Lisp symbols is broader
than the range of variable names allowed in most languages. In fact, a
symbol can have any string as its name. You can get the name of a
symbol by calling symbol-name:

 > (symbol-name 'abc) "ABC"

 Notice that the name of this symbol is all uppercase letters. By
 default Common Lisp converts all alphabetic characters in a symbol's
 name into uppercase as they are read. This means that, by default,
 Common Lisp is not case-sensitive:

 > (eql 'aBc 'Abe) T > (CaR ' ( a b c)) A

133

134

SYMBOLS



There is a special syntax for referring to symbols whose names contain
whitespace or other things that might otherwise be significant to the
reader. Any sequence of characters between vertical bars is treated as
a symbol. You can put anything in the name of a symbol this way:

> ( LIST ' I L i s p 1.51 Ml Mabel MABCl) (ILisp 1.51 II label ABC)
  When the name of such a symbol is read, there is no case conversion,
  and macro characters are treated just like other characters.

 So which symbols can you refer to without using vertical bars?
 Essentially, any symbol whose name is neither a number nor contains
 characters significant to the reader. A quick way to find out if you
 could refer to a symbol without using vertical bars is to see how
 Lisp prints it. If Lisp represents a symbol without vertical bars, as
 it did the last symbol in the list above, then you can too.

 Remember that the vertical bars are a special syntax for denoting
 symbols. They are not part of the symbol's name:

 > (symbol-name Ma b c | ) "a b c"

(If you want to use a vertical bar in the name of a symbol, you can do it by putting a backslash before the bar.)

@node Property Lists
@section Property Lists


In Common Lisp every symbol has a property-list, or plist. The
function get takes a symbol and a key of any type, and returns the
value associated with that key in the symbol's property list:

 > (get ' a l i z a r i n NIL 'color)



It uses eql to compare keys. If the specified property isn't found,
get returns nil.

 To associate a value with a key you can use s e t f with get:

 > ( s e t f (get ' a l i z a r i n ' c o l o r ) RED > (get ' a l i z a r i n ' c o l o r ) RED 'red)

Now the color property of a l i z a r i n is red.

8.4

SYMBOLS ARE BIG

135

package

-·

(color red)

Figure 8.1: Structure of a symbol.

The function symbol-plist returns the property list of a symbol:

 > (setf (get alizarin 'transparency) HIGH > (symbol-plist ' a l i z a r i n ) (TRANSPARENCY HIGH COLOR RED) 'high)

Notice that property lists are not represented as assoc-lists, though
they are used the same way.

 In Common Lisp, property lists aren't used very much. They have
 largely been superseded by hash tables (Section 4.8).

@node Symbols Are Big
@section Symbols Are Big


Symbols are created implicitly when we type their names, and when they
are displayed the name is all we see. Under the circumstances it's
easy to think that the symbol is what we see, and nothing more. But
there is more to symbols than meets they eye.

 From the way we use them and the way they look, it might seem that
 symbols would be small objects, like integers. In fact a symbol is a
 substantial object, more like the kind of structure that might be
 defined by def s t r u c t . A symbol can have a name, a home
 package, a value as a variable, a value as a function, and a property
 list. Figure 8.1 shows how symbols are represented internally.

Few programs use so many symbols that it would be worth using
something else to save space. But it is worth bearing in mind that
symbols are real objects, and not just names. When two variables are
set to the same symbol, it's the same as when two variables are set to
the same list: both variables have pointers to the same object.



136

SYMBOLS

@node Creating Symbols
@section Creating Symbols



Section 8.1 showed how to get from symbols to their names. It's also
possible to go in the other direction, from strings to symbols. This
gets a little more complicated, because we have to introduce the topic
of packages.

 Conceptually, packages are symbol-tables, mapping names to
 symbols. Every ordinary symbol belongs to a particular package. A
 symbol that belongs to a package is said to be interned in that
 package. Functions and variables have symbols as their
 names. Packages enforce modularity by restricting which symbols are
 accessible, and thus, which functions and variables one can refer to.

 Most symbols are interned when they are read. The first time you type
 the name of a new symbol, Lisp will create a new symbol object and
 intern it in the current package (which by default will be
 common-lisp-user). But you can also intern a symbol by giving a
 string and an optional package argument to i n t e r n :

 > ( i n t e r n "RANDOM-SYMBOL") RANDOM-SYMBOL NIL

The package argument defaults to the current package, so the preceding
expression returns the symbol in the current package whose name is the
string "RANDOM-SYMBOL", creating such a symbol if it doesn't already
exist. The second return value shows whether the symbol already
existed\; in this case, it didn't.

 Not all symbols are interned. It can sometimes be useful to have an
 uninterned symbol, for the same reason that it can be useful to have
 an unlisted phone number. Uninterned symbols are called
 gensyms. We'll see the point of gensyms when we come to macros in
 Chapter 10.

@node Multiple Packages
@section Multiple Packages 

Larger programs are often divided up into multiple packages. If each
part of a program is in its own package, then someone working on one
part of the program will be able to use a symbol as the name of a
function or variable without worrying that the name is already used
elsewhere.

In languages that don't provide a way to define multiple namespaces,
the programmers working on a big project usually work out some
convention to ensure that they don't use the same names. For example,
the programmer writing the display code might only use names beginning
with disp_, while the programmer writing the math code only used names
beginning with



8.6

KEYWORDS

137

math_. So if the math code included a function to do fast Fourier
transforms, it might be called math_f f t .

Packages just provide a way to do this automatically. If you define
your functions in a separate package, you can use whatever names you
like. Only symbols that you explicitly export will be visible in
other packages, and there they will usually have to be preceded (or
qualified) by the name of the package that owns them.

For example, suppose a program is divided into two packages, math and
disp. If the symbol f f t is exported by the math package, then code
in the disp package will be able to refer to it as math:fft. Within
 the math package, it will be possible to refer to it as simply f f t
 .

Here is what you might put at the top of afilecontaining a distinct
package of code:


(defpackage "MY-APPLICATION" (:use "COMMON-LISP" "MY-UTILITIES") (:nicknames "APP") (:export "WIN" "LOSE" "DRAW"))
(in-package my-application)

The defpackage defines a new package called my-application.1 It uses
two other packages, common-lisp and m y - u t i l i t i e s , which
means that symbols exported by these packages will be accessible
without package qualifiers. Most packages will use common-lisp--you
don't want to have to qualify the names of the built-in Lisp operators
and variables.

The my-application package itself exports just three symbols: win,
lose, and draw. Since the call to defpackage gave my-application the
nickname app, code in other packages will be able to refer to them as
e.g. app: win.

The defpackage is followed by an in-package that makes the current
package be my-application. All the unqualified symbols in the rest of
the file will be interned in my-application--unless there is another
in-package later on. When a file has been loaded, the current package
is always reset to the value it had before the load began.

@node Keywords
@section Keywords


Symbols in the keyword package (known as keywords) have two unique
properties: they always evaluate to themselves, and you can refer to
them


1 The names in the call to defpackage are all uppercase because, as mentioned in Section 8.1, symbol names are converted to uppercase by default.

138

SYMBOLS

anywhere simply as :x, instead of keyword:x. When keyword parameters
were first introduced on page 44, it might have seemed more natural
for the call to read (member ; (a) ' ( ( a ) (z)) t e s t : # ' equal)
rather than (member ' ( a ) ' ( ( a ) (z)) : t e s t # ' equal). Now
we see why the unnatural-looking second form is actually the correct
one. The colon prefixed to t e s t is just to identify it as a
keyword.

Why use keywords instead of ordinary symbols? Because they are
accessible anywhere. A function that takes symbols as arguments should
usually be written to expect keywords. For example, this function
could safely be called from any package:


(defun noise (animal) (case animal (:dog :woof) (:cat :meow) (:pig
:oink)))

If it had been written to use ordinary symbols, it would only work
when called from the package in which it was defined, unless the keys
were exported as well.

@node Symbols and Variables
@section Symbols and Variables


One potentially confusing thing about Lisp is that symbols are related
to variables in two very different ways. When a symbol is the name of
a special variable, the value of the variable is stored in a field
within the symbol (Figure 8.1). The symbol-value function refers to
that field, so we have a direct connection between a symbol and the
value of the special variable it represents.

With lexical variables, things are completely different. A symbol used
as a lexical variable is just a placeholder. The compiler will
translate it into a reference to a register or a location in
memory. In the eventual compiled code, there will be no trace of the
symbol (unless it is retained somewhere for use by the debugger). So
of course there is no connection between symbols and the values of the
lexical variables they represent; by the time there is a value, the
symbol is gone.


@node Example-- Random Text
@section Example-- Random Text

If you're going to write programs that operate on words, it's often a good idea to use symbols instead of strings, because symbols are conceptually atomic. Symbols can be compared in one step with eql, while strings have to be compared character-by-character with s t r i n g - e q u a l or string=. As an

8.8

EXAMPLE: RANDOM TEXT

139

example, this section shows how to write a program to generate random
text. The first part of the program will read a sample text (the
larger the better), accumulating information about the likelihood of
any given word following another. The second part will take random
walks through the network of words built in the first, after each word
making a weighted random choice among the words that followed it in
the original sample.

The resulting text will always be locally plausible, because any two
words that occur together will be two words that occurred together in
the input text. What's surprising is how often you can get entire
sentences--sometimes entire paragraphs--that seem to make sense.

Figure 8.2 contains the first half of the program, the code for
reading the sample text. The data derived from it will be stored in
the hash table *words*. The keys in this hash table will be symbols
representing words, and the values will be assoc-lists like the
following:

((Isinl . 1) (|wide I . 2) (I s i g h t s I . 1))

This is the value associated with the key I discover I when Milton's
Paradise Lost is used as the sample text. It indicates that "discover"
was used four times in the poem, being twice followed by "wide" and
once each by "sin" and "sights".

The function r e a d - t e x t accumulates this information. It takes
a pathname, and builds an assoc-list like the one shown above for each
word encountered in the file. It works by reading the file one
character at a time, accumulating words in the string buffer. With
maxword = 100, the program will be able to read words of up to 100
letters, which is sufficient for English.

As long as the next character is a letter (as determined by a l p h a
- char-p) or an apostrophe, we keep accumulating characters. Any other
character ends the word, whereupon the corresponding symbol is sent to
see. Several kinds of punctuation are also recognized as if they were
words; the function punc returns the pseudo-word corresponding to a
punctuation character.

The function see registers each word seen. It needs to know the
previous word as well as the one just recognized--hence the variable
prev. Initially this variable is set to the period pseudo-word; after
see has been called, it will always contain the last word sent to the
function.

After r e a d - t e x t returns, * words* will contain an entry for
each word in the input file. By calling h a s h - t a b l e - c o u n
t you can see how many distinct words there were. Few English texts
have over 10,000.

Now comes the fun part. Figure 8.3 contains the code that generates
text from the data accumulated by the code in Figure 8.2. The
recursive function g e n e r a t e - t e x t drives the process. It
takes a number indicating the number of words to be generated, and an
optional previous word. Using the default will make the generated text
start at the beginning of a sentence.



140

SYMBOLS

(defparameter *words* (make-hash-table :size 10000))

(defconstant maxword 100)

(defun read-text (pathname)
  (with-open-file (s pathname :direction :input)
    (let ((buffer (make-string maxword))
	  (pos 0))
      (do ((c (read-char s nil :eof)
	      (read-char s nil :eof)))
	  ((eql c :eof))
	(if (or (alpha-char-p c) (char= c #\'))
	    (progn
	      (setf (aref buffer pos) c)
	      (incf pos))
	    (progn
	      (unless (zerop pos)
		(see (intern (string-downcase
			      (subseq buffer 0 pos))))
		(setf pos 0))
	      (let ((p (punc c)))
		(if p (see p)))))))))

(defun punc (c)
  (case c
    (#\. '|.|)
    (#\, '|,|)
    (#\; '|;|)
    (#\! '|!|)
    (#\? '|?|)))

(let ((prev '|.|))
  (defun see (symb)
    (let ((pair (assoc symb (gethash prev *words*))))
      (if (null pair)
	  (push (cons symb 1) (gethash prev *words*))
	  (incf (cdr pair))))
    (setf prev symb)))

Figure 8.2: Reading sample text.


(defun generate-text (n &optional (prev '|.|))
  (if (zerop n)
      (terpri)
      (let ((next (random-next prev)))
	(format t "~A " next)
	(generate-text (1- n) next))))

(defun random-next (prev)
  (let* ((choices (gethash prev *words*))
	 (i (random (reduce #'+ choices :key #'cdr ))))
    (dolist (pair choices)
      (if (minusp (decf i (cdr pair)))
	  (return (car pair))))))

figure 8.3: Generating text.

To get a new word, g e n e r a t e - t e x t calls random-next with
the previous word. This function makes a random choice among the words
that followed prev in the input text, weighted according to the
frequency of each.0

At this point it would be time to give the program a test run. But in
fact you have already seen an example of what it produces: the stanza
at the beginning of this book, which was generated by using Milton's
Paradise Lost as the input text.0



Summary

1. Any string can be the name of a symbol, but symbols created by read
are transformed into uppercase by default.


2. Symbols have associated property lists, which behave like
assoc-lists, though they don't have the same form.


3. Symbols are substantial objects, more like structures than mere
names.


4. Packages map strings to symbols. To create an entry for a symbol in
a package is to intern it. Symbols do not have to be interned.


5. Packages enforce modularity by restricting which names you can
refer to. By default your programs will be in the user package, but
larger programs are often divided into several packages defined for
that purpose.




142

SYMBOLS


6. Symbols can be made accessible in other packages. Keywords are
self-evaluating and accessible in any package.


7. When a program operates on words, it's convenient to represent the
words as symbols.



Exercises

1. Is it possible for two symbols to have the same name but not be
eql?

2. Estimate the difference between the amount of memory used to
represent the string "F00" and the amount used to represent the symbol
foo.

3. The call to defpackage on page 137 used only strings as
arguments. We could have used symbols instead. Why might this have
been dangerous?

4. Add the code necessary to make the code in Figure 7.1 be in a
package named "RING", and that in Figure 7.2 be in a package named
"FILE". The existing code should remain unchanged.

5. Write a program that can verify whether or not a quote was produced
by Henley (Section 8.8).

6. Write a version of Henley that can take a word and generate a sentence with that word in the middle of it.



@node Numbers
@chapter Numbers


Number-crunching is one of Common Lisp's strengths. It has a rich set
of numeric types, and its features for manipulating numbers compare
favorably with any language.

@menu 
* Number Types::
* Conversion and Extraction::
* Comparison::
* Arithmetic::
* Exponentiation::
* Trigonometric Functions::
* Representation::
* Example-- Ray-Tracing::
@end menu

@node Number Types
@section Number Types


Common Lisp provides four distinct types of numbers: integers,
floatingpoint numbers, ratios, and complex numbers. Most of the
functions described in this chapter work on numbers of any type. A
few, explicitly noted, accept all but complex numbers.

An integer is written as a string of digits: 2001. A floating-point
number can be written as a string of digits containing a decimal
point, 253.72, or in scientific notation, 2.5372e2. A ratio is written
as a fraction of integers: 2/3. And the complex number a+bi is written
as #c (a b), where a and b are any two real numbers of the same type.

The predicates integerp, f l o a t p , and complexp return true for
numbers of the corresponding types. Figure 9.1 shows the hierarchy of
numeric types.

Here are some general rules of thumb for determining what kind of
number a computation will return:

1. If a numeric function receives one or more floating-point numbers as arguments, the return value will be a floating-point number (or a complex number with floating-point components). So (+ 1.0 2) evaluates to 3.0, and (+ #c(0 1.0) 2) evaluates to # c ( 2 . 0 1.0).

143

144

NUMBERS

^ <CT ^

ratio integer ^ <^ ^^ bignum fixnum bit

/

"
y \ float y/^ 4 \^-- \

/"A
number / \ complex

short-float single-float double-float long-float

Figure 9.1: Numeric types.









2. Ratios that divide evenly will be converted into integers. So (/ 10 2) will return 5.



3. Complex numbers whose imaginary part would be zero will be
converted into reals. So (+ # c ( l -1) #c(2 1)) evaluates to 3.

Rules 2 and 3 apply to arguments as soon as they are read, so: > ( LIST ( r a t i o p 2/2) (complexp # c ( l 0 ))) (NIL NIL)

@node Conversion and Extraction
@section Conversion and Extraction



Lisp provides functions for converting, and extracting components of,
the four kinds of numbers. The function f l o a t converts any real
number to a floating-point number:

> (mapcar # ' f l o a t ' ( 1 2/3 .5)) (1.0 0.6666667 0.5)

Reducing numbers to integers is not necessarily conversion, because it
can involve some loss of information. The function t r u n c a t e
returns the integer component of any real number:

> (truncate 1.3) 1 0.29999995

9.2

CONVERSION AND EXTRACTION

145

The second return value is the original argument minus thefirstreturn
value. (The difference of .00000005 is due to the inherent
inexactitude of floatingpoint computation.)

The functions floor, c e i l i n g , and round also derive integers
from their arguments. Using floor, which returns the greatest integer
less than or equal to its argument, and c e i l i n g , which returns
the least integer greater than or equal to its argument, we can
generalize mirror? (page 46) to recognize all palindromes:



(defun palindrome? (x) (let ((mid (/ (length x) 2))) (equal (subseq x
  0 (floor mid)) (reverse (subseq x (ceiling mid))))))

Like truncate, floor and c e i l i n g also return as a second value
the difference between the argument and the first return value:


> (floor 1.5) 1 0.5

In fact, we could think of truncate as being defined:


(defun our-truncate (n) (if (> n 0) (floor n) (ceiling n)))



The function round returns the nearest integer to its argument. When
the argument is equidistant from two integers, Common Lisp, like many
programming languages, does not round up. Instead it rounds to the
nearest even digit:

> (mapcar #'round ' ( - 2 . 5 - 1 . 5 1.5 2 . 5 )) (-2 -2 2 2)

In some numerical applications this is a good thing, because rounding
errors tend to cancel one another out. However, if end-users are
expecting your program to round certain values up, you must provide
for this yourself.1 Like its cousins, round returns as its second
value the difference between the argument and the first return value.

The function mod returns just the second value that f l o o r would
return; and rem returns just the second value that truncate would
return. We used



When format rounds for display, it doesn't even guarantee to round to
an even or odd digit. See page 125.  1



146

NUMBERS



mod on page 94 to determine if one number was divisible by another,
and on page 127 to find the actual position of an element in a ring
buffer.

For reals, the function signum returns either 1, 0, or - 1 , depending
on whether its argument is positive, zero, or negative. The function
abs returns the absolute value of its argument. Thus (* (abs x)
(signum x)) =x.

> (mapcar #'signum ; ( - 2 - 0 . 0 0.0 0 .5 3)) (-1 - 0 . 0 0.0 0 1.0 1)

In some implementations - 0 . 0 may exist in its own right, as
above. Functionally it makes little difference whether it does or not,
because in numeric code - 0 . 0 behaves exactly like 0.0.

Ratios and complex numbers are conceptually two-part structures. The
functions numerator and denominator return the corresponding
components of a ratio or integer. (If the number is an integer, the
former returns the number itself and the latter returns 1.) The
functions r e a l p a r t and imagpart return the real and imaginary
components of any number. (If the number isn't complex, the former
returns the number itself and the latter returns zero.)

The function random takes an integer or floating-point number. An
expression of the form (random n) returns a number greater than or
equal to zero and less than n, and of the same type as n.

@node Comparison
@section Comparison


The predicate = returns true when its arguments are numerically
equal--when the difference between them is zero.

> (= 1 1.0) T > (eql 1 1.0) NIL

It is less strict than eql, which also requires its arguments to be of
the same type.

The predicates for comparing numbers are < (less than) , <= (less than
or equal), = (equal), >= (greater than or equal), > (greater than),
and /= (different). All of them take one or more arguments. With one
argument they all return t. For all except /=, a call with three or
more arguments,


(<= w x y z)

is equivalent to the conjunction of a binary operator applied to
successive pairs of arguments:



9.4

ARITHMETIC

147





(and (<= w x) (<= x y) (<= y z ))

Since /= returns true if no two of its arguments are =, the expression

(/= w x y z)

is equivalent to

(and (/= w x) (/= w y) (/= w z) (/= x y) (/= x z) (/= y z ))

The specialized predicates zerop, plusp, and minusp take one argument
and return true if it is =, >, and < zero, respectively. These
functions do not overlap. Although - 0 . 0 (if an implementation uses
it) is preceded by a negative sign, it is = to 0,

> ( LIST (minusp - 0 . 0 ) (zerop - 0 . 0 )) (NIL T)

and therefore zerop, not minusp.

The predicates oddp and evenp apply only to integers. The former is
true only of odd integers, and the latter only of even ones.

Of the predicates described in this section, only =, /=, and zerop
apply to complex numbers.

The functions max and min return, respectively, the maximum and
minimum of their arguments. Both require at least one:

> ( LIST (max 1 2 3 4 5) (min (5 1) 12345))

If the arguments to either include floating-point numbers, the type of
the result is implementation-dependent.

@node Arithmetic
@section Arithmetic


The functions for addition and subtraction are + and -. Both can take
any number of arguments, including none, in which case they return
0. An expression of the form (- n) returns -- n. An expression of the
form

(- x y z) is equivalent to
(- (- x y) z)

148

NUMBERS







There are also two functions 1+ and 1-, which return their argument
plus 1 and minus 1 respectively. The name 1- is a bit misleading,
because ( 1 - x) returns x - 1, not 1 - x.

The macros incf and decf increment and decrement their argument,
respectively. An expression of the form (incf x ri) is similar in
effect to ( s e t f x (+ x ri)), and (decf x ri) to ( s e t f x (- x
ri)). In both cases the second argument is optional and defaults to 1.

The function for multiplication is *. It takes any number of
arguments. When given no arguments it returns 1. Otherwise it returns
the product of its arguments.

The division function, /, expects at least one argument. A call of the
form (/ ri) is equivalent to (/ 1 ri),

> (/ 3) 1/3 while a call of the form

(/ x y z)

is equivalent to

(/ (/ x y) z)

Notice the similarity between - and / in this respect. When given two
integers, / will return a ratio if the first is not a multiple of the
second:

> (/ 365 12) 365/12

If what you're trying to do is find out how long an average month is,
for example, this may give the impression that the toplevel is playing
games with you. In such cases, what you really need is to call f l o a
t on a ratio, not / on two integers:

> (float 365/12) 30.416666

@node Exponentiation
@section Exponentiation


To find.*\" we call (expt x ri), > (expt 2 5) 32

9.7

TRIGONOMETRIC FUNCTIONS

149



and to find logrt\;t we call (log x n): > (log 32 2) 5.0 This will
ordinarily return a floating-point number. To find e* there is a
distinct function exp, > (exp 2) 7.389056 and to find a natural
logarithm you can just use log, because the second argument defaults
to e: > (log 7.389056) 2.0 To find roots you can call expt with a
ratio as the second argument, > (expt 27 1/3) 3.0 but for finding
square roots the function s q r t should be faster: > ( s q r t 4) 2.0

@node Trigonometric Functions
@section Trigonometric Functions


The constant p i is a floating-point representation of IT. Its
precision is implementation-dependent. The functions sin, cos, and t a
n find the sine, cosine, and tangent, respectively, of angles
expressed in radians:

> (let ((x (/ p i 4 ))) ( LIST ( s i n x) (cos x) ( t a n x )))
  (0.7071067811865475d0 0.7071067811865476d0 l.OdO)

These functions all take negative and complex arguments.



The functions as in, acos, and a t an implement the inverse of sine,
cosine, and tangent. For arguments between --1 and 1 inclusive, as i n
and acos return real numbers.

Hyperbolic sine, cosine, and tangent are implemented by sinh, cosh,
and tanh, respectively. Their inverses are likewise asinh, acosh, and
atanh.



150

NUMBERS

@node Representation
@section Representation


Common Lisp imposes no limit on the size of integers. Small integers fit in one word of memory and are calledJbcnums. When a computation produces an integer too large to fit in one memory word, Lisp switches to a representation (a bignum) that uses multiple words of memory. So the effective limit on the size of an integer is imposed by physical memory, not by the language. The constants m o s t - p o s i t i v e - f ixnum and most-negative-f ixmim indicate the largest magnitudes an implementation can represent without having to use bignums. In many implementations they are:
> (values most-positive-fixnum most-negative-fixnum) 536870911 -536870912

The predicate typep takes an argument and a type name and returns true if the argument is of the specified type. So, > (typep 1 'fixnum) T > (typep (1+ most-positive-fixnum) T

'bignum)

The limits on the values of floating-point numbers are implementationdependent. Common Lisp provides for up to four types offloating-pointnumbers: s h o r t - f l o a t , s i n g l e - f l o a t , d o u b l e - f l o a t , and l o n g - f l o a t . Implementations are not required to use distinct formats for all four types (and few do). The general idea is that a short float is supposed to fit in a single word, that single and double floats are supposed to provide the usual idea of singleand double-precision floating-point numbers, and that long floats can be something really big, if desired. But an implementation could perfectly well implement all four the same way. You can specify what format you want a floating-point number to be by substituting the letters s, f, d, or 1 for the e when a number is represented in scientific notation. (You can use uppercase too, and this is a good idea for long floats, because 1 looks so much like 1.) So to make the largest representation of 1.0 you would write 1L0. Sixteen global constants mark the limits of each format in a given implementation. Their names are of the form m-s-f, where m is most or l e a s t , s is p o s i t i v e or negative, and/is one of the four types of float.0 Floating-point underflow and overflow are signalled as errors by Common Lisp:


> ( * most-positive-long-float 10) Error: floating-point-overflow.

9.8

EXAMPLE: RAY-TRACING

151


@node Example-- Ray-Tracing
@section Example: Ray-Tracing




As an example of a mostly numerical application, this section shows how to write a ray-tracer. Ray-tracing is the rendering algorithm deluxe: it yields the most realistic images, but takes the most time. To generate a 3D image, we need to define at least four things: an eye, one or more light sources, a simulated world consisting of one or more surfaces, and a plane (the image plane) that serves as a window onto this world. The image we generate is the projection of the world onto a region of the image plane. What makes ray-tracing unusual is the way we find this projection: we go pixel-by-pixel along the image plane, tracing the light back into the simulated World. This approach brings three main advantages: it makes it easy to get real-world optical effects like transparency, reflected light, and cast shadows; it allows us to define the simulated world directly in terms of whatever geometric objects we want, instead of having to construct them out of polygons; and it is straightforward to implement. Figure 9.2 contains some math utilities we are going to need in our raytracer. The first, sq, just returns the square of its argument. The next, mag, returns the length of a vector given its x, y, and z components. This function is used in the next two. We use it in u n i t - v e c t o r , which returns three values representing the components of a unit vector with the same direction as the vector whose components are x, y, and z: > ( m u l t i p l e - v a l u e - c a l l #'mag ( u n i t - v e c t o r 23 12 47)) 1.0 And we use mag in d i s t a n c e , which returns the distance between two points in 3-space. (Defining the point structure to have a : cone-name of NIL means that the access functions for the fields will have the same names as the fields: x instead of p o i n t - x , for example.) Finally, minroot takes three reals a, b, and c, and returns the smallest real x for which ax2 H- b;t + c = 0. When a is nonzero, the roots of this equation are yielded by the familiar formula:

x=

- b ± \/b 2 - 4ac

£

Figure 9.3 contains code defining a minimal ray-tracer. It generates black and white images illuminated by a single light source, at the same position as the eye. (The results thus tend to look like flash photographs.) The surface structure will be used to represent the objects in the simulated world. More precisely, it will be included in the structures defined to represent specific kinds of objects, like spheres. The surface structure itself contains only a single field: a color ranging from 0 (black) to 1 (white).

152

NUMBERS



(defun sq (x) (* x x)) (defun mag (x y z) (sqrt (+ (sq x) (sq y) (sq z )))) (defun unit-vector (x y z) (let ((d (mag x y z ))) (values (/ x d) (/ y d) (/ z d )))) (defstruct (point (:cone-name NIL )) x y z) (defun distance (mag (- (x pi) (- (y p i ) (- (z p i ) (pi (x (y (z p2) p2)) p2)) p2))))















(defun minroot (a b c) ( i f (zerop a) (/ (- c) b) i (let ( ( d i s c (- (sq b) (* 4 a c )))) (unless (minusp disc) (let ( ( d i s c r t (sqrt d i s c ))) (min (/ (+ (- b) d i s c r t ) (* 2 a)) (/ (- (- b) d i s c r t ) (* 2 a )))))))) Figure 9.2: Math utilities.

The image plane will be the plane defined by the x- and y-axes. The eye will be on the z-axis, 200 units from the origin. So to be visible through the image plane, the surfaces that get inserted into * world* (initially NIL ) will have to have negative z coordinates. Figure 9.4 illustrates a ray passing through a point on the image plane and hitting a sphere. The function tracer takes a pathname and writes an image to the corresponding file. Image files will be written in a simple ASCII format called G Mfileswill PGM. By default, images will be 100 x 100. The header in our P consist of the tag P2, followed by integers indicating the breadth (100) and height (100) of the image in pixels, and the highest possible value (255). The remainder of the file will consist of 10,000 integers between 0 (black) and 255 (white), representing 100 horizontal stripes of 100 pixels.

9.8

EXAMPLE: RAY-TRACING

153

(defstruct surface color)

(defparameter *world* nil)

(defconstant eye (make-point :x 0 :y 0 :z 200))









(defun tracer (pathname feoptional (res 1)) (with-open-file (p pathname :direction :output) (format p "P2 ~A ~A 255" ( * res 100) ( * res 100)) (let ((inc ( / res))) (do ((y -50 (+ y inc))) ((< - 50 y) inc)) (do ((x -50 (+ x inc))) ((< ( - 50 x) inc)) (print (color-at x y) p)))))









(defun color-at (x y) (multiple-value-bind (xr yr zr) (unit-vector ( - x (x eye)) ( - y (y eye)) ( - 0 (z eye))) (round ( * (sendray eye xr yr zr) 255))))



(defun sendray (pt xr yr zr) (multiple-value-bind (s int) (first-hit pt xr yr zr) (if s ( * (lambert s int xr yr zr) (surface-color s)) 0)))

(defun first-hit (pt xr yr zr) (let (surface hit dist) (dolist (s *world*) (let ((h (intersect s pt xr yr zr))) (when h (let ((d (distance h pt))) (when (or (null dist) (< d dist)) (setf surface s hit h dist d)))))) (values surface hit)))







(defun lambert (s int xr yr zr) (multiple-value-bind (xn yn zn) (normal s int) (max 0 (+ ( * xr xn) ( * yr yn) ( * zr zn)))))


Figure 9.3: Ray-tracing.

154

NUMBERS

V
J ^ \ --·*·*"

point of view

IK
image planeM K

c
x

)
z

t

Figure 9.4: Ray-tracing.

The resolution of the image can be adjusted by giving an explicit r e s . If r e s is 2, for example, then the same image will be rendered with 200x200 pixels. The image is a 100 x 100 square on the image plane. Each pixel represents the amount of light that passes through the image plane at that point on the way to the eye. To find the amount of light at each pixel, t r a c e r calls c o l o r - a t . This function finds the vector from the eye to that point, then calls sendray to trace the course of this vector back into the simulated world; sendray will return an intensity value between 0 and 1, which is then scaled to an integer between 0 and 255 for display. To determine the intensity of a ray, sendray has to find the object that it was reflected from. To do this it calls f i r s t - h i t , which considers all the surfaces in *world*, and returns the surface (if any) that the ray hits first. If the ray doesn't hit anything, sendray just returns the background color, which by convention is 0 (black). If the ray does hit something, we have to find out the amount of light shining on the surface at the point where the ray hits it. Lambert's law says that the intensity of light reflected by a point on a surface is proportional to the dot-product of the unit normal vector N at that point (the vector of length 1 that is perpendicular to the surface there), and the unit vector L from the point to the light source: i= NL

If the light is shining right at the point, N and L will be coincident, and the dot-product will be 1, the maximum value. If the surface is turned 90° to the light at that point, then N and L will be perpendicular, and their dot-product will be 0. If the light is behind the surface, the dot-product will be negative. In our program, we are assuming that the light source is at the eye, so lambert, which uses this rule to find the illumination at some point on a surface, returns the dot-product of the normal with the ray we were tracing.

9.8

EXAMPLE: RAY-TRACING

155

In sendray this value is multiplied by the color of the surface (a dark surface is dark even when well-illuminated) to determine the overall intensity at that point. For simplicity, we will have only one kind of object in our simulated world, spheres. Figure 9.5 contains the code involving spheres. The sphere structure includes surface, so a sphere will have a color as well as a center and r a d i u s . Calling defsphere adds a new one to the world. The function i n t e r s e c t considers the type of surface involved and calls the corresponding intersect function. At the moment there is only one, s p h e r e - i n t e r s e c t , but i n t e r s e c t is written so that it can easily be extended to deal with other kinds of objects. How do we find the intersection of a ray with a sphere? The ray is represented as a point/? = xo,y0,Zo), and a unit yector v = (xr, yn zr). Every point on the ray can be expressed as p + nv, for some n--that is, as (*o -I- nxn y0 + nyr, zo + nzr)- Where the ray hits the sphere, the distance from that point to the center (JCC, yc, zc) will be equal to the sphere's radius r. So at the intersection the following equation will hold: r = yj(x0 + nxr- xc)

 + (y0 + nyr - yc)2 -f (zo + nzr - Zc)2 This yields an2 + bn + c = 0 where
2 2 2

a = xr + yr + zr b = 2((xo - *c)xr + (y0 - yc)yr + (zo ~ zc)zr) c=(x0xc)2 + (y0 - ycf + (z0 - zcf - r1

To find the intersection we just find the roots of this quadratic equation. It might have zero, one, or two real roots. No roots means that the ray misses the sphere; one root means that it intersects the sphere at one point (a grazing hit); and two roots means that it intersects the sphere at two points (in one side and out the other). In the latter case, we want the smaller of the two roots; n increases as the ray travels away from the eye, so the first hit is the smaller n. Hence the call to minroot. If there is a root, s p h e r e - i n t e r s e c t returns the point representing (XQ + nxr, y0 -f nyn zo 4- nzr). The other two functions in Figure 9.5, normal and sphere-normal, are analogous to i n t e r s e c t and s p h e r e - i n t e r s e c t . Finding the normal to a sphere is easy--it's just the vector from the point to the center of the sphere. Figure 9.6 shows how we would generate an image; r a y - t e s t defines 38 spheres (not all of which will be visible) and then generates an image

156

NUMBERS

(defstruct (sphere (:include surface)) radius center)

(defun defsphere (x y z r c) (let ((s (make-sphere :radius r reenter (make-point :x x :y y :z z) :color c))) (push s *world*) s))

(defun intersect (s pt xr yr zr) (funcall (typecase s (sphere #'sphere-intersect)) s pt xr yr zr))





























(defun sphere-intersect (s pt xr yr zr) (let* ((c (sphere-center s)) (n (minroot (+ (sq xr) (sq yr) (sq zr)) ( * 2 (+ ( * ( - (x pt) (x c)) xr) ( * ( - (y pt) (y c)) yr) ( * ( - (z pt) (z c)) zr))) (+ (sq ( - (x pt) (x c))) (sq ( - (y pt) (y c))) (sq ( - (z pt) (z c))) ( - (sq (sphere-radius s))))))) (if n (make-point :x (+ (x pt) ( * n xr)) :y (+ (y pt) ( * n yr)) :z (+ (z pt) ( * n zr))))))

(defun normal (s pt) (funcall (typecase s (sphere #'sphere-normal)) s pt))







(defun sphere-normal (s pt) (let ((c (sphere-center s))) (unit-vector ( - (x c) (x pt)) ( - (y c) (y pt)) ( - (z c) (z pt)))))


Figure 9.5: Spheres.

9.8

EXAMPLE: RAY-TRACING

157



(defun ray-test (feoptional (res D) (setf *world* nil) (defsphere 0 -300 -1200 200 . 8) (defsphere -80 -150 -1200 20C .7) (defsphere 70 -100 -1200 200 .9) (do ((x -2 (1+ x))) ((> x 2)) (do ((z 2 (1+ z))) ((> z 7)) (defsphere (* x 200) 300 ( * z -400) 40 .75))) (tracer (make-pathname :name "spheres.pgm") res)) Figure 9.6: Using the ray-tracer.

Figure 9.7: Ray-traced image. file called "spheres .pgm". Figure 9.7 shows the resulting image, generated with a r e s of 10. A real ray-tracer could generate much more sophisticated images, because it would consider more than just the contribution of a single light source to a

158

NUMBERS

point on a surface. There might be multiple light sources, each of different intensities. They would not ordinarily be at the eye, in which case the program would have to check to see whether the vector to a light source intersected another surface, which would then be casting its shadow onto the first. Putting the light source at the eye saves us from having to consider this complication, because we can't see any of the points that are in shadow. A real ray-tracer would also follow the ray beyond the first surface it hit, adding in some amount of light reflected by other surfaces. It would do color, of course, and would also be able to model surfaces that were transparent or shiny. But the basic algorithm would remain much as shown in Figure 9.3, and many of the refinements would just involve recursive uses of the same ingredients. A real ray-tracer would probably also be highly optimized. The program given here is written for brevity, and is not even optimized as a Lisp program, let alone as a ray-tracer. Merely adding type and inline declarations (Section 13.3) could make it more than twice as fast.

Summary
1. Common Lisp provides integers, ratios, floating-point numbers, and complex numbers.
2. Numbers can be simplified and converted, and their components can be extracted.
3. Predicates for comparing numbers take any number of arguments, and compare successive pairs--except /=, which compares all pairs.
4. Common Lisp provides roughly the numerical functions you might see on a low-end scientific calculator. The same functions generally apply to numbers of several types.
5. Fixnums are integers small enough to fit in one word. They are quietly but expensively converted to bignums when necessary. Common Lisp provides for up to four types of floating-point number. The limits of each representation are implementation-dependent constants.
6. A ray-tracer generates an image by tracing the light that makes each pixel back into a simulated world.

Exercises

1. Define a function that takes a list of reals and returns true iff they are in nondecreasing order.

9.8

EXERCISES

159

2. Define a function that takes an integer number of cents and returns four values showing how to make that number out of 25-, 10-, 5- and 1-cent pieces, using the smallest total number of coins. 3. A faraway planet is inhabited by two kinds of beings, wigglies and wobblies. Wigglies and wobblies are equally good at singing. Every year there is a great competition to chooses the ten best singers. Here are the results for the past ten years:
YEAR WIGGLIES WOBBLIES

1 6 4

2 5 5

3 6 4

4 4 6

5 5 5

6 5 5

7 4 6

8 5 5

9 6 4

10 5 5

Write a program to simulate such a contest. Do your results suggest that the committee is, in fact, choosing the ten best singers each year? 4. Define a function that takes 8 reals representing the endpoints of two segments in 2-space, and returns either NIL if the segments do not intersect, or two values representing the x- and y-coordinates of the intersection if they do. 5. Suppose f is a function of one (real) argument, and that min and max are nonzero reals with different signs such that f has a root (returns zero) for one argument / such that min < i < max. Define a function that takes four arguments, f, min, max, and epsilon, and returns an approximation of / accurate to within plus or minus e p s i l o n . 6. Horner's method is a trick for evaluating polynomials efficiently. To frndax3*+BX2+cx+dyou evaluate x(x(ax+b)+c)+d. Define a function that takes one or more arguments--the value of x followed by n reals representing the coefficients of an (n - l)th-degree polynomial--and calculates the value of the polynomial by Horner's method. 7. How many bits would you estimate your implementation uses to represent fixnums? 8. How many distinct types of float does your implementation provide?



@node Macros
@chapter Macros


Lisp code is expressed as lists, which are Lisp objects. Section 2.3
claimed that this made it possible to write programs that would write
programs. This chapter shows how to cross the line from expressions to
code.

@menu 
* Eval::
* Defining Macros::
* Backquote::
* Example-- Quicksort::
* Macro Design::
* Generalized Reference::
* Example-- Macro Utilities::
* On Lisp::
@end menu

@node Eval
@section Eval



It's obvious how to generate expressions: just call LIST . What we
haven't considered is how to make Lisp treat them as code. The missing
link is the function eval, which takes an expression, evaluates it,
and returns its value:

> (eval ' ( + 1 2 3))
6
> (eval '(format t "Hello"))
Hello NIL

If this looks familiar, it should. It's eval we have been talking to
all this time. The following function implements something very like
the toplevel:
(defun our-toplevel () (do () (nil) (format t "~%> ") (print (eval (read)))))

For this reason the toplevel is also known as a read-eval-print loop. 160

10.1

EVAL

161

Calling eval is one way to cross the line between lists and code. However, it is not a very good way:

1. It's inefficient: eval is handed a raw list, and either has to compile it on the spot, or evaluate it in an interpreter. Either way is much slower than running compiled code.

2. The expression is evaluated with no lexical context. If you call eval within a l e t , for example, the expressions passed to eval cannot refer to variables established by the l e t . There are much better ways (described in the next section) to take advantage of the possibility of generating code. Indeed, one of the only places where it is legitimate to use eval is in something like a toplevel loop. For programmers the main value of eval is probably as a conceptual model for Lisp. We can imagine it defined as a big cond expression:

(defun eval (expr env) (cond ... ((eql (car expr) 'quote) (cadr expr)) (t (apply (symbol-function (car expr)) (mapcar #'(lambda (x) (eval x env)) (cdr expr))))))

Most expressions are handled by the default clause, which says to get the function referred to in the car, evaluate all the arguments in the cdr, and return the result of applying the former to the latter.1 However, we can't do this for an expression like (quote x), since the whole point of quote is to preserve its argument from evaluation. So we have to have a distinct clause just for quote. That's what a special operator is, essentially: an operator that has to be implemented as a special case in eval. The functions coerce and compile provide a similar bridge from lists to code. You can coerce a lambda expression into a function, > (coerce '(lambda (x) x) ' f u n c t i o n ) #<Interpreted-Function BF9D96> and if you give NIL as the first argument to compile, it will compile a lambda expression given as the second argument.
'To really duplicate Lisp, eval would have to take a second argument (here env) to represent the lexical environment. This model of eval is inaccurate in that it retrieves the function before evaluating the arguments, whereas in Common Lisp the order of these two operations is deliberately unspecified.

162

MACROS

> (compile nil '(lambda (x) (+ x 2))) #<Compiled-Function BF55BE> NIL NIL Since coerce and compile can take lists as arguments, a program could build new functions on the fly. However, this is a drastic measure, comparable to calling eval, and should be viewed with the same suspicion. The trouble with eval, coerce, and compile is not that they cross the line between lists and code, but that they do it at run-time. Crossing the line is expensive. Doing it at compile-time is good enough in most cases, and costs nothing when your program runs. The next section shows how to do this.

@node Defining Macros
@section Defining Macros 

The most common way to write programs that write programs is by defining macros. Macros are operators that are implemented by transformation. You define a macro by saying how a call to it should be translated. This translation, called macro-expansion, is done automatically by the compiler. So the code generated by your macros becomes an integral part of your program, just as if you had typed it in yourself. Macros are usually defined by calling defmacro. A defmacro looks a lot like a def un, but instead of defining the value a call should produce, it defines how a call should be translated. For example, a macro to set its argument to NIL might be defined as follows:





(defmacro nil! (x) (list 'setf x nil))













 This defines a new operator called NIL ! , which will take one argument. A call of the form ( NIL ! a) will be translated into ( s e t f a NIL ) before being compiled or evaluated. So if we type ( NIL ! x) into the toplevel, > ( NIL ! x) NIL > x NIL it is exactly equivalent to typing the expansion, ( s e t f x NIL ) . To test a function, we call it, but to test a macro, we look at its expansion. The function macroexpand-1 takes a macro call and generates its expansion: > (macroexpand-1 '(nil! x)) (SETF X NIL) T


10.3

BACKQUOTE

163



A macro call can expand into another macro call. When the compiler (or the toplevel) encounters a macro call, it simply keeps expanding it until it is no longer one. The secret to understanding macros is to understand how they are implemented. Underneath, they're just functions that transform expressions. For example, if you pass an expression of the form ( NIL ! a) to this function



(lambda (expr) (apply #'(lambda (x) ( LIST ' s e t f x NIL )) (cdr e x p r )))



it will return ( s e t f a NIL ) . When you use defmacro, you're defining a function much like this one. All macroexpand-1 does, when it sees an expression whose car is known to be the name of a macro, is pass the expression to the corresponding function.

@node Backquote
@section Backquote









The backquote read-macro makes it possible to build lists from templates. Backquote is used extensively in macro definitions. While a regular quote is a close-quote (apostrophe) on the keyboard, a backquote is an open-quote. It's called "backquote" because it looks like a normal quote tilted backwards. Used by itself, a backquote is equivalent to a regular quote: > ' ( a b c) (A B C) Like a regular quote, a backquote alone protects its argument from evaluation. The advantage of backquote is that, within a backquoted expression, you can use , (comma) and , @ (comma-at) to turn evaluation back on. If you prefix a comma to something within a backquoted expression, it will be evaluated. Thus we can use backquote and comma together to build list templates: > ( s e t f a 1 b 2) 2 > ( ( a i s ,a and b i s ,b) (A IS 1 AND B IS 2) By using backquote instead of a call to LIST , we can write macro definitions that look like the expansions they will produce. For example, NIL ! could be defined as:







(defmacro NIL ! (x) ' ( s e t f ,x NIL ))



164

MACROS







Comma-at is like comma, but splices its argument (which should be a
list). Instead of the list itself, its elements are inserted in the
template: 
> ( s e t f lst ' ( a b c))
 (A B C) 

> '(lst is ,lst)
 (LST IS ( A B C ))

 > '(its elements are ,\Comma-at lst)
 (ITS ELEMENTS ARE A B C ) Comma-at is useful in macros that have rest parameters representing, for example, a body of code. Suppose we want a while macro that will evaluate its body so long as an initial test expression remains true:

> (let ((x 0)) (while (< x 10) (princ x) (incf x)))
0123456789
NIL

 We can define such a macro by using a rest parameter to collect a list of the expressions in the body, then using comma-at to splice this list into the expansion:







(defmacro while ( t e s t ferest body) ' ( d o () ((not , t e s t )) ,Obody))

@node Example-- Quicksort
@section Example-- Quicksort 

Figure 10.1 contains an example of a function that relies heavily on macros--a function to sort vectors using the Quicksort algorithm.0 The algorithm works as follows: 1. You begin by choosing some element as the pivot. Many implementations choose an element in the middle of the sequence to be sorted. 2. Then you partition the vector, swapping elements until all the elements less than the pivot are to the left of all those greater than or equal to the pivot.

70.5

MACRO DESIGN

165

(defun quicksort (vec 1 r)
  (let ((i 1)
	(j r)
	(p (svref vec (round (+ 1 r) 2)))) ; 1
    (while (<= i j) ; 2
	   (while (< (svref vec i) p) (incf i))
	   (while (> (svref vec j) p) (decf j))
	   (when (<= i j) (rotatef (svref vec i) (svref vec j))
		 (incf i) (decf j)))


    (if (> ( - j 1) 1) (quicksort vec 1 j)) ; 3


    (if (> ( - r i) 1) (quicksort vec i r)))
  vec)

Figure 10.1: Quicksort.

3. Finally, if either of the partitions has two or more elements, you apply the algorithm recursively to those segments of the vector. With each recursion the partitions get smaller, till finally the vector is completely sorted. The implementation in Figure 10.1 takes a vector and two integers that mark the range to be sorted. The element currently in the middle of this range is chosen as the pivot (p). Then the partition is done by working inward from either end of the range, and swapping elements that are either too big to be on the left side or too small to be on the right. (Giving two arguments to r o t a t e f swaps their values.) Finally, if either partition contains multiple elements, they are sorted by the same process. As well as the while macro we defined in the previous section, the implementation in Figure 10.1 uses the built-in when, incf, decf, and r o t a t e f macros. Using these macros makes the code substantially shorter and clearer.

@node Macro Design
@section Macro Design 

Writing macros is a distinct kind of programming, with its own unique aims and problems. Being able to change what the compiler sees is almost like being able to rewrite it. So when you start writing macros, you have to start thinking like a language designer. This section gives a quick overview of the problems involved, and the techniques used to solve them. As an example, we will define a macro called

166

MACROS

ntimes, which takes a number n and evaluates its body n times:

> (ntimes 10 (princ "."))

NIL

Here is an incorrect definition of ntimes that illustrates some issues in macro design:



(defmacro ntimes (n ferest body) <(do ((x 0 (+ x 1))) ((>= x ,n)) ,\Comma-atbody))


; wrong

This definition may look ok at first sight. In the case above it would work as intended. But in fact it is broken in two ways. One of the problems that macro designers have to think about is inadvertent variable capture. This happens when a variable used in a macro expansion happens to have the same name as a variable existing in the context where the expansion is inserted. The incorrect definition of ntimes creates a variable x. So if the macro is called in a place where there is already a variable with that name, it may not do what we expect:

> (let ((x 10)) (ntimes 5 (setf x (+ x 1))) x) 10 If ntimes did what it was supposed to, this expression should increment x five times, and finally return 15. But because the macro expansion happens to use x as its iteration variable, the s e t f expression increments the value of that x, not the one that we meant to increment. Once the macro call is expanded, the preceding expression becomes:





(let ((x 10)) (do ((x 0 (+ x 1))) ((>= x 5)) ( s e t f x (+ x 1))) x)

The most general solution is not to use ordinary symbols anywhere they might be captured. Instead we can use gensyms (Section 8.4). Because read interns every symbol it sees, there is no way a gensym could be eql to any symbol occurring in a program text. If we rewrite the definition of ntimes to use a gensym instead of x, it will at least be safe from variable capture:

10.5

MACRO DESIGN

167
; wrong



(defmacro ntimes (n &rest body) (let ((g (gensym))) '(do ((,g 0 (+ ,g 1))) ((>= ,g ,n)) ,<3body)))


However, this macro is still susceptible to another problem: multiple evaluation. Because the first argument is inserted directly into the do, it will be evaluated on each iteration. This mistake shows most clearly when the first argument is an expression with side-effects:



> (let ((v 10))


(ntimes (setf v ( - v 1)) (princ "."))) NIL

Since v is initially 10 and s e t f returns the value of its second argument, this should print nine periods. In fact it prints only five. We see why if we look at the expression with the macro call expanded:









(let ((v 10)) (do ( ( # : g l 0 (+ # : g l 1))) ((>= # : g l ( s e t f v (- v 1 )))) (princ " . " )))

On each iteration we compare the iteration variable (gensyms usually print as symbols preceded by #:) not against 9, but against an expression that decreases each time it is evaluated. It is as if the horizon gets closer each time we look at it. The way to avoid unintended multiple evaluations is to set a variable to the value of the expression in question before any iteration. This usually involves another gensym:




(defmacro ntimes (n &rest body) (let ((g (gensym)) (h (gensym))) '(let ((,h ,n)) (do ((,g 0 (+ ,g 1))) ((>= ,g ,h)) ,®body))))



Here, finally, is a correct definition of ntimes. Unintended variable capture and multiple evaluation are the major problems that can afflict macros, but they are not the only ones. With experience it

168

MACROS

is no more difficult to avoid such errors than it is to avoid more familiar errors, like dividing by zero. But because macros give us a new kind of power, the kind of problems we have to worry about are also new. Your Common Lisp implementation is a good place to learn more about macro design. By expanding calls to the built-in macros, you can usually understand how they were written. Here is the expansion most implementations will generate for a cond expression: > (pprint (macroexpand-1 '(cond (a b) (c d e) (t f)))) (IF A B (IF C (PROGN D E) F)) The function p p r i n t , which prints expressions indented like code, is especially useful when looking at macro expansions.

@node Generalized Reference
@section Generalized Reference 

Since a macro call is expanded right into the code where it appears, any macro call whose expansion could be the first argument to setf can itself be the first argument to setf. For example, if we defined a synonym for car,







(defmacro can ( lst ) ' ( c a r , lst ))








then because a call to car can be the first argument to setf, so could a call to can: > (let ((x ( LIST ' a >b >c))) ( s e t f (can x) 44) x) (44 B C) Writing a macro that expands into a s e t f is another question, and a more difficult one than it might seem at first. It might seem that you could implement incf, say, simply as



(defmacro incf (x feoptional (y 1)) ' ( s e t f ,x (+ ,x , y )))

; wrong

But this would not work. These two expressions are not equivalent:

10J

EXAMPLE: MACRO UTILITIES

169

(setf (car (push 1 lst)) (1+ (car (push 1 lst)))) (incf (car (push 1 lst)))









If lst is initially NIL , then the second expression will set it to (2), but the first expression would set it to (1 2). Common Lisp provides def ine-modif y-macro as a way of writing a restricted class of macros on setf. It takes three arguments: the name of the macro, its additional parameters (the place is implicitly the first), and the name of a function that yields the new value of the place. So we could define incf as (define-modify-macro our-incf (feoptional (y 1)) +) and a version of push for the end of a list as (define-modify-macro appendlf ( v a l ) (lambda ( lst v a l ) (append lst ( LIST v a l )))) The latter would work as follows: > (let ((lst ' ( a b c))) (appendlf lst J d) lst) (A B C D) Incidentally, neither push nor pop can be defined as modify-macros, the former because the place is not its first argument, and the latter because its return value is not the modified object.

@node Example-- Macro Utilities
@section Example-- Macro Utilities 

Section 6.4 introduced the concept of a utility, a general-purpose operator like those that make up Lisp itself. We can use macros to define utilities that could not be written as functions. We've seen several examples already: NIL ! , ntimes, and while all have to be written as macros, because all have to control the way in which their arguments are evaluated. This section gives some more examples of the kinds of utilities you can write with macros. Figure 10.2 contains a selection that have proven their worth in practice. The first, for, is similar in design to while (page 164). It is for loops whose bodies are evaluated with a new variable bound to a range of values: > (for x 1 8
(princ x)) 12345678 NIL

170

MACROS



(defmacro for (var start stop ftbody body) (let ((gstop (gensym))) '(do ((,var ,start (1+ ,var)) (,gstop ,stop)) ((> ,var ,gstop)) ,<3body)))



(defmacro in (obj ferest choices) (let ((insym (gensym))) '(let ((,insym ,obj)) (or ,\Comma-at(mapcar #'(lambda (c) '(eql ,insym ,c)) choices)))))



(defmacro random-choice (ferest exprs) '(case (random ,(length exprs)) ,\Comma-at(let ((key -1)) (mapcar #>(lambda (expr) '(,(incf key) ,expr)) exprs))))



(defmacro avg (&rest args) '(/ (+ ,<3args) ,(length args)))



(defmacro with-gensyms (syms febody body) '(let ,(mapcar #'(lambda (s) '(,s (gensym))) syms) ,©body))



(defmacro aif (test then ^optional else) '(let ((it ,test)) (if it ,then ,else)))


Figure 10.2: Macro utilities.



This is less work to write than the equivalent do, (do ((x 1 (1+ x ))) ((> x 8)) ( princx)) which is very close to the actual expansion:



10.7 (do ((x 1 (1+ x)) ( # : g l 8)) ((> x # : g l )) (princ x))

EXAMPLE: MACRO UTILITIES

171



The macro has to introduce an additional variable to hold the value that marks the end of the range. The 8 in the example above might have been a call, and we would not want to evaluate it multiple times. The additional variable has to be a gensym, in order to avoid inadvertent variable capture. The second macro in Figure 10.2, in, returns true if its first argument is eql to any of the other arguments. The expression that we can write as (in (car expr) '+ ' - '*) we would otherwise have to write as (let ((op (car (or (eql op (eql op (eql op expr))) '+) '-) '*)))







Indeed, the first expression expands into one like the second, except that the variable op is replaced by a gensym. The next example, random-choice, randomly chooses an argument to evaluate. We had to choose randomly between two alternatives on page 74. The random-choice macro implements the general solution. A call like (random-choice (turn-left) (turn-right)) gets expanded into: (case (random 2) (0 ( t u r n - l e f t )) (1 ( t u r n - r i g h t ))) The next macro, with-gensyms is intended to be used mainly within macro bodies. It's not unusual, especially in macros for specific applications, to have to gensym several variables. With this macro, instead of (let ((x (gensym)) (y (gensym)) (z (gensym))) ...) we can write (with-gensyms (x y z) ...)

172

MACROS

So far, none of the macros defined in Figure 10.2 could have been defined as functions. As a rule, the only reason to write something as a macro is because you can't write it as a function. But there are a few exceptions to this rule. Sometimes you may want to define an operator as a macro in order to make it do some of its work at compile-time. The macro avg, which returns the average of its arguments, > (avg 2 4 8) 14/3 is an example of such a macro. We could write avg as a function,

(defun avg (ferest args) (/ (apply #'+ args) (length a r g s )))



but then it would have to find the number of arguments at run-time. As long as we are willing to forgo applying avg, why not make this call to length at compile-time? The last macro in Figure 10.2 is aif, which is included as an example of intentional variable capture. It allows us to use the variable i t to refer to the value returned by the test argument in a conditional. That is, instead of (let ((val (calculate-something))) (if val (1+ v a l ) 0)) we can write (aif (calculate-something) (1+ it) 0) Used judiciously, intentional variable capture can be a valuable technique. Common Lisp itself uses it in several places: both next-method-p and c a l l - n e x t - m e t hod rely on variable capture, for example. Macros like these show clearly what it means to write programs that write your programs for you. Once you have defined for, you don't have to write out the whole do expression. Is it worth writing a macro just to save typing? Very much so. Saving typing is what programming languages are all about; the purpose of a compiler is to save you from typing your program in machine language. And macros allow you to bring to your specific applications the same kinds of advantages that high-level languages bring to programming in general. By the careful use of macros, you may be able to make your programs

ON LISP

173

significantly shorter than they would be otherwise, and proportionately easier to read, write, and maintain. If you doubt this, consider what your programs would look like if you didn't use any of the built-in macros. All the expansions those macros generate, you would have to generate by hand. You can use this question in the other direction as well. As you're writing a program, ask yourself, am I writing macroexpansions? If so, the macros that generate those expansions are the ones you need to write.


@node On Lisp
@section On Lisp
Now that macros have been introduced, we see that even more of Lisp is written in Lisp than we might have expected. Most of the Common Lisp operators that aren't functions are macros, and they are all written in Lisp. Only 25 of Common Lisp's built-in operators are special operators. John Foderaro has called Lisp "a programmable programming language."0 By writing your own functions and macros, you can turn Lisp into just about any language you want. (We'll see a graphic demonstration of this possibility in Chapter 17.) Whatever turns out to be the right form for your program, you can be assured that you will be able to shape Lisp to suit it. Macros are one of the key ingredients in this flexibility. They allow you to transform Lisp almost beyond recognition, and yet to do so in a principled, efficient way. Within the Lisp community, macros are a topic of increasing interest. It's clear already that one can do amazing things with them, but more certainly remain to be discovered. By you, if you want. Lisp has always put its evolution in the hands of the programmer. That's why it survives.

Summary
1. Calling eval is one way to make Lisp treat lists as code, but it's inefficient and unnecessary.
2. You define a macro by saying what a call should expand into. Underneath, macros are just functions that return expressions.
3. A macro body defined with backquote resembles the expansion it will produce.
4. The macro designer must be aware of variable capture and multiple evaluation. Macros can be tested by pretty-printing their expansions.
5. Multiple evaluation is a problem for most macros that expand into setfs.


174

MACROS


6. Macros are more flexible than functions, and can be used to define a broader range of utilities. You can even use variable capture to advantage.
7. Lisp has survived because it puts its evolution in the hands of the programmer. Macros are part of what makes this possible.

Exercises






1. If x is a, y is b, and z is ( c d), write backquoted expressions containing only variables that yield each of the following: (a) ((CD) A Z) (b) (X B C D) (c) ((C D A) Z) 2. Define if in terms of cond. 3. Define a macro that takes a number n followed by one or more expressions, and returns the value of the nth expression: > (let ((n 2)) (nth-expr n (/ 1 0) ( + 1 2 ) 3

(/ 1 0 )))









4. Define ntimes (page 167) to expand into a (local) recursive function instead of ado. 5. Define a macro n-of that takes a number n and an expression, and returns a list of n successive values returned by the expression: > (let ( ( i 0) (n 4)) (n-of n (incf i ))) ( 1 2 3 4) 6. Define a macro that takes a list of variables and a body of code, and ensures that the variables revert to their original values after the body of code is evaluated.

10.8

EXERCISES

175

7. What's wrong with the following definition of push?

(defmacro push (obj lst) ( (setf ,lst (cons ,obj ,lst)))



Give an example of a call where it would not do the same thing as the real push. 8. Define a macro that doubles its argument: > (let ((x 1)) (double x) x) 2



@node CLOS
@chapter CLOS



The Common Lisp Object System, or CLOS, is a set of operators for
doing object-oriented programming. Because of their common history it
is conventional to treat these operators as a group.0 Technically,
they are in no way distinguished from the rest of Common Lisp: def
method is just as much (and just as little) an integral part of the
language as defun.

@menu 
* Object-Oriented Programming::
* Classes and Instances::
* Slot Properties::
* Superclasses::
* Precedence::
* Generic Functions::
* Auxiliary Methods::
* Method Combination::
* Encapsulation::
* Two Models::
@end menu

@node Object-Oriented Programming
@section Object-Oriented Programming 

Object-oriented programming means a change in the way programs are organized. This change is analogous to the one that has taken place in the distribution of processor power. In 1970, a multi-user computer system meant one or two big mainframes connected to a large number of dumb terminals. Now it is more likely to mean a large number of workstations connected to one another by a network. The processing power of the system is now distributed among individual users instead of centralized in one big computer. Object-oriented programming breaks up traditional programs in much the same way. Instead of having a single program that operates on an inert mass of data, the data itself is told how to behave, and the program is implicit in the interactions of these new data "objects." For example, suppose we want to write a program to find the areas of two-dimensional shapes. One way to do this would be to write a single function that looked at the type of its argument and behaved accordingly, as in Figure 11.1.

176

11.1

OBJECT-ORIENTED PROGRAMMING

177

(defstruct rectangle height width) (defstruct circle radius)





(defun area (x) (cond ((rectangle-p x) ( * (rectangle-height x) (rectangle-width x))) ((circle-p x) ( * pi (expt (circle-radius x) 2)))))

> (let ((r (make-rectangle))) (setf (rectangle-height r) 2 (rectangle-width r) 3) (area r)) 6

Figure 11.1: Area with structures and a function.





Using CLOS we might write an equivalent program as in Figure 11.2. In the object-oriented model, our program gets broken up into several distinct methods, each one intended for certain kinds of arguments. The two methods in Figure 11.2 implicitly define an a r e a function that works just like the one in Figure 11.1. When we call area, Lisp looks at the type of the argument and invokes the corresponding method. Together with this way of breaking up functions into distinct methods, object-oriented programming implies inheritance--both of slots and methods. The empty list given as the second argument in the two def classes in Figure 11.2 is a list of superclasses. Suppose we define a new class of colored objects, and then a class of colored circles that has both colored and c i r c l e as superclasses: ( d e f c l a s s colored () (color)) (defclass c o l o r e d - c i r c l e ( c i r c l e colored) 0) When we make instances of c o l o r e d - c i r c l e , we will see two kinds of inheritance:

178

CLOS

















(defclass rectangle 0 (height width)) ( d e f c l a s s c i r c l e () (radius)) (defmethod a r e a ((x r e c t a n g l e )) (* ( s l o t - v a l u e x J h e i g h t ) ( s l o t - v a l u e x ' w i d t h ))) (defmethod area ((x c i r c l e )) (* p i (expt ( s l o t --value x ' r a d i u s ) 2 ))) > (let ( ( r (make-instance ' r e c t a n g l e ))) (setf (slot-value r 'height) 2 ( s l o t - v a l u e r 'width) 3) (area r )) 6 Figure 11.2 : Area with classes and methods.

1. Instances of c o l o r e d - c i r c l e will have two slots: r a d i u s , which is inherited from the c i r c l e class, and color, which is inherited from the colored class. 2. Because there is no a r e a method defined explicitly for instances of c o l o r e d - c i r c l e , if we call a r e a on an instance of c o l o r e d - c i r c l e , we will get the method defined for the c i r c l e class. In practical terms, object-oriented programming means organizing a program in terms of methods, classes, instances, and inheritance. Why would you want to organize programs this way? One of the claims of the objectoriented approach is that it makes programs easier to change. If we want to change the way objects of class ob are displayed, we just change the d i s p l a y method of the ob class. If we want to make a new class of objects like obs but different in a few respects, we can create a subclass of ob; in the subclass, we change the properties we want, and all the rest will be inherited by default from the ob class. And if we just want to make a single ob that behaves differently from the rest, we can create a new child of ob and modify the child's properties directly. If the program was written carefully to begin with, we can make all these types of modifications without even looking at the rest of the code.0

11.3

CLASSES AND INSTANCES

179

@node Classes and Instances
@section Classes and Instances 

In Section 4.6 we went through two steps to create structures: we called def s t r u c t to lay out the form of a structure, and a specific function like make-point to make them. Creating instances requires two analogous steps. First we define a class, using def c l a s s :
(defclass circle () (radius center))

This definition says that instances of the c i r c l e class will have two slots (like fields in a structure), named r a d i u s and c e n t e r respectively. To make instances of this class, instead of calling a specific function, we call the general make-instance with the class name as the first argument: > (setf c (make-instance #<Circle #XC27496> 'circle))



To set the slots in this instance, we can use s e t f with s l o t - v a l u e : > (setf ( s l o t - v a l u e c ' r a d i u s ) 1) 1 Like structure fields, the values of uninitialized slots are undefined.

@node Slot Properties
@section Slot Properties





The third argument to d e f c l a s s must be a list of slot definitions. The simplest slot definition, as in the example above, is a symbol representing its name. In the general case, a slot definition can be a list of a name followed by one or more properties. Properties are specified like keyword arguments, By defining an : accessor for a slot, we implicitly define a function that refers to the slot, making it unnecessary to call s l o t - v a l u e . If we update our definition of the c i r c l e class as follows, (defclass c i r c l e () ( ( r a d i u s :accessor c i r c l e - r a d i u s ) (center :accessor c i r c l e - c e n t e r ))) then we will be able to refer to the slots as c i r c l e - r a d i u s and c i r c l e center respectively: > (setf c (make-instance ' c i r c l e )) #<Circle #XC5C726>

180

CLOS









> (setf (circle-radius c) 1) 1 > (circle-radius c) 1 By specifying a : w r i t e r or a : r e a d e r instead of an : accessor, we could get just the first half of this behavior, or just the second. To specify a default value for a slot, we have to give an : i n i t f orm argument. If we want to be able to initialize the slot in the call to make-instance, we define a parameter name as an : i n i t a r g . 1 With both added, our class definition might become: ( d e f c l a s s c i r c l e () ( ( r a d i u s :accessor :initarg :initform ( c e n t e r :accessor :initarg :initform circle-radius :radius 1) circle-center :center (cons 0 0 ))))



Now when we make an instance of a c i r c l e we can either pass a value for a slot using the keyword parameter defined as the slot's : i n i t a r g , or let the value default to that of the slot's : i n i t f orm. > ( s e t f c (make-instance ' c i r c l e .-radius 3)) #<Circle #XC2DE0E>

> (circle-radius c) 3


> ( c i r c l e - c e n t e r c) (0 . 0) Note that : i n i t a r g s take precedence over : i n i t f orms. We can specify that some slots are to be shared--that is, their value is the same for every instance. We do this by declaring the slot to have ·.allocation : c l a s s . (The alternative is for a slot to have -.allocation : i n s t a n c e , but since this is the default there is no need to say so explicitly.) When we change the value of such a slot in one instance, that slot will get the same value in every other instance. So we would want to use shared slots to contain properties that all the instances would have in common. For example, suppose we wanted to simulate the behavior of a flock of tabloids. In our simulation we want to be able to represent the fact that when one tabloid takes up a subject, they all do. We can do this by making all the instances share a slot. If the t a b l o i d class is defined as follows,
Initarg names are usually keywords, but they don't have to be.

11.4

SUPERCLASSES

181





(defclass t a b l o i d () ( ( t o p - s t o r y .-accessor t a b l o i d - s t o r y :allocation :class))) then if we make two instances of tabloids, whatever becomes front-page news to one instantly becomes front-page news to the other:
> (setf daily-blab (make-instance 'tabloid) unsolicited-mail (make-instance 'tabloid)) #<Tabloid #XC2AB16> > (setf (tabloid-story daily-blab) 'adultery-of-senator) ADULTERY-OF-SENATOR > (tabloid-story unsolicited-mail) ADULTERY-OF-SENATOR

The : documentation property, if given, should be a string to serve as the slot's documentation. By specifying a : type, you are promising that the slot will only contain elements of that type. Type declarations are explained in Section 13.3.

@node Superclasses
@section Superclasses






The second argument to def c l a s s is a list of superclasses. A class inherits the union of the slots of its superclasses. So if we define the class s c r e e n - c i r c l e to be a subclass of both c i r c l e and graphic, (defclass graphic () ((color :accessor g r a p h i c - c o l o r :initarg ( v i s i b l e :accessor g r a p h i c - v i s i b l e : i n i t a r g :initform t ))) (defclass s c r e e n - c i r c l e ( c i r c l e graphic) :color) :visible

0)


then instances of s c r e e n - c i r c l e will have four slots, two inherited from each superclass. A class does not have to create any new slots of its own; s c r e e n - c i r c l e exists just to provide something instantiable that inherits from both c i r c l e and graphic. The accessors and initargs work for instances of s c r e e n - c i r c l e just as they would for instances of c i r c l e or graphic: > ( g r a p h i c - c o l o r (make-instance RED 'screen-circle :color ' r e d : r a d i u s 3))

182

CLOS







We can cause every s c r e e n - c i r c l e to have some default initial color by specifying an initform for this slot in the def c l a s s : ( d e f c l a s s s c r e e n - c i r c l e ( c i r c l e graphic) ((color :initform 'purple))) Now instances of s c r e e n - c i r c l e will be purple by default: > ( g r a p h i c - c o l o r (make-instance PURPLE 'screen-circle))

@node Precedence
@section Precedence





We've seen how classes can have multiple superclasses. When there are methods defined for several of the classes to which an instance belongs, Lisp needs some way to decide which one to use. The point of precedence is to ensure that this happens in an intuitive way. For every class there is a precedence list: an ordering of itself and its superclasses from most specific to least specific. In the examples so far, precedence has not been an issue, but it can become one in bigger programs. Here's a more complex class hierarchy: ( d e f c l a s s s c u l p t u r e () (height width depth)) (defclass statue (sculpture) ( d e f c l a s s metalwork () (subject))

(metal-type))





( d e f c l a s s c a s t i n g (metalwork) ( )) (defclass cast-statue (statue casting) ())



Figure 11.3 contains a network representing c a s t - s t a t u e and its superclasses. To build such a network for a class, start at the bottom with a node representing that class. Draw links upward to nodes representing each of its immediate superclasses, laid out from left to right as they appeared in the calls to d e f c l a s s . Repeat the process for each of those nodes, and so on, until you reach classes whose only immediate superclass is standard-object--that is, classes for which the second argument to d e f c l a s s was ( ) . Create links from those classes up to a node representing s t a n d a r d - o b j e c t , and one from that node up to another node representing the class t . The result will be a network that comes to a point at both top and bottom, as in Figure 11.3.

11.6

PRECEDENCE

183

^standard-objt

JL icT^
\V
(jnetalworkj)

0

i

^sculpture

y

C

^jUT
statue

J)

Q

jn"
casting

^

/if

> (^cast-statue Figure 11.3: Class hierarchy.

The precedence list for a class can be computed by traversing the corresponding network as follows: 1. Start at the bottom of the network. 2. Walk upward, always taking the leftmost unexplored branch. 3. If you are about to enter a node and you notice another path entering the same node from the right, then instead of entering the node, retrace your steps until you get to a node with an unexplored path leading upward. Go back to step 2. 4. When you get to the node representing t, you're done. The order in which you first entered each node determines its place in the precedence list. One of the consequences of this definition (in fact, of rule 3) is that no class appears in the precedence list before one of its subclasses. The arrows in Figure 11.3 show how it would be traversed. The precedence list determined by this graph is: c a s t - s t a t u e , s t a t u e , s c u l p t u r e , c a s t i n g , metalwork, s t a n d a r d - o b j e c t , t . Sometimes the word specific is used as shorthand to refer to the position of a class in a given precedence list. The preceding list runs from most specific to least specific. The main point of precedence is to decide what method gets used when a generic function is invoked. This process is described in the next section. The other time precedence matters is when a slot with a given name is inherited from several superclasses. The note on page 408 explains the rules that apply when this happens.0

184

CLOS

@node Generic Functions
@section Generic Functions





















A generic function is a function made up of one or more methods. Methods are defined with def method, which is similar in form to def un: (defmethod combine (x y) ( LIST x y)) Now combine has one method. If we call combine at this point, we will get the two arguments in a list: > (combine ' a 'b) (A B) So far we haven't done anything we could not have done with a normal function. The unusual thing about a generic function is that we can continue to add new methods for it. First, we define some classes for the new methods to refer to: ( d e f c l a s s s t u f f () ((name :accessor name : i n i t a r g :name))) ( d e f c l a s s ice-cream ( s t u f f ) ( )) ( d e f c l a s s topping ( s t u f f ) ( )) This defines three classes: stuff, which is just something with a name, and ice-cream and topping, which are subclasses of stuff. Now here is a second method for combine: (defmethod combine ( ( i c ice-cream) (top topping)) (format NIL ""A ice-cream with ~A t o p p i n g . " (name i c ) (name t o p ))) In this call to defmethod the parameters are specialized: each one appears in a list with the name of a class. The specializations of a method indicate the kinds of arguments to which it applies. The method we just defined will only be used if the arguments to combine are instances of ice-cream and topping respectively. How does Lisp decide which method to use when a generic function is called? It will use the most specific method for which the classes of the arguments match the specializations of the parameters. Which means that if we call combine with an instance of ice-cream and an instance of topping, we'll get the method we just defined: > (combine (make-instance ' i c e - c r e a m :name ' f i g ) (make-instance ' t o p p i n g :name ' t r e a c l e )) "FIG ice-cream with TREACLE t o p p i n g . "

11.6

GENERIC FUNCTIONS

185

But with any other arguments, we'll get the first method we defined: > (combine 23 'skiddoo) (23 SKIDDOO) Because neither of the parameters of the first method is specialized, it will always get last priority, yet will always get called if no other method does. An unspecialized method acts as a safety net, like an otherwise clause in a case expression. Any combination of the parameters in a method can be specialized. In this method only the first argument is:
(defmethod combine ((ic ice-cream) x) (format nil "~A ice-cream with A." (name ic) x))

If we call combine with an instance of ice-cream and an instance of topping, we'll still get the method that's looking for both, because it's more specific: > (combine (make-instance ' i c e - c r e a m :name 'grape) (make-instance ' t o p p i n g :name 'marshmallow)) "GRAPE ice-cream with M A R S H M A L L O W topping." However, if the first argument is ice-cream and the second argument is anything but topping, we'll get the method we just defined above: > (combine (make-instance ' i c e - c r e a m :name 'clam) 'reluctance) "CLAM ice-cream with RELUCTANCE." When a generic function is called, the arguments determine a set of one or more applicable methods. A method is applicable if the arguments in the call come within the specializations of all its parameters. If there are no applicable methods we get an error. If there is just one, it is called. If there is more than one, the most specific gets called. The most specific applicable method is determined based on the class precedence for the arguments in the call. The arguments are examined left to right. If the first parameter of one of the applicable methods is specialized on a more specific class than thefirstparameters of the other methods, then it is the most specific method. Ties are broken by looking at the second argument, and so on.2
2 We can't go through all the arguments and still have a tie, because then we would have two methods with exactly the same specializations. That's impossible because the definition of the second would overwrite the first.

186

CLOS

In the preceding examples, it is easy to see what the most specific applicable method would be, because all the objects have a single line of descent. An instance of ice-cream is, in order, itself, ice-cream, stuff, a standard-ob j ect, and a member of the class t. Methods don't have to be specialized on classes defined by def c l a s s . They can also be specialized on types (or more precisely, the classes that mirror types). Here is a method for combine that's specialized on numbers:
(defmethod combine ((x number) (y number)) (+ x y))

Methods can even be specialized on individual objects, as determined by eql: (defmethod combine ((x (eql 'powder)) (y (eql ' s p a r k ))) 'boom) Specializations on individual objects take precedence over class specializations. Methods can have parameter lists as complex as ordinary Common Lisp functions, but the parameter lists of all the methods that compose a generic function must be congruent. They must have the same number of required parameters, the same number of optional parameters (if any), and must either all use ferest or &key, or all not use them. The following pairs of parameter lists are all congruent,
(x) (x feoptional y) (x y ferest z) (x y &key z) (a) (afeoptionalb) (a b &key c) (a b &key c d)

and the following pairs are not: (x) (a b) (x &optional y) (a &optional b c) (x feoptional y) (a forest b) (x &key x y) (a) Only required parameters can be specialized. Thus each method is uniquely identified by its name and the specializations of its required parameters. If we define another method with the same qualifiers and specializations, it overwrites the original one. So by saying
(defmethod combine ((x (eql 'powder)) (y (eql 'spark))) 'kaboom)

we redefine what combine does when its arguments are powder and spark.

11.7

AUXILIARY METHODS

187

@node Auxiliary Methods
@section Auxiliary Methods 

Methods can be augmented by auxiliary methods, including before-, after-, and around-methods. Before-methods allow us to say, "But first, do this." They are called, most specific first, as a prelude to the rest of the method call. After-methods allow us to say, "P.S. Do this too." They are called, most specific last, as an epilogue to the method call. Between them, we run what has till now been considered just the method, but is more precisely known as the primary method. The value of this call is the one returned, even if after-methods are called later. Before- and after-methods allow us to wrap new behavior around the call to the primary method. Around-methods provide a more drastic way of doing the same thing. If an around-method exists, it will be called instead of the primary method. Then, at its own discretion, the around-method may itself invoke the primary method (via the function call-next-method, which is provided just for this purpose). This is called standard method combination. In standard method combination, calling a generic function invokes 1. The most specific around-method, if there is one. 2. Otherwise, in order, (a) All before-methods, from most specific to least specific. (b) The most specific primary method. (c) All after-methods, from least specific to most specific. The value returned is the value of the around-method (in case 1) or the value of the most specific primary method (in case 2). Auxiliary methods are defined by putting a qualifying keyword after the method name in the call to def method. If we define a primary speak method for the speaker class as (def c l a s s speaker 0 0)





(defmethod speak ( ( s speaker) s t r i n g ) (format t "~A" s t r i n g )) then calling speak with an instance of speaker just prints the second argument:
> (speak (make-instance 'speaker) "I'm hungry") I'm hungry NIL

188

CLOS



By defining a subclass i n t e l l e c t u a l , which wraps before- and aftermethods around the primary speak method, ( d e f c l a s s i n t e l l e c t u a l (speaker) ()) string)













(defmethod speak :before ( ( i i n t e l l e c t u a l ) ( princ"Perhaps ")) (defmethod speak : a f t e r ( ( i i n t e l l e c t u a l ) ( princ" i n some s e n s e " ))

string)

we can create a subclass of speakers that always have the last (and the first) word:
> (speak (make-instance 'intellectual) "I'm hungry") Perhaps I'm hungry in some sense NIL







As the preceding outline of standard method combination noted, all before- and after-methods get called. So if we define before- or after-methods for the speaker superclass, (defmethod speak .-before ( ( s speaker) s t r i n g ) ( princ"I t h i n k ")) they will get called in the middle of the sandwich:
> (speak (make-instance 'intellectual) "I'm hungry") Perhaps I think I'm hungry in some sense NIL

Regardless of what before- or after-methods get called, the value returned by the generic function is the value of the most specific primary method--in this case, the NIL returned by format. This changes if there are around-methods. If there is an around-method specialized for the arguments passed to the generic function, the aroundmethod will get called first, and the rest of the methods will only run if the around-method decides to let them. An around- or primary method can invoke the next method by calling call-next-method. Before doing so, it can use next-method-p to test whether there is a next method to call. With around-methods we can define another, more cautious, subclass of speaker:

11.8

METHOD COMBINATION

189

(defclass courtier (speaker) ()) (defmethod speak :around ((c courtier) string) (format t "Does the King believe that ~A? " string) (if (eql (read) 'yes) (if (next-method-p) (call-next-method)) (format t "Indeed, it is a preposterous idea.~°/,")) 'bow)

When the first argument to speak is an instance of the c o u r t i e r class, the courtier's tongue is now guarded by the around-method: > (speak (make-instance ' c o u r t i e r ) "kings will l a s t " ) Does the King believe that kings will l a s t ? yes I think kings will l a s t
BOW

> (speak (make-instance ' c o u r t i e r ) "the world i s round") Does the King believe that the world i s round? no Indeed, i t is a preposterous idea. B O W Note that, unlike before- and after-methods, the value returned by the aroundmethod is returned as the value of the generic function.

@node Method Combination
@section Method Combination 

In standard method combination the only primary method that gets called is the most specific (though it can call others via call-next-method). Instead we might like to be able to combine the results of all applicable primary methods. It's possible to define methods that are combined in other ways--for example, for a generic function to return the sum of all the applicable primary methods. Operator method combination can be understood as if it resulted in the evaluation of a Lisp expression whose first element was some operator, and whose arguments were calls to the applicable primary methods, in order of specificity. If we defined the p r i c e generic function to combine values with +, and there were no applicable around-methods, it would behave as though it were defined:

(defun p r i c e (&rest args) (+ (apply (most specific primary method) args) (apply (least specific primary method) a r g s )))


190

CLOS









If there are applicable around-methods, they take precedence, just as in standard method combination. Under operator method combination, an aroundmethod can still call the next method via call-next-method. However, primary methods can no longer use call-next-method. We can specify the type of method combination to be used by a generic function with a :method-combinat ion clause in a call to def generic: (defgeneric p r i c e (x) (:method-combination +)) Now the p r i c e method will use + method combination; any def met hods for p r i c e must have + as the second argument. If we define some classes with prices, ( d e f c l a s s j a c k e t () ( )) ( d e f c l a s s t r o u s e r s () ()) ( d e f c l a s s s u i t (jacket t r o u s e r s )

())











(defmethod p r i c e + ( ( j k j a c k e t )) 350) (defmethod p r i c e + ( ( t r t r o u s e r s )) 200) then when we ask for the price of an instance of s u i t , we get the sum of the applicable p r i c e methods: > ( p r i c e (make-instance 550 'suit))

The following symbols can be used as the second argument to def method or in the : met hod-combination option to defgeneric: + and append list max min nconc or progn

You can also use standard, which yields standard method combination. Once you specify the method combination a generic function should use, all methods for that function must use the same kind. Now it would cause an error if we tried to use another operator (or -.before or : a f t e r ) as the second argument in a def method for pr i ce. If we want to change the method combination of p r i c e , we must remove the whole generic function by calling fmakunbound.

@node Encapsulation
@section Encapsulation 

Object-oriented languages often provide some way of distinguishing between the actual representation of objects and the interface they present to the world. Hiding implementation details brings two advantages: you can change the

11.10

ENCAPSULATION

191

implementation without affecting the object's outward appearance, and you prevent objects from being modified in potentially dangerous ways. Hidden details are sometimes said to be encapsulated. Although encapsulation is often associated with object-oriented programming, the two ideas are really separate. You can have either one without the other. We saw an example of encapsulation on a small scale on page 108. The functions stamp and r e s e t work by sharing a counter, but calling code does not need to know about this counter, nor can it modify it directly. In Common Lisp, packages are the standard way to distinguish between public and private information. To restrict access to something, we put it in a separate package, and only export the names that are part of the external interface. We can encapsulate a slot by exporting the names of the methods that can modify it, but not the name of the slot itself. For example, we could define a counter class and associated increment and c l e a r methods as follows: (defpackage "CTR" (:use "COMMON-LISP")
(:export "COUNTER" "INCREMENT" "CLEAR")) (in-package ctr) (defclass counter () ((state :initform 0))) (defmethod increment ((c counter)) (incf (slot-value c 'state))) (defmethod clear ((c counter)) (setf (slot-value c 'state) 0))

Under this definition, code outside the package would be able to make instances of counter and call increment and c l e a r , but would not have legitimate access to the name s t a t e . If you want to do more than just distinguish between the internal and external interface to a class, and actually make it impossible to reach the value stored in a slot, you can do that too. Simply unintern its name after you've defined the code that needs to refer to it: (unintern
;

state)

Then there is no way, legitimate or otherwise, to refer to the slot from any package.0

192

CLOS


@node Two Models
@section Two Models
Object-oriented programming is a confusing topic partly because there are two models of how to do it: the message-passing model and the generic function model. The message-passing model came first. Generic functions are a generalization of message-passing. In the message-passing model, methods belong to objects, and are inherited in the same sense that slots are. To find the area of an object, we send it an a r e a message, t e l l obj a r e a and this invokes whatever a r e a method obj has or inherits. Sometimes we have to pass additional arguments. For example, a move method might take an argument specifying how far to move. If we wanted to tell obj to move 10, we might send it the following message:
tell obj move 10

If we put this another way, (move obj 10) the limitation of the message-passing model becomes clearer. In messagepassing, we only specialize the first parameter. There is no provision for methods involving multiple objects--indeed, the model of objects responding to messages makes this hard even to conceive of. In the message-passing model, methods are of objects, while in the generic function model, they are specialized/or objects. If we only specialize the first parameter, they amount to exactly the same thing. But in the generic function model, we can go further and specialize as many parameters as we need to. This means that, functionally, the message-passing model is a subset of the generic function model. If you have generic functions, you can simulate message-passing by only specializing the first parameter.

Summary
1. In object-oriented programming, the function/is defined implicitly via the/methods of the objects that have them. Objects inherit methods from their parents.

2. Defining a class is like defining a structure, but more verbose. A shared slot belongs to a whole class.

3. A class inherits the slots of its superclasses.

EXERCISES



193



4. The ancestors of a class are ordered into a precedence list. The precedence algorithm is best understood visually.

5. A generic function consists of all the methods with a given name. A method is identified by its name and the specializations of its parameters. Argument precedence determines the method used when a generic function is called.

6. Methods can be augmented by auxiliary methods. Standard method combination means calling the around-method, if there is one; otherwise the before-, most specific primary, and after-methods.

7. In operator method combination, all the primary methods are treated as arguments to some operator.

8. Encapsulation can be done via packages.
9. There are two models of object-oriented programming. The generic function model is a generalization of the message-passing model.

Exercises
1. Define accessors, initforms, and initargs for the classes defined in Figure 11.2. Rewrite the associated code so that it no longer calls slot-value. 2. Rewrite the code in Figure 9.5 so that spheres and points are classes, and i n t e r s e c t and normal are generic functions. 3. Suppose that a number of classes are defined as follows: (defclass (defclass (defclass (defclass a b c d (c (d () (e d) ...) c) ...) ..) f g) ...) (defclass (defclass (defclass (defclass e f g h () . ..) (h) ...) (h) ...) () , .0

(a) Draw the network representing the ancestors of a, and list the classes an instance of a belongs to, from most to least specific. (b) Do the same for b. 4. Suppose that you already have the following functions; precedence: takes an object and returns its precedence list, a list of classes ordered from most specific to least specific.

194

CLOS

methods: takes a generic function and returns a list of all its methods. s p e c i a l i z a t i o n s : takes a method and returns a list of the specializations of the parameters. Each element of the returned list will be either a class, or a list of the form (eql x), or t (indicating that the parameter is unspecialized). Using these functions (and not compute-applicable-methods or find-method), define a function most-spec-app-meth that takes a generic function and a list of the arguments with which it has been called, and returns the most specific applicable method, if any. 5. Without changing the behavior of the generic function area (Figure 11.2) in any other respect, arrange it so that a global counter gets incremented each time a r e a is called. 6. Give an example of a problem that would be difficult to solve if only the first argument to a generic function could be specialized.



@node Structure
@chapter Structure


Section 3.3 explained how Lisp's use of pointers allows us to put any
value anywhere. This statement is full of possibilities, not all of
them good. For example, an object can be an element of itself. Whether
this is good or bad depends on whether it's done on purpose or by
accident.

@menu 
* Shared Structure::
* SI::
* Modification::
* Example-- Queues::
* Destructive Functions::
* Example-- Binary Search Trees II::
* Example-- Doubly-Linked Lists::
* Circular Structure::
* Constant Structure::

@end menu

@node Shared Structure
@section Shared Structure





Lists can share conses in common. In the simplest case, one list might be part of another. After > (setf p a r t ( LIST 'b ' c )) (B C) > (setf whole (cons ' a p a r t )) (A B C) the first cons is part of (in fact, is the cdr of) the second. In situations like this, we say that the two lists share structure. The underlying structure of the two lists is represented in Figure 12.1. The predicate t a i l p detects this situation. It takes two lists and returns true if the first would be encountered on traversing the second: > ( t a i l p p a r t whole) T We could imagine it written as:

195

196

STRUCTURE

parts: wholel = nil whole2 =

Figure 12.2: A shared tail.



(defun our-tailp (x y) (or (eql x y) (and (consp y) (our-tailp x (cdr y))))) As the definition suggests, every list is a tail of itself, and NIL is a tail of every proper list. In the more complex case, two lists can share structure without either one being a tail of the other. This happens when they share a tail in common, as in Figure 12.2. We can create this situation as follows: (setf part ( LIST ' b 'c) wholel (cons 1 p a r t ) whole2 (cons 2 p a r t )) Now wholel and whole2 share structure without either list being part of the other. When we have nested lists, it's important to distinguish between the lists sharing structure, and their elements sharing structure. Top-level list structure

12.1

SHARED STRUCTURE

197

holds 1 =

·
i

nil
f
i

\f
nil

f
d.

\
i

r

holds2 =

·

1
Fig ure 3 iare d su btre B.

I!

nil

@node SI
@section SI


refers to the conses that make up a list, not including any conses that make up its elements. Figure 12.3 shows the top-level list structure of a nested list. Whether two conses share structure depends on whether we are considering them as lists or as trees. Two nested lists may share structure as trees, without sharing structure as lists. The following code creates the situation shown in Figure 12.4, in which two lists contain the same list as an element:
(setf element (list 'a Jb) holdsl (list 1 element 2) holds2 (list element 3))

Although the second element of h o l d s l shares structure with (in fact, is identical to) the first element of holds2, h o l d s l and holds2 do not share structure as lists. Two lists only share structure as lists if they share top-level list structure, which h o l d s l and holds2 do not.

198

STRUCTURE

X

(copy-list)<) nil

(copy-tree x)

1 ^>* ;

nil

f

1
a ~+

1

nil

1

1

nil

nil

Figure 12.5: 1Pwo kinds o f copying.

If we want to avoid sharing structure, we can do it by copying. The function c o p y - LIST , which could be defined as

(defun our-copy-list (lst) (if (null lst) nil (cons (car lst) (our-copy-list (cdr lst)))))

will return a list that doesn't share top-level list structure with the original list. The function copy-tree, which might be defined as

(defun our-copy-tree (tr) (if (atom tr) tr (cons (our-copy-tree (car tr)) (our-copy-tree (cdr tr)))))

will return a list that doesn't even share tree structure with the original list. Figure 12.5 shows the difference between calling c o p y - LIST and copy-tree on a nested list.

@node Modification
@section Modification 

Why would we want to avoid sharing structure? Up to this point, the issue of shared structure has been just an intellectual exercise. It would not have made any difference to any program we've written so far. It is when we modify objects that shared structure becomes an issue. If two lists share structure, and we modify one, then we may inadvertently be modifying the other. In the previous section, we saw how to make one list a tail of another: (setf whole (list 'a ;b c) tail (cdr whole))

12.3

MODIFICATION

199

Since this will make t a i l identical with the cdr of whole, if we modify either t a i l or the cdr of whole, we are modifying the same cons:

> (setf (second t a i l ) ' e) E > tail (B E)
> whole (A B E) The same thing can also happen, of course, if two lists share the same tail. It's not always an error to modify two things at once. Sometimes it might be what you want. But when it happens inadvertently, modifying shared structure can cause some very subtle bugs. Lisp programmers learn to be aware of shared structure, and to suspect it immediately in certain kinds of errors. When a list mysteriously changes for no apparent reason, it is probably because you changed something else that shared structure with it. It is not the shared structure that's dangerous, but the changing. To be on the safe side, simply avoid using s e t f (or related operators like pop, rplaca, etc.) on list structure, and you won't run into any problems. If some application absolutely requires you to modify list structure, find out where the lists come from to make sure that they don't share structure with anything that shouldn't be changed. If they do, or if you can't predict where the lists will come from, make the changes to a copy. You have to be doubly careful when you are calling a function written by someone else. Until you know otherwise, consider the possibility that anything you pass to the function 1. could have destructive operations done to it, and/or 2. could be saved somewhere, so that if you later modified the object, you would also be modifying part of something that the other code was maintaining for its own use.1 In both cases, the solution is to pass a copy. In Common Lisp, a function called in the course of traversing list structure (e.g. an argument to mapcar or remove-if) is not allowed to modify the structure being traversed. The consequences of evaluating such code are undefined.
For example, in Common Lisp it's an error to modify a string being used as a symbol name, and since the definition of i n t e r n doesn't say that it copies its argument, we must assume that it's an error to modify any string that has been passed to i n t e r n to create a new symbol.
1

200

STRUCTURE

@node Example-- Queues
@section Example-- Queues 

Shared structure is not just something to worry about. It's also something you can put to use. This section shows how to use shared structure to represent queues. A queue is a repository from which objects can be retrieved, one at a time, in the order in which they were inserted. This principle is known as FTFO, from "first in, first out." It's easy to represent stacks using lists, because in a stack you insert and retrieve from the same end. Representing queues is more difficult, because insertion and retrieval happen at different ends. To implement queues efficiently, we need somehow to get hold of both ends of a list. Figure 12.6 suggests a strategy we could use. It shows how we might represent a queue of a, b, and c. A queue is a pair of a list, and the last cons in that same list. Call these front and back. To retrieve an element from the queue we just pop front. To add an element, we create a new cons, make it the cdr of back, and then set back to it. The code in Figure 12.7 implements this strategy. It's used as below:
> (setf ql (make-queue)) (NIL) > (progn (enqueue 'a ql) (enqueue ; b ql) (enqueue 'c ql)) (A B C)

At this point, ql is the structure shown in Figure 12.6: > qi ((A B C) C) Now we can try dequeueing some elements:

12.4

DESTRUCTIVE FUNCTIONS

201

(defun make--queue () (cons nil nil))

(defun enqueue (obj q) (if (null (car q)) (setf (cdr q) (setf (car q) (list obj))) (setf (cdr (cdr q)) (list obj) (cdr q) (cdr (cdr q)))) (car q))

(defun dequeue (q) (pop (car q))) Figure 12.7: Implementing queues.

> (dequeue ql) A > (dequeue ql) B > (enqueue 'd ql) (C D)

@node Destructive Functions
@section Destructive Functions



Common Lisp includes several functions that are allowed to modify list structure. These functions are destructive for reasons of efficiency. Though they may recycle conses passed to them as arguments, they are not meant to be called for their side-effects. For example, d e l e t e is a destructive version of remove. While it is allowed to trash the list passed to it as an argument, it doesn't promise to do anything. This is what happens in most implementations: > ( s e t f lst >(a r a b i a )) (ARABIA) > (delete 'a lst) (R B I) > lst (A R B I) As with remove, if you want side-effects, you should use s e t f with the return value:
(setf lst (delete 'a lst))

202

STRUCTURE

As an example of how destructive functions recycle the lists passed to them, consider nconc, the destructive version of append. 2 This twoargument version shows clearly how two existing lists are sewn together:

(defun nconc2 (x y) (if (consp x) (progn (setf (cdr (last x)) y) x) y» We go to the last cons cell in the first list, and set its cdr to point to the second list. A proper multi-argument nconc could be defined as in Appendix B. The function mapcan is like mapcar, but splices together the values returned by the function (which must be lists) using nconc: > (mapcan #;list '(a b c) '(1 2 3 4)) (A 1 B 2 C 3) This function might be defined as follows: (defun our-mapcan (fn ferest l s t s ) (apply #'nconc (apply #'inapcar fn l s t s ))) Use mapcan with caution, because it is destructive. It splices together the returned lists with nconc, so they had better not be needed elsewhere. This kind of function is particularly useful in problems that can be understood as collecting all the nodes at one level of some tree. For example, if c h i l d r e n returns a list of someone's children, then we could define a function to return a list of someone's grandchildren as follows: (defun grandchildren (x) (mapcan #'(lambda (c) (copy-list (children c))) (children x))) This function calls c o p y - LIST on the assumption that c h i l d r e n returns a list that's stored somewhere, instead of making a fresh one. A nondestructive variant of mapcan might be defined: (defun mappend (fn &rest l s t s ) (apply #'append (apply #'mapcar fn l s t s )))
2 The n originally stood for "non-consing." Several destructive functions have names beginning with n.

12.5

EXAMPLE: BINARY SEARCH TREES

203

(defun bst-insert! (obj bst <) (if (null bst) (make-node :elt obj) (progn (bsti obj bst <) bst))) (defun bsti (obj bst <) (let ((elt (node-elt bst))) (if (eql obj elt) bst (if (funcall < obj elt) (let ((1 (node-1 bst))) (if 1 (bsti obj 1 <) (setf (node-1 bst) (make-node :elt obj)))) (let ((r (node-r bst))) (if r (bsti obj r <) (setf (node-r bst) (make-node :elt obj))))))))

Figure 12.8: Binary search trees: Destructive insertion.

If we used mappend, we could leave out the c o p y - LIST in the definition of grandchildren:
(defun grandchildren (x) (mappend #'children (children x)))

@node Example-- Binary Search Trees II
@section Example-- Binary Search Trees II 

In some situations it's more natural to use destructive operations than nondestructive ones. Section 4.7 showed how to maintain a sorted collection of objects in a binary search tree, or BST. The functions given in Section 4.7 were all nondestructive, but in the situations where we would actually use BSTS, this is a needless precaution. This section shows how to define destructive insertion and deletion functions that are more likely to be useful in practice. Figure 12.8 shows how to define a destructive version of b s t - i n s e r t (page 72). It takes the same arguments and has the same return value. The only difference is that it may modify the BST given as the second argument.

204

STRUCTURE









As Section 2.12 warned, being destructive doesn't mean that a function is meant to be called for side-effects. And indeed, if you want to build a BST using b s t - i n s e r t ! , you have to call it the same way you would call the original b s t - i n s e r t : > (setf *bst* nil) NIL > (dolist (x ' ( 7 2 9 8 4 1 5 12)) (setf *bst* (bst-insert! x *bst* #'<))) NIL You could define an analogue of push for BSTs, but the techniques for doing so are beyond the scope of this book. (For the curious, this macro is defined on page 409.°) Figure 12.9 contains a destructive b s t - d e l e t e , which is to bst-remove (page 74) as d e l e t e is to remove. And like d e l e t e , it's not meant to be called for side-effects. You should call b s t - d e l e t e as you would call bst-remove: > ( s e t f *bst* ( b s t - d e l e t e 2 *bst* # ' < )) #<7> > ( b s t - f i n d 2 *bst* #'<) NIL

@node Example-- Doubly-Linked Lists
@section Example-- Doubly-Linked Lists 

Ordinary Lisp lists are singly linked lists, meaning that the pointers go in one direction: you can get to the next element, but not the preceding one. In a doubly linked list, the pointers go in both directions, so you can go backward as well as forward. This section shows how to create and manipulate doubly linked lists. Figure 12.10 shows how to implement doubly linked lists using structures. Considered as a structure, a cons has two fields: the car, which points to the data, and the cdr, which points to the next element. To represent an element in a doubly linked list we will need a third field, to point to the preceding element. The def s t r u c t in Figure 12.10 defines a three-part object called a d l (for "doubly linked") that we will use to build doubly linked lists. The d a t a field of a d l corresponds to the car of a cons, and the r e s t field to the cdr. The prev field will be like a cdr that goes in the other direction. (Figure 12.11 shows a doubly linked list of three elements.) The empty doubly linked list will be NIL , just like the empty list. By this call to def s t r u c t we define functions corresponding to car, cdr and consp for doubly linked lists: d l - d a t a , d l - n e x t , and d l - p . The print-

12.6

EXAMPLE: DOUBLY-LINKED LISTS

205





(defun bst-delete (obj bst <) (if bst (bstd obj bst nil nil <)) bst) (defun bstd (obj bst prev dir <) (let ((elt (node-elt bst))) (if (eql elt obj) (let ((rest (percolate! bst))) (case dir ( : 1 (setf (node-1 prev) rest)) ( : r (setf (node-r prev) rest)))) (if (funcall < obj elt) (if (node-1 bst) (bstd obj (node-1 bst) bst :1 <)) (if (node-r bst) (bstd obj (node-r bst) bst :r <)))))) (defun percolate! (bst) (cond ((null (node-1 bst)) (if (null (node-r bst)) nil (rperc! bst))) ((null (node-r bst)) (lperc! bst)) (t (if (zerop (random 2)) (lperc! bst) (rperc! bst))))) (defun lperc! (bst) (setf (node-elt bst) (node-elt (node-1 bst))) (percolate! (node-1 bst))) (defun rperc! (bst) (setf (node-elt bst) (node-elt (node-r bst))) (percolate! (node-r bst))) Figure 12.9: Binary search trees: Destructive deletion.

function for dls calls d l - > LIST , which returns an ordinary list containing the elements of a dl. The function d l - i n s e r t is like cons for doubly linked lists. At least, it's like cons in that it is the basic constructor function. It's unlike cons

206

STRUCTURE

(defstruct (dl (:print-function print-dl)) prev data next) (defun print-dl (dl stream depth) (declare (ignore depth)) (format stream "#<DL ~A>" (dl->list dl))) (defun dl->list (lst) (if (dl-p lst) (cons (dl-data lst) (dl->list (dl-next lst))) lst)) (defun dl-insert (x lst) (let ((elt (make-dl :data x :next lst))) (when (dl-p lst) (if (dl-prev lst) (setf (dl-next (dl-prev lst)) elt (dl-prev elt) (dl-prev lst))) (setf (dl-prev lst) elt)) elt)) (defun dl-list (forest args) (reduce #'dl-insert args :from-end t :initial-value nil)) (defun dl-remove (lst) (if (dl-prev lst) (setf (dl-next (dl-prev lst)) (dl-next lst))) (if (dl-next lst) (setf (dl-prev (dl-next lst)) (dl-prev lst))) (dl-next lst))

Figure 12.10: Building doubly linked lists.

in that it actually modifies the doubly linked list passed to it as the second argument. In this situation it is the most natural thing to do. You don't have to do anything to the rest of an ordinary list to cons something onto it, but if you want to put something on the front of a doubly linked list, you have to make the prev field of the rest of the list point back to the new element. To put it another way, several normal lists can share the same tail. But in doubly linked lists the tails have to point back at the structure that precedes

72.7

EXAMPLE: DOUBLY-LINKED LISTS

207

nil

nil

f

a

t

b

*

c

Figure 12.11: A doubly linked list.











them, so no two doubly linked lists can have the same tail. If d l - i n s e r t weren't destructive, it would always have to copy its second argument. Another interesting difference between singly and doubly linked lists is how you hold them. You hold a singly linked list by the front; when you set a variable to a list, it has a pointer to the first cons. But since a doubly linked list is connected in both directions, you can hold it at any point. So d l - i n s e r t is also unlike cons in that it can put a new element anywhere in a doubly linked list, not just on the front. The function d l - LIST is the d l analogue of LIST . You give it any number of arguments and it returns a d l containing them: > ( d l - LIST ' a ' b >c) #<DL (A B C)> It uses reduce, which, with :from-end true and an : i n i t i a l - v a l u e of NIL , makes the preceding call equivalent to ( d l - i n s e r t 'a ( d l - i n s e r t 'b ( d l - i n s e r t ' c NIL ))) If you replaced # ' d l - i n s e r t in the definition of d l - LIST with # ' cons, it would behave like LIST . Here is the new code in use: > (setf d l ( d l - LIST ' a >b)) #<DL (A B)> > (setf dl (dl-insert >c dl)) #<DL (C A B)> > (dl-insert 'r (dl-next dl)) #<DL (R A B)> > dl #<DL (C R A B)> Finally, dl-remove is for removing an element from a doubly linked list. Like d l - i n s e r t , it makes sense for it to be destructive.

208

STRUCTURE

J a Figure 12.12: Circular lists.

@node Circular Structure
@section Circular Structure
By modifying list structure it's possible to create circular lists. There are two kinds of circular lists. The more useful kind are those whose top-level list structure is a loop. Such lists are called cdr-circular because the loop passes through the cdr part of a cons. To make a cdr-circular list with one element, you set the cdr of a list to be the list itself: > (setf x (list 'a)) (A) > (progn (setf (cdr x) x) nil) NIL At this point x is a circular list, with the structure shown in Figure 12.12. If Lisp tried to print the list we just created, it would usually display (a a a a a, ad infinitum. But if we set the global * p r i n t - c i r c l e * to t, objects will be displayed in a way that can represent circular structure:

> (setf *print-circle* t ) T
> x #1=(A . #1#) If you need to, you can use the #n= and #n# read-macros to represent shared structure yourself. Cdr-circular lists could be useful--to represent buffers or pools, for example. The following function would take any non-cdr-circular, nonempty list and convert it into a cdr-circular list with the same elements: (defun circular (lst) (setf (cdr (last lst)) lst))

12.7

CIRCULAR STRUCTURE

209











The other kind of circular lists are car-circular lists. A car-circular list is a tree that has itself as a subtree. They are so called because the loop passes through the car of some cons. Here we create a car-circular list whose second element is itself: > (let ((y ( LIST >a ))) (setf (car y) y) y) #i=(#i#) Figure 12.12 shows the resulting structure. Though car-circular, this list is a proper list. Cdr-circular lists are never proper lists, but car-circular lists can be, unless they are disqualified for some other reason. A list could be both car- and cdr-circular. The car and the cdr of this cons will be the cons itself: > (let ( ( c (cons 1 1 ))) (setf (car c) c (cdr c) c) c) #1=(#1# . #1#) It's hard to imagine what the use of such an object would be. Indeed, the main reason to know about circular lists may be to avoid creating them by accident, because most functions that traverse list structure will go into an infinite loop if they are given a list that's circular in the dimension they traverse. Circular structure can be an issue for other kinds of objects besides lists. For example, an array can contain itself as an element:

> (setf *print-array* t ) T






> (let ( ( a (make-array 1 ))) (setf (aref a 0) a) a) #1=#(#1#) Indeed, just about anything that can have elements can have itself as an element. It's quite common to have circularities involving structures created by def s t r u c t . For example, a structure c representing an element in a tree might have a parent field that contained another structure/? whose c h i l d field in turn contained c:

210

STRUCTURE



















> (progn ( d e f s t r u c t e l t (parent NIL ) ( c h i l d NIL )) (let ( ( c (make-elt)) (p ( m a k e - e l t ))) ( s e t f (elt - p a r e n t c) p (elt - c h i l d p) c) c)) #1=#S(ELT PARENT #S(ELT PARENT NIL CHILD #1#) CHILD NIL) In the p r i n t - f u n c t i o n of such a structure, you would either want to bind · p r i n t - c i r c l e * to t , or avoid printing the values of the fields through which cycles might pass.



@node Constant Structure
@section Constant Structure




Because constants are effectively part of the code in which they occur, it is also important not to modify them, or you may inadvertently create selfrewriting programs. A quoted list is a constant, so you should be careful not to modify any cons that was ever part of a quoted list in the text of a program. For example, if we use the following predicate to test whether something is an arithmetic operator, (defun arith-op (x) (member x '(+ - * /))) then its return value, if true, will incorporate at least part of a quoted list. If we modify the return value, > (nconc ( a r i t h - o p '*) ' ( a s i t were)) (* / AS IT WERE) then we could be modifying the list within a r i t h - o p , and thereby changing what the function does: > (arith-op 'as) (AS IT WERE) It is not necessarily an error to write a function that returns constant structure. But when you are considering whether it's safe to perform destructive operations on something, you must certainly take this into account. There are several ways to write a r i t h - o p so that it doesn't return part of a quoted list. In the general case, you can ensure safety by replacing any quoted list with a call to LIST , which returns a new list each time:

SUMMARY

211

(defun arith-op (x) (member x (list ;+ '-

'* V)))

In this case, calling LIST is an inefficient solution. You would be better off using find instead of member: (defnn arith-op (x) (find x >(+ - * /))) The problem described in this section is most likely to happen with lists, but it could happen with complex objects of any type: arrays, strings, structures, instances, and so on. You shouldn't modify anything that occurs literally in the text of a program. Even if you want to write self-modifying programs, modifying constants is not the way to do it. The compiler can wire constants into the code, and destructive operators can modify their arguments, but neither is guaranteed. The way to write self-modifying programs, if that's what you want, is to use closures (Section 6.5).

Summary
1. Two lists can share a tail. Lists can share structure as trees without sharing top-level list structure. Shared structure can be avoided by copying. 2. Shared structure can usually be ignored, but it must be considered if you are going to modify lists. Modifying one list can modify other lists that share structure with it. 3. Queues can be represented as conses in which the car points to the first cons in a list and the cdr to the last. 4. For reasons of efficiency, destructive functions are allowed to modify their arguments. 5. In some applications, destructive implementations are the most natural. 6. Lists can be car- or cdr-circular. Lisp can represent circular and shared structure. 7. Constants occurring in the text of a program should not be modified.

212

STRUCTURE

Exercises
1. Draw three different trees that would print as ((A) (A) (A)). Write an expression that generates each. 2. Assuming make-queue, enqueue, and dequeue are defined as in Figure 12.7, draw the queue in box-notation after each step:
> (setf q (make-queue)) (NIL) > (enqueue ' a q) (A) > (enqueue ' b q) (A B) > (dequeue q) A

3. Define a function copy-queue that returns a copy of a queue. 4. Define a function that takes an object and a queue, and puts the object on the front of the queue. 5. Define a function that takes an object and a queue, and (destructively) moves the first (eql) instance of the object to the front of the queue. 6. Define a function that takes an object and a possibly cdr-circular list, and returns true if the object is a member of the list. 7. Define a function that returns true when its argument is a cdr-circular list. 8. Define a function that returns true when its argument is a car-circular list.



@node Speed
@chapter Speed


Lisp is really two languages: a language for writing fast programs and
a language for writing programs fast. In the early stages of a program
you can trade speed for convenience. Then once the structure of your
program begins to crystallize, you can refine critical portions to
make them faster.


 It's difficult to give general advice about optimization, because of
the variation between Common Lisp implementations. A change that made
your program faster in one implementation might make it slower in
another. This is something that comes with the territory. The more
powerful the language, the further you are from the machine, and the
further you are from the machine, the greater the chance that
different implementations will take different paths toward it. So
while there are some techniques that are almost certain to make your
programs faster, the aim of this chapter will be to suggest rather
than to prescribe.

@menu 
* The Bottleneck Rule::
* Compilation II::
* Type Declarations::
* Garbage Avoidance::
* Example-- Pools::
* Fast Operators::
* Two-Phase Development::
@end menu

@node The Bottleneck Rule
@section The Bottleneck Rule 

Three points can be made about optimization, regardless of the implementation: it should be focused on bottlenecks, it should not begin too early, and it should begin with algorithms. Probably the most important thing to understand about optimization is that programs tend to have a few bottlenecks that account for a great part of the execution time. According to Knuth, "most of the running time in non-iobound programs is concentrated in about 3% of the source text."0 Optimizing these parts of the program will make it run noticeably faster; optimizing the rest of the program will be a waste of time in comparison. 213

214

SPEED

So the crucial first step in optimizing any program is to find the bottlenecks. Many Lisp implementations come with profilers that can watch a program as it's running and report the amount of time spent in each part. A profiler is a valuable tool--perhaps even a necessity--in producing the most efficient code. If your Lisp implementation provides one, use it to guide optimization. If not, you are reduced to guessing where the bottlenecks are, and you might be surprised how often such guesses turn out to be wrong. A corollary of the bottleneck rule is that one should not put too much effort into optimization early in a program's life. Knuth puts the point even more strongly: "Premature optimization is the root of all evil (or at least most of it) in programming."0 It's hard to see where the real bottlenecks will be when you've just started writing a program, so there's more chance you'll be wasting your time. Optimizations also tend to make a program harder to change, so trying to write a program and optimize it at the same time can be like trying to paint a picture with paint that dries too fast. You end up with better programs if each task can be emphasized at the appropriate time. One of the benefits of Lisp is that it lets you work at a range of different speeds: you can write slow code fast or fast code slow. In the early stages of a program you tend to work in the former mode, then as optimization takes precedence you switch into the latter. As the bottleneck rule suggests, this is a more effective use of your time. In a very low-level language, like assembler, you are essentially optimizing every line of the program. Most of this effort is wasted, because the bottlenecks only make up a small part of it. A more abstract language allows you to spend a greater proportion of your time on the bottlenecks, and so get most of the gains with a fraction of the effort. When you do turn to optimization, begin at the top. That is, make sure that you're using the most efficient algorithm before you resort to low-level coding tricks. The potential gains are greater--perhaps great enough that you won't have to resort to coding tricks after all. This rule has to be balanced against the preceding one, though. Sometimes decisions about algorithms have to be made early.

@node Compilation II
@section Compilation II 

Five parameters control the way your code is compiled: speed refers to the speed of the code produced by the compiler; compilation-speed refers to the speed at which your program will be compiled; s a f e t y refers to the amount of error-checking done in the object code; space refers to the size and memory needs of the object code; and debug refers to the amount of information retained for debugging.

13.2

COMPILATION

215

INTERACTIVE VS. INTERPRETED

Lisp is an interactive language, but a language does not have to be interpreted to be interactive. Early Lisp implementations were implemented by interpreters, and the idea arose that Lisp's unique qualities depended on its being interpreted. This idea is mistaken: Common Lisp is the same language compiled as it is interpreted. At least two Common Lisp implementations do not even include interpreters. In these implementations, expressions typed into the toplevel are compiled before being evaluated. So it is not merely old-fashioned to call the toplevel the "interpreter," it can be an error of fact.













The compilation parameters are not real variables. They are assigned weights from 0 (unimportant) to 3 (most important) in declarations. If a major bottleneck occurred in the inner loop of some function, we might add a declaration like the following: (defun b o t t l e n e c k ( . . . ) (do ( . . . ) (...) (do ( . . . ) (...) ( d e c l a r e (optimize (speed 3) ( s a f e t y 0 ))) ...))) Generally you would not want to add such declarations until the code was finished and tested. To ask globally for the fastest possible code, regardless of the consequences, you could say: (declaim (optimize (speed 3) (compilation-speed 0) ( s a f e t y 0) (debug 0 ))) This would be a drastic step, and probably not even necessary, given the bottleneck rule.1 One particularly important kind of optimization done by Lisp compilers is the optimization of tail calls. Giving speed the maximum weight will ensure tail call optimization by any compiler capable of it.
'Older implementations may not provide declaim; instead use proclaim and quote the argument.

216

SPEED

A call is a tail call if nothing remains to be done after it returns. The following function returns the length of a list:
(defun length/r (lst) (if (null lst) 0 (1+ (length/r (cdr lst)))))

The recursive call is not a tail call, because after it returns, its value has to be passed to 1+. However, this version is tail-recursive,
(defun length/tr (lst) (labels ((len (lst ace) (if (null lst) ace (len (cdr lst) (1+ ace))))) (len lst 0)))

or more precisely, the local function l e n is, because nothing more has to happen after the recursive call returns. Instead of building its return value on the way back up the recursion, like l e n g t h / r , it accumulates the return value on the way down. Hence the additional parameter ace, which can simply be returned at the end of the last recursive call. A good compiler can compile a tail call into a goto, and so can compile a tail-recursive function into a loop.0 In typical machine language code, when control arrives for the first time at the segment of instructions representing len, there is information on the stack saying what to do upon returning. Because nothing remains to be done after the recursive call, this information remains valid for the second invocation as well: what we are supposed to do on returning from the second invocation is simply to return from the first invocation. So after setting the parameters to their new values, we can just jump back to the beginning of the function and act as if this were the second invocation. There is no need to do a real function call. Another way to have the abstraction of function calls without the cost is to have functions compiled inline. This is valuable mainly for small functions, where the machinery of calling the function could entail more work than the function itself performs. For example, the following function tells whether something is a list of a single element:
(declaim (inline single?)) (defun single? (lst) (and (consp lst) (null (cdr lst))))

13.3

TYPE DECLARATIONS

217

Because this function is globally declared inline, a reference to s i n g l e ? within a compiled function should no longer require a real function call.2 If we define a function that calls it,
(defun foo (x) (single? (bar x)))









then when foo is compiled, the code for s i n g l e ? should be compiled right into it, just as if we had written (defun foo (x) (let ( ( lst (bar x ))) (and (consp lst ) ( n u l l (cdr lst ))))) in the first place. There are two limitations on inline compilation. Recursive functions can't be inlined. And if an inlined function is redefined, we have to recompile any function that calls it, or the calling function will still reflect the old definition. In some earlier dialects of Lisp, one used macros (Section 10.2) to avoid function calls. In Common Lisp this is no longer supposed to be necessary. Different Lisp compilers do varying amounts of optimization. If you want to see the code your compiler produces for a function, try calling disassemble. This function takes a function or function name and displays its compiled form. Even if what you see is completely incomprehensible, you can still use disassemble to determine whether declarations are being used: compile two version of the function, one with the declaration and one without, and see if the code displayed by disassemble differs between the two. You can use a similar technique to see if functions are being compiled inline. In either case, be sure to set the compilation parameters beforehand to get the fastest code.0

@node Type Declarations
@section Type Declarations 

If you're learning Lisp as a second language, you may have been puzzled by the omission up to this point of something that's de rigueur in most other languages: type declarations. In most languages, you have to declare the type of each variable, and the variable can only hold values of that type. Such a language is said to be strongly typed. As well as being a lot of work for the programmer, this approach imposes restrictions on what you can do. In such a language it's hard to write functions that work for different kinds of arguments, or to have
2 For inline declarations to have an effect, you may also have to set the compilation parameters to get fast code.

218

SPEED





data structures that contain different kinds of elements.0 The advantage of this approach is that whenever the compiler sees an addition, for example, it knows beforehand what kind of addition is involved. If both arguments are integers, it can hard-wire an integer addition in the object code. As Section 2.15 mentioned, Common Lisp uses a more flexible approach called manifest typing.3 Values have types, not variables. Variables can hold objects of any type. If we left it at that, we would have to pay for this flexibility in speed. Because it can take several different types of numbers, + would have to look at the types of each of its arguments, and decide what kind of addition to do at run-time. If we just want an integer addition after all, this is an inefficient way to get it. So Common Lisp's approach is: tell me as much as you know. If we know ahead of time that both of the arguments in some addition will be fixnums, then we can declare them to be such, and the compiler will hard-wire an integer addition just as in C. So the difference between the two approaches to typing need not entail any difference in speed. It's just that the first approach makes type declarations mandatory, and the second doesn't. In Common Lisp, type declarations are completely optional. They may make a program faster, but (unless incorrect) they will not change its behavior. Global declarations are made with declaim, which should be followed by one or more declaration forms. A type declaration is a list containing the symbol type, followed by a type name and the names of one or more variables. So to declare the type of a global variable, one could say: (declaim (type fixnum *count*)) In ANSI Common Lisp you can omit the type and say simply: (declaim (fixnum *count*)) Local declarations are made with d e c l a r e , which takes the same arguments as declaim. Declarations can begin any body of code where variables have just been created: in defun, lambda, l e t , do, and so on. To declare a function's parameters to be fixnums, for example, we would say: (defun poly (a b x) (declare (fixnum a b x)) (+ ( * a (expt x 2)) ( * b x)))
3 There are two ways to describe Lisp's approach to typing: by where the type information is kept, and by when it is used. Manifest typing means that the type information is attached to the data objects, and run-time typing means that type information is used at run-time. In practice they mean the same thing.

13.3

TYPE DECLARATIONS

219





A variable name in a type declaration refers to the variable with that name in the context where the declaration occurs--to the variable whose value would be altered if it were instead an assignment. You can also declare that the value of an expression will be of a certain type, by using the. If we know beforehand that a, b, and x will not only be fixnums, but that they will be small enough fixnums that all the intermediate results will be fixnums, we can say: (defun poly (a b x) (declare (fixnum a b x)) (the fixnum (+ (the fixnum ( * a (the fixnum (expt x 2)))) (the fixnum ( * b x))))) Looks a bit awkward, doesn't it? Fortunately, there are two reasons that you rarely have to clutter up your numeric code with thes in this way. One is that it's easy to use macros to insert such declarations for you.° The other is that some implementations use special tricks to make fixnum arithmetic fast without declarations. There are a great many types in Common Lisp--a potentially unlimited number, considering that you can define new types yourself. However, declarations only matter for a few. When does it pay to make type declarations? There are two general rules: 1. It pays to declare the types of arguments to functions that work for arguments of several different types (but not all types). If you knew that the arguments in a call to + would always be fixnums, or that the first argument in a call to aref would always be a particular kind of array, it could pay to make a type declaration. 2. It is usually only worthwhile to make declarations for types near the bottom of the type hierarchy: declaring something to be of type f ixnum or simple-array might be useful, but declaring something to be of type i n t e g e r or sequence probably would not. Type declarations are particularly important for the contents of complex objects, including arrays, structures, and instances. Such declarations can improve efficiency in two ways: as well as allowing the compiler to determine the types of arguments to functions, they make it possible to represent these objects more efficiently in memory. If nothing is known about the type of elements an array will contain, it has to be represented in memory as a block of pointers. But if it is known that the array will only contain, say, double-floats, then the array can be represented as a block of actual double-floats. This way the array will take less space, because we no longer need a pointer to point to each of the double-floats, and

220

SPEED

--CH

1

\

N

N

N 2.345d0 3.456d0 2.345d0 3.456d0 1.234d0

' --c::r
i 1.234d0

Figure 13.1: Effect of specifying element type.



access will be faster, because we don't have to follow pointers to read and write elements. You can specify the kind of values that an array will contain by giving the : element-type argument to make-array. Such an an array is called a specialized array. Figure 13.1 shows what would happen, in most implementations, as a result of evaluating the following code: ( s e t f x (vector 1.234d0 2.345d0 3.456d0) y (make-array 3 :element-type ' d o u b l e - f l o a t ) (aref y 0) 1.234d0 (aref y 1) 2.345d0 (aref y 2) 3.456d0) Each rectangle in Figure 13.1 represents a word of memory. The two arrays each consist of a header of unspecified length, followed by some representation of the three elements. In x, each element is represented by a pointer. All three pointers happen to point to double-floats at the moment, but we could store objects of any type in this vector. In y, each element is an actual double-float. This is faster and takes less space, but it means that the vector can only hold double-floats. Note that we use aref to refer to the elements of y. A specialized vector is no longer a simple vector, so we can no longer use svref to refer to its elements. As well as specifying the element type of an array when you create it, you should declare the dimensions and element type of an array in code that uses it. A full vector declaration would look like: (declare (type (vector fixnum 20) v)) This declares v to be a vector of length 20, specialized for fixnums.

133

TYPE DECLARATIONS

221







(setf a (make-array '(1000 1000) :element-type ' s i n g l e - f l o a t : i n i t i a l - e l e m e n t l.OsO)) (defun sum-elts (a) ( d e c l a r e (type ( s i m p l e - a r r a y s i n g l e - f l o a t a)) (let ((sum 0.0s0)) (declare (type s i n g l e - f l o a t sum)) (dotimes (r 1000) (dotimes (c 1000) (incf sum (aref a r c )))) sum)) Figure 13.2: Summing an array.

(1000 1000))

The most general form of array declaration consists of the array type followed by the element type and a list of dimensions:
(declare (type (simple-array fixnum (4 4)) ar))

This declares that a r will be a 4 x 4 simple array specialized for fixnums. Figure 13.2 shows how to create a lOOOx 1000 array of single-floats, and how to write a function to sum the elements of such an array. Arrays are stored in row-major order and should be traversed that way when possible. We will use t ime to compare the performance of sum-elt s with and without declarations. The t ime macro displays some (implementation-dependent) measure of how long it takes to evaluate an expression. It's only meaningful to time compiled functions. In one implementation, if we compile sum-elts with the compilation parameters set to get the fastest code, it returns in less than half a second: > (time (sum-elts a ))
User Run Time = 0 . 4 3 seconds 1000000.0

If we take the type declarations out of sum-elts and recompile it, the same computation takes more than five seconds: > (time (sum-elts a))
User Run Time = 5 . 1 7 seconds 1000000.0

222

SPEED

The importance of type declarations, especially for arrays and numbers, cannot be overemphasized. Here, two lines of code make sum-elts twelve times faster.

@node Garbage Avoidance
@section Garbage Avoidance 

As Lisp allows you to delay thinking about the types of variables, it also allows you to delay thinking about memory allocation. In the early stages of a program it frees your imagination not to have to think about (or deal with bugs involving) memory allocation. As a program matures, it can rely less on dynamic allocation and so become faster. However, consing less does not always make a program faster. In Lisp implementations with bad garbage collectors, programs that cons a lot tend to run slowly. Until recently, most Lisp implementations have had bad garbage collectors, and so it has become a tradition that efficient programs should cons as little as possible. Recent developments have turned this conventional wisdom on its head. Some implementations now have such sophisticated garbage collectors that it is faster to cons up new objects and throw them away than it is to recycle them. This section introduces some ways to make programs cons less. Whether consing less will make your programs run faster depends on the implementation. Again, the best advice is to try it and see. There are a lot of things you can do to reduce consing. Some of them won't affect the shape of your program at all. For example, one of the easiest steps you can take is to use destructive functions. The following table lists some commonly used functions and their destructive counterparts.

[ SAFE append reverse remove remove-if remove-duplicates subst subst-if union intersection set-difference
DESTRUCTIVE nconc nreverse delete delete-if delete-duplicates nsubst nsubst-if nunion nintersection nset-difference .

When you know it's safe to modify a list, you can use d e l e t e instead of remove, n r e v e r s e instead of r e v e r s e , and so on. If you want to eliminate consing entirely, you don't have to give up the possibility of creating things on the fly. What you have to avoid is allocating

13.4

GARBAGE AVOIDANCE

223

space for them on the fly, and reclaiming it by garbage collection. The general solution is to allocate blocks of memory beforehand, and explicitly recycle used blocks yourself. Beforehand could mean at compile-time, or in some initialization routine. When speed begins to matter depends on the application. For example, when circumstances allow us to impose a limit on the size of a stack, we could have the stack grow and shrink along a pre-allocated vector, instead of building it out of conses. Common Lisp has built-in support for using vectors as stacks. If we give the optional f i l l - p o i n t e r argument to make-array, we will get a vector that seems to be expandable. The first argument to make-array specifies the amount of storage to be allocated for the vector, but the f i l l - p o i n t e r , when given, specifies the initial effective length:
> (setf *print-array* t) T > (setf vec (make-array 10 -.fill-pointer 2 :initial-element nil)) #(NIL NIL)

The vector we just made will seem to sequence functions as if it had only two elements, > (length vec) 2 but it will be able to grow until it has up to ten. Because vec has a fill pointer, we can use the functions vector-push and vector-pop to push and pop elements as if it were a list:
> (vector-push 'a vec) 2 > vec #(NIL NIL A) > (vector-pop vec) A > vec #(NIL NIL)

When we called vector-push, it incremented the fill pointer and returned its old value. As long as the fill pointer is less than the initial argument to make-array, we can push new elements onto the vector; when it runs out of space, vector-push will return NIL . We could push up to eight more elements onto vec at this point.

224

SPEED

















(defconstant d i e t (make-array 25000 : f i l l - p o i n t e r 0)) (defun read-words (from) ( s e t f ( f i l l - p o i n t e r d i e t ) 0) ( w i t h - o p e n - f i l e ( i n from : d i r e c t i o n :input) (do ((w ( r e a d - l i n e i n NIL :eof) (read-line in NIL :eof))) ( ( e q l w :eof)) (vector-push w d i e t )))) (defun xform (fn seq) (map-into seq fn seq)) (defun write-words (to) ( w i t h - o p e n - f i l e (out t o

: d i r e c t i o n :output : i f - e x i s t s .·supersede)





(map NIL #'(lambda (x) ( f r e s h - l i n e out) (princ x out)) (xform U n r e v e r s e ( s o r t (xform U n r e v e r s e d i e t ) #'string<))))) Figure 3.3: Generating a rhyming dictionary.



One disadvantage of vectors with fill pointers is that they are no longer simple vectors. We have to use aref instead of svref to refer to elements. This, cost has to be balanced against the potential gains. In applications that involve very long sequences, you may want to use map-into instead of map. Instead of a sequence type, map-into takes as its first argument an actual sequence to hold the result. This sequence can be one of those from which the arguments to the function are taken. So, for example, if you want to increment each element of a vector v, you might write: ( s e t f v (map-into v #'1+ v)) Figure 13.3 shows an example of an application that uses a large vector: a program to generate a simple rhyming dictionary (or more precisely, a dictionary of sight rhymes). The function read-words reads words from a file containing one per line,0 and the function write-words prints them out in reverse alphabetical order. That is, the output might begin with
a amoeba alba samba marimba...

13.4
and end with

GARBAGE AVOIDANCE

225

...megahertz gigahertz jazz buzz fuzz





By taking advantage of fill-pointers and map- into* we can write this program in a way that's both simple and efficient. In numeric applications, be careful of bignums. Bignum arithmetic conses, as well as being inherently slower. But even if your program must return bignums in the end, you may be able to make it more efficient by arranging that intermediate results are usually fixnums. Another way to avoid garbage collection is to encourage the compiler to allocate objects on the stack instead of the heap. When you know that you will only need something temporarily, you may be able to avoid allocating space for it on the heap by declaring it to have dynamic extent. By giving a dynamic extent declaration for a variable, you're saying that the variable's value need not last any longer than the variable does. When could the value last longer than the variable? Here's an example: (defun o u r - r e v e r s e ( lst ) (let ((rev NIL )) ( d o LIST (x lst ) (push x r e v )) rev)) In o u r - r e v e r s e , the list passed as an argument will be accumulated in reverse order in rev. When the function returns, the variable rev will go away. However, the list that is its value will persist: it is sent back to the calling function, where who knows what fate awaits it. In contrast, consider the following implementation of adj oin: (defun our-adjoin (obj lst &rest args) (if (apply t'member obj lst args) lst (cons obj lst ))) In this case, we can see from the definition of the function that the list in args is going nowhere. It need not last longer than the variable itself. This is the kind of situation where it would make sense to make a dynamic extent declaration. If we add such a declaration,
(defun our-adjoin (obj lst ferest args) (declare (dynamic-extent args)) (if (apply #'member obj lst args) lst (cons obj lst)))

226

SPEED

(defparameter *harbor* nil) (defstruct ship name flag tons) (defun enter (n f d) (push (make-ship :name n :flag f :tons d) *harbor*)) (defun find-ship (n) (find n *harbor* :key #'ship-name)) (defun leave (n) (setf *harbor* (delete (find-ship n) *harbor*))) Figure 13.4: Harbor.

then the compiler is free (but not required) to allocate space for args on the stack, where it will be automatically discarded on return from our-adjoin.

@node Example-- Pools
@section Example-- Pools 

In applications that involve data structures, you can avoid dynamic allocation by pre-allocating a certain number of them in a pool. When you need a structure, you get one from the pool, and when you're finished with one, you send it back to the pool.0 To illustrate the use of pools, we'll write a quick prototype of a program to keep track of the ships in a harbor, and then rewrite it to use a pool. Figure 13.4 contains the first version. The global *harbor* will be a list of ships, each represented by a ship structure. The function e n t e r is called when a ship enters the harbor; f i n d - s h i p finds a ship with a given name (if there is one); and leave is called when a ship leaves the harbor. This would be a perfectly good way to write the initial version of a program, but it will generate a lot of garbage. As this program runs it will cons in two ways: new structures will have to be allocated as ships enter the harbor, and new conses will have to be made as *harbor* grows. We can eliminate both sources of consing by allocating the space at compile-time. Figure 13.5 contains a second version of the program that shouldn't cons at all.

13.6

EXAMPLE: POOLS

227

(defconstant pool (make-array 1000 :f ill-pointer t)) (dotimes (i 1000) (setf (aref pool i) (make-ship))) (defconstant harbor (make-hash-table :size 1100 :test # ; eq)) (defun enter (n f d) (let ((s (if (plusp (length pool)) (vector-pop pool) (make-ship)))) (setf (ship-name s) n (ship-flag s) f (ship-tons s) d (gethash n harbor) s))) (defun find-ship (n) (gethash n harbor)) (defun leave (n) (let ((s (gethash n harbor))) (remhash n harbor) (vector-push s pool))) Figure 13.5: Harbor, version 2.

Strictly speaking, the new version does cons, just not at run-time. In the second version, harbor is a hash table instead of a list, so all the space for it will be allocated at compile-time. A thousand ship structures will also be created at compile-time, and stored in the vector pool. (If the : f i l l - p o i n t e r argument is t, the fill pointer points to the end of the vector.) Now when e n t e r needs a new structure, it gets one from the pool instead of calling make-ship. And when leave removes a ship from harbor, instead of being thrown away, it is sent back to the pool. What we're doing by using pools is taking over the job of memory management. Whether this actually makes our program run faster depends on how our Lisp implementation manages memory. Generally speaking, it pays to use pools only in implementations with primitive garbage collectors, or in real-time applications where the unpredictability of GC would be a problem.

228

SPEED

@node Fast Operators
@section Fast Operators



The beginning of this chapter described Lisp as two different languages. In one sense this is literally true. If you look closely at the design of Common Lisp, you can see that some features are intended mainly for speed, and others mainly for convenience. For example, there are three functions you could use to retrieve the element at a given position in a vector: e l t , aref, and svref. Such variety exists to allow you to squeeze as much performance out of a program as possible. So if you can use svref, do. Conversely, a part of a program where speed is important probably should not be calling e l t , which works for both arrays and lists. Instead of calling e l t on a list, you can call nth, which is specifically for lists. Yet there is only a single function, length, for finding the length of any sequence. Why doesn't Common Lisp provide a separate version for lists? Because if your program is finding the lengths of lists, it's already lost, as far as speed is concerned. In this case, as in many others, the design of the language suggests what is fast and what isn't. Another pair of similar functions are eql and eq. The former is the default predicate for testing identity, but the latter is faster if you know that the arguments won't be characters or numbers. Two objects are eq when they have the same location in memory. Numbers and characters may not be associated with any particular memory location, so eq does not apply to them (though in most implementations it does work for fixnums). For arguments of any other kind, eq will return the same value as eql. It's always fastest to compare objects using eq, because all Lisp has to do is compare the pointers to them. So eq hash tables (as in Figure 13.5) should offer the fastest access. In an eq hash table, gethash can just hash on pointers, without even looking at what they point to. Access is not the only thing to consider, however; eq and e q l hash tables incur extra costs under copying garbage collection algorithms because they have to be rehashed after a GC. If this becomes a problem, the best solution may be to use an eql hash table with fixnums as keys. Calling reduce can be a more efficient alternative to apply when the function in question has a rest parameter. For example, instead of something like (apply #'+ ' ( 1 2 3)) it can be more efficient to say: (reduce #'+ ' (1 2 3)) Not only does it help to call the right functions, it helps to call them the right way. Rest, optional, and keyword parameters are expensive. With

13.7

TWO-PHASE DEVELOPMENT

229

ordinary parameters, the arguments in a function call are simply left by the caller where the callee knows to look for them. But other kinds of parameters involve processing at run-time. Keyword parameters are the worst. For builtin functions, good compilers take special measures to compile calls with keyword arguments into fast code. But in your own functions it is just as well to avoid using them in speed-critical parts of a program. It is also wise not to push large numbers of arguments into rest parameters, if this can be avoided. Individual compilers sometimes perform their own particular optimizations. For example, some compilers can optimize case statements where the keys are integers in a narrow range. Check your user's manual for hints about such implementation-specific optimizations.


@node Two-Phase Development
@section Two-Phase Development
In applications where speed is paramount, you may want to rewrite part of a Lisp program in a lower-level language like C or assembler. You can use this technique with programs written in any language--critical parts of C programs are often rewritten in assembler--but the more abstract the language, the greater the benefits of developing programs in two phases. Common Lisp does not prescribe a way of integrating code written in other languages. This is left up to the implementation, but almost all implementations provide some way to do it. It may seem wasteful to write a program in one language and then to rewrite part of it in another. In fact, experience has shown this to be a good way to develop software. It can be easier to aim for functionality first, and then for speed, than to try to achieve both at the same time. If programming were an entirely mechanical process--a matter of simply translating specifications into code--it would be reasonable to do everything in a single step. But programming is never like that. No matter how precise the specifications, programming always involves a certain amount of exploration--usually a lot more than anyone had anticipated. It might seem that if the specifications were good, programming would simply be a matter of translating them into code. This is a widespread misconception. Programming necessarily involves exploration, because specifications are necessarily vague. If they weren't vague, they wouldn't be specifications. In other fields, it may be desirable for specifications to be as precise as possible. If you're asking for a piece of metal to be cut to a certain shape, it's probably best to say exactly what you want. But this rule does not extend to software, because programs and specifications are made out of the same thing: text. You can't write specifications that say exactly what you want. If the specifications were that precise, then they would be the program.0

230

SPEED

In applications that involve a substantial amount of exploration (and again, more do than anyone admits), it can pay to separate implementation into two phases. And the medium you use in the first phase need not be the final one. For example, the standard way to make bronze sculptures is to begin with clay. You build a sculpture out of clay first, and then use that to make a mold in which the bronze sculpture is cast.0 No clay remains in the final sculpture, but you can see its effect in the shape of the bronze. Imagine how much more difficult it would be to produce the same thing starting with a lump of bronze and a chisel. For the same reasons, it can be better to write a program in Lisp, and then rewrite it in C, than to try to write it in C from the start.

Summary
1. Optimization should not begin too early, should be focused on bottlenecks, and should begin with algorithms.
2. Five parameters control compilation. They can be set with local or global declarations.
3. A good compiler can optimize tail calls, turning a tail-recursive function into a loop. Inline compilation is another way to avoid function calls.
4. Type declarations are not necessary, but they can make a program more efficient. Type declarations are especially important in numeric code, and code that deals with arrays.
5. Consing less can make a program faster, especially in implementations with primitive garbage collectors. Solutions include using destructive functions, pre-allocating blocks of space, and stack allocation.
6. In some situations, it might pay to draw objects from a pre-allocated pool.
7. Some parts of Common Lisp are designed for speed and others for flexibility.
8. Programming necessarily involves exploration. Exploration and optimization should be separated--sometimes even to the extent of using different languages for each.

Exercises
1. Test whether your compiler observes inline declarations.

13.7

EXERCISES

231

2. Rewrite the following function to be tail-recursive. How much faster is it when compiled? (defun foo (x) (if (zerop x) 0 (+ 1 (foo (1- x))))) Note: you will have to add another parameter. 3. Add declarations to the following programs. How much faster can you make them? (a) The date arithmetic code in Section 5.7. (b) The ray-tracer in Section 9.8. 4. Rewrite the breadth-first search code in Section 3.15 so that it conses as little as possible. 5. Modify the binary search tree code in Section 4.7 to use pools.



@node Advanced Topics
@chapter Advanced Topics


This chapter is optional. It describes a selection of the more
esoteric features of Common Lisp. Common Lisp is like an iceberg: a
great part of its functionality is invisible to most users, who never
need it. You may never need to define packages or read-macros of your
own, but when you do, it is helpful to have examples to work from.

@menu 
* Type Specifiers::
* Binary Streams::
* Read-Macros::
* Packages::
* The Loop Facility::
* Conditions::

@end menu

@node Type Specifiers
@section Type Specifiers 

lypes are not objects in Common Lisp. There is no object that corresponds to the type i n t e g e r , for example. What we get from a function like type-of, and give as an argument to a function like typep, is not a type, but a type specifier. A type specifier is the name of a type. The simplest type specifiers are symbols like i n t e g e r . These form a hierarchy in Common Lisp. At the top of the hierarchy is the type t--all objects are of type t . The hierarchy is not a tree. There are two paths from NIL to the top, for example: one through atom, and the other through LIST and sequence. A type is really just a set of objects. Which means that there are as many types as there are sets of objects: an infinite number. We can denote some of these sets with atomic type specifiers: i n t e g e r denotes the set of all the integers. But we can also construct compound type specifiers that refer to any set of objects. For example, if a and b are two type specifiers, then (or a b) denotes the union of the type denoted by a and that denoted by b. That is, an object is of type (or a b) if it is of type a or type b. 232

14.1

TYPE SPECIFIERS

233

If c i r c u l a r ? were a function that returned true of cdr-circular lists, then to denote the set of proper sequences you could use:1
(or vector (and list (not (satisfies circular?))))



Some of the atomic type specifiers can also appear in compound type specifiers. To denote the set of integers between 1 and 100 inclusive, we would use: ( i n t e g e r 1 100) Such a type specifier is said to denote a.finitetype. In a compound type-specifier, you can leave some information unspecified by using * in place of an argument. So (simple-array fixnum (* *)) describes the set of two-dimensional simple arrays specialized for fixnums, and (simple-array fixnum *) describes the set (a supertype of the first) of simple arrays specialized for fixnums. Trailing asterisks can be dropped, so in the latter case we could have said: (simple-array fixnum) If no arguments are given to a compound type-specifier, you can use an atom. So simple-array describes the set of all simple arrays. If there is some compound type specifier that you'd like to use repeatedly, you can define an abbreviation for it with def type. This macro is just like def macro, but expands into a type specifier instead of an expression. By saying
(deftype proseq () '(or vector (and list (not (satisfies circular?)))))

we define proseq as a new atomic type specifier: > (typep #(1 2) 'proseq) T If you define a type-specifier to take arguments, the arguments are treated as forms (that is, not evaluated), just as with def macro. So
1 Though the standard does not seem to mention this, you can assume that the type-specifiers and and or only consider as many of their arguments as they need to, like the and and or macros.

234

ADVANCED TOPICS





(deftype multiple-of (n) '(and integer (satisfies (lambda (x) (zerop (mod x ,n)))))) defines ( m u l t i p l e - o f n) as a specifier for all multiples of n: > (typep 12 ' ( m u l t i p l e - o f 4)) T Type specifiers are interpreted, and therefore slow, so you would generally be better off defining a function to make this kind of test.

@node Binary Streams
@section Binary Streams


Chapter 7 mentioned that there were binary streams as well as character streams. A binary stream is a source and/or destination not of characters but of integers. You create a binary stream by specifying a subtype of integer--most often unsigned-byte--as the : element-type when you open the stream. There are only two functions for I/O on binary streams, read-byte and w r i t e - b y t e . So here is how you might define a function to copy a file: (defun c o p y - f i l e (from t o ) ( w i t h - o p e n - f i l e ( i n from : d i r e c t i o n :input :element-type 'unsigned-byte) ( w i t h - o p e n - f i l e (out t o : d i r e c t i o n :output :element-type 'unsigned-byte) (do ( ( i ( r e a d - b y t e in NIL -1) (read-byte in NIL -1))) ((minusp i )) ( d e c l a r e (fixnum i )) (write-byte i out))))) By specifying just unsigned-byte as the : element-type, you let the operating system choose the length of a byte. If you specifically wanted to read or write 7-bit integers, for example, you would use (unsigned-byte 7) as the : element-type instead.

14.3

READ-MACROS

235

@node Read-Macros
@section Read-Macros


Section 7.5 introduced the concept of a macro character, a character that has a special meaning to read. Each such character has a function associated with it that tells read what to do when the character is encountered. You can change the function associated with an existing macro character, or define new read-macros of your own. The function s e t - m a c r o - c h a r a c t e r provides one way to define readmacros. It takes a character and a function, and thereafter when read encounters the character, it returns the result of calling the function. One of the oldest read-macros in Lisp is ', the quote. We could define it as: (set-macro-character #V #'(lambda (stream char) ( LIST (quote quote) (read stream t NIL t )))) When read encounters an instance of * in a normal context, it will return the result of calling this function on the current stream and character. (The function ignores this second parameter, which will always be the quote character.) So when read sees ' a, it will return (quote a ) . Now we see the point of the last argument to read. It says whether the call to read occurs within a call to read. The arguments to read will be the same in nearly all read-macros: the stream; the second argument, t , which says that read should signal an error if the next thing it sees is the end-of-file; the third argument, which says what to return instead of generating an error is therefore irrelevant; and the fourth argument, t, which says that the call to read is a recursive one. You can (with make-dispatch-macro-character) define your own dispatching macro characters, but since # is already defined as one, you may as well use it. Six combinations beginning with # are explicitly reserved for your use: #!, #?, # [ , # ] , #"", and #. You can define new dispatching macro character combinations by calling s e t - d i s p a t c h - m a c r o - c h a r a c t e r , which is like s e t - m a c r o - c h a r a c t e r except that it takes two character arguments. This code defines #? as a read-macro that returns a list of integers. ( s e t - d i s p a t c h - m a c r o - c h a r a c t e r #\# #\? #'(lambda (stream c h a r l char2) ( LIST 'quote (let ((lst NIL ))
(dotimes (i (+ (read stream t nil t) 1)) (push i lst)) (nreverse lst)))))

236

ADVANCED TOPICS


Now #?rc will be read as a list of all the integers from 0 to n. For example: > #?7 (01234567) After simple macro characters, the most commonly defined macro characters are list delimiters. Another character combination reserved for the user is #"". Here we define it as a more elaborate kind of left parenthesis: ( s e t - m a c r o - c h a r a c t e r # \  (get-macro-character # \ ))) ( s e t - d i s p a t c h - m a c r o - c h a r a c t e r #\# #\"" #'(lambda (stream c h a r l char2) (let ((accum NIL ) ( p a i r ( r e a d - d e l i m i t e d - LIST # \  stream t ))) (do ( ( i (car p a i r ) (+ i 1))) ((> i (cadr p a i r )) ( LIST 'quote (nreverse accum))) (push i accum))))) This defines an expression of the form #""x y to read as a list of all the integers between x and y, inclusive:


> #""2 7 ( 2 3 4 5 6 7 )

The function r e a d - d e l i m i t e d - LIST is provided just for such read-macros. Its first argument is the character to treat as the end of the list. For  to be recognized as a delimiter, it must first be given this role, hence the preliminary call to s e t - m a c r o - c h a r a c t e r . If you want to use a read-macro in the file in which it is defined, the definition should be wrapped in an eval-when expression, to ensure that it is evaluated at compile time. Otherwise the definition will be compiled, but not evaluated until the compiled file is loaded.

@node Packages
@section Packages 

A package is a Lisp object that maps names to symbols. The current package is always stored in the global variable *package*. When Common Lisp starts up, the current package will be common-lisp-user, informally known as the user package. The function package-name returns the name of a package, and find-package returns the package with a given name:

14.4

PACKAGES

237



> (package-name *package*) "COMMON-LISP-USER" > (find-package "COMMON-LISP-USER") #<Package "COMMON-LISP-USER" 4CD15E> Usually a symbol is interned in the package that was current at the time it was read. The function symbol-package takes a symbol and returns the package in which it is interned. > (symbol-package 'sym) #<Package "COMMON-LISP-USER" 4CD15E> Interestingly, this expression returns the value it does because the expression had to be read before it could be evaluated, and reading the expression caused sym to be interned. For future use, let's give sym a value: > ( s e t f sym 99) 99 Now we will create and switch to a new package: > (setf *package* (make-package 'mine :use '(common-lisp))) #<Package "MINE" 63390E> At this point there should be eerie music, because we are in a different world: sym here is not what it used to be. MINE> sym Error: S Y M has no v a l u e . Why did this happen? Because the sym we set to 99 above is a distinct symbol from sym here in mine. 2 To refer to the original sym from outside the user package, we must prefix the package name and two colons: MINE> common-lisp-user::sym 99 So different symbols with the same print-name can coexist in different packages. There can be one sym in package common-lisp-user and another sym in package mine, and they will be distinct symbols. That's the point of packages. If you're writing your program in a separate package, you can choose names for your functions and variables without worrying that someone
2 Some implementations of Common Lisp print the package name before the toplevel prompt whenever we are not in the user package.

238

ADVANCED TOPICS

will use the same name for something else. Even if they use the same name, it won't be the same symbol. Packages also provide a means of information-hiding. Programs must refer to functions and variables by their names. If you don't make a given name available outside your package, it becomes unlikely that code in another package will be able to use or modify what it refers to. It's usually bad style to use package prefixes with double colons. By doing so you are violating the modularity that packages are supposed to provide. If you have to use a double colon to refer to a symbol, it's because someone didn't want you to. Usually one should only refer to symbols that have been exported. If we go back to the user package (in-package sets *package*) and export a symbol interned there, MINE> (in-package common-lisp-user) #<Package "COMMON-LISP-USER" 4CD15E>
> (export 'bar) T > (setf bar 5) 5

we cause it to be visible to other packages. Now when we return to mine, we can refer to bar with only a single colon, because it is a publicly available name: > (in-package mine) #<Package "MINE" 63390E> MINE> common-lisp-user:bar 5 By importing bar into mine, we can go one step further and make mine actually share the symbol bar with the user package: MINE> (import T MINE> bar 5 'common-lisp-user:bar)

After importing bar we can refer to it without any package qualifier at all. The two packages now share the same symbol; there can't be a distinct mine: bar. What if there already was one? In that case, the call to import would have caused an error, as we see if we try to import sym: MINE> (import 'common-lisp-user::sym) Error: S Y M i s a l r e a d y p r e s e n t in MINE.

14.5

THE LOOP FACILITY

239

Before, when we tried unsuccessfully to evaluate sym in mine, we thereby caused a symbol sym to be interned there. It had no value and therefore generated an error, but the interning happened simply as a consequence of typing its name. So now when we try to import sym into mine, there is already a symbol there with the same name. Another way to get access to symbols from another package is to use it:
MINE> (use-package ;common-lisp-user) T

Now all symbols exported by the user package can be used without any qualifier in mine. (If sym had been exported by the user package, this call would also have generated an error.) The package containing the names of built-in operators and variables is called common-lisp. Since we gave the name of this package in the :use argument of the make-package that created mine, all of Common Lisp's names will be visible here: MINE> #'cons #<Compiled-Function CONS 462A3E> As with compilation, operations on packages are not usually done at the toplevel like this. More often the calls are contained in source files. Generally it will suffice to begin a file with a def package and an in-package, as on page 137. The kind of modularity provided by packages is actually a bit odd. We have modules not of objects, but of names. Every package that uses common-lisp has access to the name cons, because common-lisp includes a function with that name. But in consequence a variable called cons would also be visible in every package that used common-lisp. If packages are confusing, this is the main reason why; they're not based on objects, but on their names.0

@node The Loop Facility
@section The Loop Facility


The loop macro was originally designed to help inexperienced Lisp
users write iterative code. Instead of writing Lisp code, you express
your program in a form meant to resemble English, and this is then
translated into Lisp. Unfortunately, loop is more like English than
its designers ever intended: you can use it in simple cases without
quite understanding how it works, but to understand it in the abstract
is almost impossible.

If you are one of the many Lisp programmers who have been planning one
day to understand what loop does, there is some good news and some bad



240

ADVANCED TOPICS

news. The good news is that you are not alone: almost no one
understands it. The bad news is that you probably never will, because
the ANSI standard does not really give a formal specification of its
behavior.

The only real definition of this macro is its implementation, and the
only way to understand it (so far as one can) is by examples. The
chapter of the ANSI standard dealing with loop consists largely of
examples, and we will use the same approach here to introduce the
basic concepts involved.

The first thing one notices about the loop macro is that it has
syntax. A loop expression contains not subexpressions but clauses. The
clauses are not delimited by parentheses; instead, each kind has a
distinct syntax. In that, loop resembles traditional Algol-like
languages. But the other distinctive feature of loop, which makes it
as unlike Algol as Lisp, is that the order in which things happen is
only loosely related to the order in which the clauses occur.

There are three phases in the evaluation of a loop expression, and a
given clause can contribute code to more than one phase. The phases
are as follows:

1. Prologue. Evaluated once as a prelude to iteration. Includes
   setting variables to their initial values.

2. Body. Evaluated on each iteration. Begins with the termination
   tests, followed by the body proper, then the updating of iteration
   variables.

3. Epilogue. Evaluated once iteration is completed. Concludes with the
   return of the value(s) of the loop expression.

We will look at some examples of loop clauses and consider what kind
of code they might contribute to each phase.

For example, in the simplest kind of loop expression we might see
something like the following:

> (loop for x from 0 to 9 do (princ x)) 0123456789 NIL

This loop expression prints the integers from 0 to 9 and returns NIL
. The first clause,

for x from 0 t o 9

contributes code to thefirsttwo phases, causing x to be set to 0 in
the prologue, compared to 9 at the beginning of the body, and
incremented at the end. The second clause,



14.5 do (princ x)

THE LOOP FACILITY

241


contributes code (the princexpression) to the body proper.

A more general kind of for clause specifies an initial and update
form. Termination can then be controlled by something like a while or
u n t i l clause.

> (loop for x = 8 then (/ x 2) u n t i l (< x 1) do (princ x)) 8421 NIL

You can use and to create a compound for clause in which two variables
will be initialized and updated in parallel:

> (loop for x from 1 to 4 and y from 1 to 4 do (princ ( LIST x y )))
(1 1)(2 2 ) ( 3 3)(4 4) NIL

Otherwise, if there are multiple for
clauses, the variables will be updated sequentially.

Another thing one typically wants to do in iterative code is
accumulate some kind of value. For example:



> (loop for x in ' ( 1 2 3 4) c o l l e c t (1+ x)) (2 3 4 5)

Using in instead of from in the for clauses causes the variable to be
set to successive elements of a list instead of successive integers.

In this case the c o l l e c t clause contributes code to all three
phases. In the prologue an anonymous accumulator is set to NIL ; in
the body (1+ x) is appended to this accumulator; and in the epilogue
its value is returned.

This is the first example to return a particular value. There are
clauses for explicitly specifying the return value, but in the absence
of such clauses, a c o l l e c t clause determines the return
value. So what we've done here is duplicate mapcar.

The most common use of loop is probably to collect the results of
calling a function a certain number of times:

> (loop for x from 1 to 5 collect (random 10)) (38650)

242

ADVANCED TOPICS

(defun most (fn lst) (if (null lst) (values nil nil) (let* ((wins (car lst)) (max (funcall fn wins))) (dolist (obj (cdr lst)) (let ((score (funcall fn obj))) (when (> score max) (setf wins obj max score)))) (values wins max)))) (defun num-year (n) (if (< n 0) (do* ((y ( - yzero 1) ( - y 1)) (d ( - (year-days y)) ( - d (year-days y)))) ((<= d n) (values y ( - n d)))) (do* ((y yzero (+ y 1)) (prev 0 d) (d (year-days y) (+ d (year-days y)))) ((> d n) (values y ( - n prev)))))) Figure 14.1: Iteration without loop.

Here we get a list of five random numbers. It was for cases like this
that we defined map-int (page 105). Why do we need map-int if we have
loop? One can as easily ask, why do we need loop if we have map-int?

0

A c o l l e c t clause can also accumulate its value into a named
variable. The following function takes a list of numbers and returns
lists of the even and odd elements:

(defun even/odd (ns) (loop for n in ns if (evenp n) collect n into evens else collect n into odds finally (return (values evens odds))))

A f i n a l l y clause contributes code to the epilogue. In this case
it specifies the return value.

A sum clause is like a c o l l e c t clause, but accumulates a number
instead of a list. To get the sum of the numbers from 1 to n we could
write:



14.5

THE LOOP FACILITY

243


(defun most (fn lst) (if (null lst) (values nil nil) (loop with wins = (car lst) with max = (funcall fn wins) for obj in (cdr lst) for score = (funcall fn obj) when (> score max) do (setf wins obj max score) finally (return (values wins max)))))

(defun num-year (n) (if (< n 0) (loop for y downfrom ( - yzero 1) until (<= d n) sum ( - (year-days y)) into d finally (return (values (+ y 1) ( - n d)))) (loop with prev = 0 for y from yzero until (> d n) do (setf prev d) sum (year-days y) into d finally (return (values ( - y 1) ( - n prev))))))
Figure 14.2: Iteration with loop.

(defun sum (n) (loop for x from 1 to n sum x))

Further details of loop are covered in Appendix D, beginning on page
325. As an example, Figure 14.1 contains two iterative functions from
preceding chapters, and Figure 14.2 shows the same functions rendered
into loops.

One loop clause can refer to variables established by another. In the
definition of even/odd, for example, the f i n a l l y clause refers
to the variables established by the two c o l l e c t clauses. The
relations between such variables are one of the greatest ambiguities
in the definition of loop. Consider the following two expressions:



244

ADVANCED TOPICS

(loop
   for y = 0 then z
   for x from 1 to 5
   sum 1 into z
   finally (return (values y z)))

(loop
   for x from 1 to 5
   for y = 0 then z
   sum 1 into z
   finally (return (values y z)))

They seem simple enough--they each have only four clauses. Do they
return the same values? What values do they return? You will search
the standard in vain for the answers. Each loop clause is simple
enough by itself. But the way they combine is extremely
complicated--and ultimately, not even well-defined.

For such reasons, the use of loop cannot be recommended. The most that
can be said for it, in typical examples like those shown in Figure
14.2, is that it makes the code look easier to understand.


@node Conditions
@section Conditions

In Common Lisp, conditions include errors and other situations that can arise at run-time. When a condition is signalled, the corresponding handler is invoked. The default handler for error conditions usually invokes a breakloop. But Common Lisp provides a variety of operators for signalling and handling conditions. It's possible to override the default handlers, or even write new handlers of your own. Most programmers will not deal with conditions directly. However, there are several layers of more abstract operators that use conditions, and to understand these operators it helps to know about the underlying mechanism. Common Lisp has several operators for signalling errors. The most basic is e r r o r . One way to call it is to give it the same arguments that you might pass to format:
> (error "Your report uses ~A as a verb." Error: Your report uses STATUS as a verb. Options: :abort, :backtrace »
)

status)

Unless such a condition is handled, execution will be interrupted, as above. More abstract operators for signalling errors include ecase, check-type and a s s e r t . The former is like case, but signals an error if none of the keys match:

14.6

CONDITIONS

245

> (ecase 1 (2 3) (4 5)) Error: No applicable clause. Options: :abort, :backtrace »

The regular case will return NIL if no key matches, but since it's bad style to take advantage of this return value, you might as well use ecase whenever you don't have an otherwise clause. The check-type macro takes a place, a type name, and an optional string, and signals a correctable error if the value of the place is not of the designated type. The handler for a correctable error will give us the option of providing a new value:
> (let ((x '(a b c))) (check-type (car x) integer "an integer") x) Error: The value of (CAR X), A, should be an integer. Options: :abort, :backtrace, :continue >> .-continue New value of (CAR X)? 99 (99 B C) >

In this example, (car x) was set to the new value that we supplied, and execution resumed, returning what it would have returned if (car x) had originally contained the value we supplied. This macro is defined in terms of the more general a s s e r t , which takes a test expression and a list of one or more places, followed by the arguments you might give to e r r o r :
> (let ((sandwich '(ham on rye))) (assert (eql (car sandwich) 'chicken) ((car sandwich)) "I wanted a ~A sandwich." 'chicken) sandwich) Error: I wanted a CHICKEN sandwich. Options: :abort, :backtrace, :continue » :continue New value of (CAR SANDWICH)? 'chicken (CHICKEN ON RYE) >

It's also possible to establish new handlers, but most programmers will only take advantage of this possibility indirectly, by using macros like

246

ADVANCED TOPICS

i g n o r e - e r r o r s . This macro behaves like progn if none of its arguments cause an error. But if an error is signalled during the evaluation of one of its arguments, execution will not be interrupted. Instead the i g n o r e - e r r o r s expression will immediately return two values: NIL and the condition that was signalled. For example, if at some point you want the user to be able to enter an expression, but you don't want an error to interrupt execution if the input is syntactically ill-formed, you could write:
(defun user-input (prompt) (format t prompt) (let ((str (read-line))) (or (ignore-errors (read-from-string str)) nil)))

This function just returns NIL if the input contains syntax errors:
> (user-input "Please type an expression> ") Please type an expression> #°/»\Comma-at#+! ! NIL



@node Example-- Inference
@chapter Example-- Inference

The next three chapters offer examples of substantial Lisp
programs. These examples were chosen to illustrate the form that
longer programs take, and also the kinds of problems for which Lisp is
especially well-suited. In this chapter we will write a program that
makes inferences based on a collection of if-then rules.

This is a classic example--not only in the sense that it often appears
in textbooks, but also because it reflects the original idea of Lisp
as a language for "symbolic computation." A lot of the earliest Lisp
programs had the flavor of the example in this chapter.

@menu 
* The Aim::
* Matching::
* Answering Queries::
* Analysis::
@end menu


@node The Aim
@section The Aim



In this program, we're going to represent information in a familiar form: a list consisting of a predicate followed by zero or more arguments. To represent the fact that Donald is the parent of Nancy, we might say: (parent donald nancy) As well as facts, our program is going to represent rules that tell what can be inferred from the facts we already have. We will represent such rules as (<- head body) where head is the then-part and body is the if-part. Within the head and body we will represent variables as symbols beginning with question marks. So this rule (<- ( c h i l d ?x ?y) (parent ?y ?x)) 247

248

EXAMPLE: INFERENCE


says that if y is the parent of x, then x is the child of y; or more precisely, that we can prove any fact of the form ( c h i l d x v) by proving (parent y x). It will be possible for the body (if-part) of a rule to be a complex expression, containing the logical operators and, or, and not. So if we want to represent the rule that if JC is the parent of v, and x is male, then x is the father of v, we would write: (<- (father ?x ?y) (and (parent ?x ?y) (male ?x))) Rules may depend on facts implied by other rules. For example, the first rule we wrote was for proving facts of the form ( c h i l d x y). If we defined a rule (<- (daughter ?x ?y) (and ( c h i l d ?x ?y) (female ?x))) then using it to prove (daughter x y) might cause the program to use the first rule to prove ( c h i l d x y). The proof of an expression can continue back through any number of rules, so long as it eventually ends up on the solid ground of known facts. This process is sometimes called backward chaining. The backward comes from the fact that this kind of inference first considers the then-part, to see if the rule will be useful, before going on to prove the if-part. The chaining comes from the way that rules can depend on other rules, forming a chain (though in fact it's more like a tree) that leads from what we want to prove back to what we already know.0

@node Matching
@section Matching 

In order to write our backward-chaining program, we are going to need a function to do pattern-matching: a function that can compare two lists, possibly containing variables, to see if there is some way of assigning values to the variables which makes the two equal. For example, if ?x and ?y are variables, then the two lists (p ?x ?y c ?x) (p a b c a) match when ?x = a and ?y = b, and the lists (p ?x b ?y a) (p ?y b c a) match when ?x = ?y = c. Figure 15.1 contains a function called match. It takes two trees, and if they can be made to match, it returns an assoc-list showing how:

15.2

MATCHING

249

(defun match (x y feoptional binds) (cond ((eql x y) (values binds t)) ((assoc x binds) (match (binding x binds) y binds)) ((assoc y binds) (match x (binding y binds) binds)) ((var? x) (values (cons (cons x y) binds) t)) ((var? y) (values (cons (cons y x) binds) t)) (t (when (and (consp x) (consp y)) (multiple-value-bind (b2 yes) (match (car x) (car y) binds) (and yes (match (cdr x) (cdr y) b2))))))) (defun var? (x) (and (symbolp x) (eql (char (symbol-name x) 0) #\?))) (defun binding (x binds) (let ((b (assoc x binds))) (if b (or (binding (cdr b) binds) (cdr b)))))

Figure 15.1: Matching function.











> (match >(p a b c a) ' ( p ?x ?y c ?x)) ((?Y . B) (?X . A)) T > (match ' ( p ?x b ?y a) ' ( p ?y b c a )) ((?Y . C) (?X . ?Y)) T > (match ' ( a b c) ' ( a a a )) NIL As match compares its arguments element by element, it builds up assignments of values to variables, called bindings, in the parameter binds. If the match is successful, match returns the bindings generated; otherwise, it returns NIL . Since not all successful matches generate any bindings, match, like gethash, returns a second value to show that the match succeeded:

250

EXAMPLE: INFERENCE









> (match ' (p ?x) »(p ?x)) NIL T When match returns NIL and t as above, it indicates a successful match that yielded no bindings. In English, the match algorithm works as follows: 1. If x and y are eql they match; otherwise, 2. If x is a variable that has a binding, they match if it matches y; otherwise, 3. If y is a variable that has a binding, they match if it matches x; otherwise, 4. If x is a variable (without a binding), they match and thereby establish a binding for it; otherwise, 5. If y is a variable (without a binding), they match and thereby establish a binding for it; otherwise, 6. They match if they are both conses, and the cars match, and the cdrs match with the bindings generated thereby. Here is an example illustrating, in order, each of the six cases: > (match ' ( p ?v b ?x d (?z ?z)) ' (p a ?w c ?y ( e e )) >((?v . a) (?w . b ))) ((?Z . E) (?Y . D) (?X . C) (?V . A) (?W . B)) T To find the value (if there is one) associated with a variable in a list of bindings, match calls binding. This function has to be recursive, because matching can build up binding lists in which a variable is only indirectly associated with its value: ?x might be bound to a in virtue of the list containing both (?x . ?y) and (?y . a ) . > (match ; ( ? x a) ' ( ? y ?y)) ((?Y . A) (?X . ?Y))
T

By matching ?x with ?y and then ?y with a, we establish indirectly that ?x must be a.

15.3

ANSWERING QUERIES

251

(defvar *rules* (make-hash-table)) (defmacro <- (con ^optional ant) f (length (push (cons (cdr ',con) ',ant) (gethash (car ',con) *rules*)))) Figure 15.2: Defining rules.

@node Answering Queries
@section Answering Queries 

Now that the concept of bindings has been introduced, we can say more precisely what our program will do: it will take an expression, possibly containing variables, and return all the bindings that make it true given the facts and rules that we have. For example, if we have just the fact (parent donald nancy) and we ask the program to prove (parent ?x ?y) it should return something like (((?x . donald) (?y . nancy))) which says that there is exactly one way for the expression to be true: if ?x is donald and ?y is nancy. Now that we have a matching function we are already a good part of the way to our destination. Figure 15.2 contains the code for defining rules. The rules are going to be contained in a hash table called *rules*, hashed according to the predicate in the head. This imposes the restriction that we can't use variables in the predicate position. We could eliminate this restriction by keeping all such rules in a separate list, but then to prove something we would have to match it against every one. We will use the same macro, <-, to define both facts and rules. A fact will be represented as a rule with a head but no body. This is consistent with our definition of rules. A rule says that you can prove the head by proving the body, so a rule with no body means that you don't have to prove anything to prove the head. Here are two familiar examples: > (<- (parent donald nancy)) 1 > (<- (child ?x ?y) (parent ?y ?x)) 1

252

EXAMPLE: INFERENCE

(defun prove (expr feoptional binds) (case (car expr) (and (prove-and (reverse (cdr expr)) binds)) (or (prove-or (cdr expr) binds))
(not (prove-not (cadr expr) binds)) (t (prove-simple (car expr) (cdr expr) binds)))) (defun prove-simple (pred args binds) (mapcan #'(lambda (r) (multiple-value-bind (b2 yes) (match args (car r) binds) (when yes (if (cdr r) (prove (cdr r) b2) (list b2))))) (mapcar #'change-vars (gethash pred *rules*)))) (defun change-vars (r) (sublis (mapcar #'(lambda (v) (cons v (gensym "?"))) (vars-in r)) r)) (defun vars-in (expr) (if (atom expr) (if (var? expr) (list expr)) (union (vars-in (car expr)) (vars-in (cdr expr)))))

Figure 15.3: Inference.

Calls to <- return the number of rules now stored under a given predicate; wrapping the push in a call to length saves us from seeing a big return value at the toplevel. Figure 15.3 contains most of the code we need for inference. The function prove is the pivot on which inference turns. It takes an expression and an optional list of bindings. If the expression doesn't contain logical operators, it calls prove-simple, and it is here that chaining takes place. This function works by looking at all the rules with the right predicate, and trying to match the head of each with the fact it is trying to prove. For each head that matches,

15.3

ANSWERING QUERIES

253







it calls prove on the body, with the new bindings generated by the match. The lists of bindings returned by each call to prove are then collected by mapcan and returned: > (prove-simple ' p a r e n t (donald nancy) NIL ) (NIL) > (prove-simple >child ' (?x ?y) NIL ) ( ( ( # : ? 6 . NANCY) (#:?5 . DONALD) (?Y . #:?5) (?X . # : ? 6 ))) Both of the return values above indicate that there is one way to prove what we asked about. (A failed proof would return NIL . ) The first example generated one empty set of bindings, and the second generated one set of bindings in which ?x and ?y were (indirectly) bound to nancy and donald. Incidentally, we see here a good example of the point made on page 23. Because our program is written in a functional style, we can test each function interactively. What about those gensyms in the second return value? If we are going to use rules containing variables, we need to avoid the possibility of two rules accidentally containing the same variable. If we define two rules as follows (<- (child ?x ?y) (parent ?y ?x)) (<- (daughter ?y ?x) (and (child ?y ?x) (female ?y))) then we mean that for any x and y, x is the child of y if y is the parent of x, and for any x and y, y is the daughter of x if y is the child of x and female. The relationship of the variables within each rule is significant, but the fact that the two rules happen to use the same variables is entirely coincidental. If we used these rules as written, they would not work that way. If we tried to prove that a was b's daughter, matching against the head of the second rule would leave ?y bound to a and ?x to b. We could not then match the head of the first rule with these bindings: > (match '(child ?y ?x) '(child ?x ?y) '((?y . a) (?x . b))) NIL To ensure that the variables in a rule imply only something about the relations of arguments within that rule, we replace all the variables in a rule with gensyms. This is the purpose of the function change-vars. A gensym could not possibly turn up as a variable in another rule. But because rules can be recursive, we also have to guard against the possibility of a rule clashing with itself, so change-vars has to be called not just when a rule is defined, but each time it is used.

254

EXAMPLE: INFERENCE

(defun prove-and (clauses binds) (if (null clauses) (list binds) (mapcan #'(lambda (b) (prove (car clauses) b)) (prove-and (cdr clauses) binds)))) (defun prove-or (clauses binds) (mapcan #'(lambda (c) (prove c binds)) clauses)) (defun prove-not (clause binds) (unless (prove clause binds) (list binds))) Figure 15.4: Logical operators.





       





, (defmacro with-answer (query &body body) (let ((binds (gensym))) 1 (dolist ( , b i n d s (prove ' , q u e r y )) (let ,(mapcar #'(lambda (v) ' ( , v (binding ' , v , b i n d s ))) ( v a r s - i n query)) ,\Comma-atbody)))) Figure 15.5: Interface macro.

Now all that remains is to define the functions that prove complex expressions. These are shown in Figure 15.4. Handling an or or not expression is particularly simple. In the former case we collect all the bindings returned by each of the expressions within the or. In the latter case, we return the current bindings iff the expression within the not yields none. The function prove-and is only a little more complicated. It works like a filter, proving the first expression for each set of bindings that can be established for the remaining expressions. This would cause the expressions within the and to be considered in reverse order, except that the call to prove-and within prove reverses them to compensate. Now we have a working program, but it's not very user-friendly. It's a nuisance to have to decipher the lists of bindings returned by prove--and

15.4

ANALYSIS

255







(with-answer (p ?x ?y) (f ?x ?y)) is macroexpanded into: ( d o LIST ( # : g l (prove ; (P ?x ? y ))) (let ((?x (binding ' ?x #:gD) (?y (binding ' #:gl))) (f ?x ?y))) Figure 15.6: Exp ansion of a call to with-answer.

they only get longer as the rules get more complex. Figure 15.5 contains a macro that will make our program more pleasant to use: a with-answer expression will take a query (not evaluated) and a body of expressions, and will evaluate its body once for each set of bindings generated by the query, with each pattern variable bound to the value it has in the bindings. > (with-answer (parent ?x ?y) (format t "~A i s t h e parent of ~A.~°/0" ?x ?y)) DONALD i s t h e p a r e n t of NANCY. NIL This macro does the work of deciphering the bindings for us, and gives us a convenient way of using prove in programs. Figure 15.6 shows what an expansion looks like, and Figure 15.7 shows some examples of it in use.


@node Analysis
@section Analysis
It may seem as if the code we've written in this chapter is simply the natural way to implement such a program. In fact it is grossly inefficient. What we've done here, essentially, is to write an interpreter. We could implement the same program as a compiler. Here is a sketch of how it would be done. The basic idea would be to pack the whole program into the macros <- and with-answer, and make them do at macro-expansion time most of the work the program now does at run-time. (The germ of this idea is visible in avg, on page 170.) Instead of representing rules as lists, we would represent them as functions, and instead of having functions like prove and prove-and to interpret expressions at run-time, we would have corresponding functions to transform expressions into code. The expressions are available at the time a rule is defined. Why wait until it

256

EXAMPLE: INFERENCE







If we do a ( c l r h a s h *rules*) and then define the following rules and facts, (<(<(<(<(<(<(parent donald (parent donald (male donald)) ( f a t h e r ?x ?y) (= ?x ?x)) ( s i b l i n g ?x ?y) nancy)) debbie)) (and (parent ?x ?y) (male ? x ))) (and (parent ?z ?x) (parent ?z ?y) (not (= ?x ? y » » j





we will be able to make inferences like the following: > (with-answer ( f a t h e r ?x ?y) (format t "~A i s t h e f a t h e r of ~A.~°/.M ?x ?y)) DONALD i s t h e f a t h e r of DEBBIE. DONALD i s t h e f a t h e r of NANCY. NIL > (with-answer ( s i b l i n g ?x ?y) (format t "~A i s t h e s i b l i n g of ~k.~V ?x ? y » DEBBIE i s t h e s i b l i n g of NANCY. NANCY i s t h e s i b l i n g of DEBBIE. ! NIL Figure 15.7: The program in use.

is used in order to analyze them? The same goes for with-answer, which would call the same functions as <- to generate its expansion. This sounds like it would be a lot more complicated than the program we wrote in this chapter, but in fact it would probably only be about two or three times as long. Readers who would like to learn about such techniques should see On Lisp or Paradigms of Artificial Intelligence Programming, which contain several examples of programs written in this style.



@node Example-- Generating HTML
@chapter Example-- Generating HTML


@node Example-- Objects
@chapter Example-- Objects

@node A-- Debugging
@chapter A-- Debugging


@node B-- Lisp in Lisp
@chapter B-- Lisp in Lisp


@node C-- Changes to Common Lisp
@chapter C-- Changes to Common Lisp


@node D-- Language Reference
@chapter D-- Language Reference

@node Index
@unnumbered

The next chapter of bullshit.

@bye

